(window.webpackJsonp=window.webpackJsonp||[]).push([[60],{384:function(h,e,v){"use strict";v.r(e);var _=v(7),s=Object(_.a)({},(function(){var h=this,e=h._self._c;return e("ContentSlotsDistributor",{attrs:{"slot-key":h.$parent.slotKey}},[e("p",[h._v("Redis中的hash扩容渐进式rehash过程")]),h._v(" "),e("p",[h._v("背景： redis字典（hash表）当数据越来越多的时候，就会发生扩容，也就是rehash")]),h._v(" "),e("p",[h._v("对比：java中的hashmap，当数据数量达到阈值的时候(0.75)，就会发生rehash，hash表长度变为原来的二倍，将原hash表数据全部重新计算hash地址，重新分配位置，达到rehash目的。")]),h._v(" "),e("p",[h._v("为了避免 rehash 对服务器性能造成影响， 服务器不是一次性将 ht[0]里面的所有键值对全部 rehash 到 ht[1]， 而是分多次、渐进式地将 ht[0]里面的键值对慢慢地 rehash 到 ht[1]。")]),h._v(" "),e("p",[h._v("步骤：")]),h._v(" "),e("ol",[e("li",[h._v("为"),e("code",[h._v("ht[1]")]),h._v("分配空间，让字典同时持有"),e("code",[h._v("ht[0]")]),h._v("和"),e("code",[h._v("ht[1]")]),h._v("两个哈希表")]),h._v(" "),e("li",[h._v("将"),e("code",[h._v("rehashindex")]),h._v("的值设置为"),e("code",[h._v("0")]),h._v("，表示rehash工作正式开始")]),h._v(" "),e("li",[h._v("在rehash期间，每次对字典执行增删改查操作是，程序除了执行指定的操作以外，还会顺带将"),e("code",[h._v("ht[0]")]),h._v("哈希表在"),e("code",[h._v("rehashindex")]),h._v("索引上的所有键值对rehash到"),e("code",[h._v("ht[1]")]),h._v("，当rehash工作完成以后，"),e("code",[h._v("rehashindex")]),h._v("的值"),e("code",[h._v("+1")])]),h._v(" "),e("li",[h._v("随着字典操作的不断执行，最终会在某一时间段上"),e("code",[h._v("ht[0]")]),h._v("的所有键值对都会被rehash到"),e("code",[h._v("ht[1]")]),h._v("，这时将"),e("code",[h._v("rehashindex")]),h._v("的值设置为"),e("code",[h._v("-1")]),h._v("，表示rehash操作结束。")])]),h._v(" "),e("p",[h._v("渐进式rehash采用的是一种分而治之的方式，将rehash的操作分摊在每一个的访问中，避免集中式rehash而带来的庞大计算量。")])])}),[],!1,null,null,null);e.default=s.exports}}]);