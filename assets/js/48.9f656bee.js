(window.webpackJsonp=window.webpackJsonp||[]).push([[48],{372:function(_,t,v){"use strict";v.r(t);var s=v(7),a=Object(s.a)({},(function(){var _=this,t=_._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":_.$parent.slotKey}},[t("p",[_._v("学习路径：先要会用，然后可以发现问题。")]),_._v(" "),t("p",[_._v("mysql参考资料：")]),_._v(" "),t("ul",[t("li",[_._v("mysql的官方手册，有定位再去查漏补缺")]),_._v(" "),t("li",[_._v("《高性能的mysql》")])]),_._v(" "),t("p",[_._v("MDL metadata lock：元数据锁")]),_._v(" "),t("p",[_._v("一些建议：")]),_._v(" "),t("ul",[t("li",[_._v("道路千万条，实践第一条。手动搭建一套主备复制结构。平时遇到问题，动手复现。在阅读其他技术文章、图书时，如果觉得自己理解了一个知识点，也一定要尝试设计一个例子来验证它。也建议设置对照的反例，达到融会贯通。")]),_._v(" "),t("li",[_._v("怎么证明自己是不是真的把原理弄清楚了？说出来，写出来！如果有人请教你某个知识点，一定要跟他将清楚，不要觉得这是浪费时间。因为这样，依一来可以验证自己确实搞懂了这个知识点，二来可以提升自己的技术表达能力。毕竟你终究要面临和3类人讲清楚原理的时候：老板、晋升答辩的评委、新工作的面试官。")]),_._v(" "),t("li",[_._v("知识要成体系，才不容易忘记。")]),_._v(" "),t("li",[_._v("手册补全面，案例扫盲点。一开始不要看手册，手册应该是在你知识网络构建的差不多时再看。")])]),_._v(" "),t("h1",{attrs:{id:"一、基础架构"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#一、基础架构"}},[_._v("#")]),_._v(" 一、基础架构")]),_._v(" "),t("p",[_._v("大体来说，MySQL可以分为Server层和存储引擎层两部分。")]),_._v(" "),t("p",[t("img",{attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gug15ascfij614e0u0djp02.jpg",alt:"image-20210914121117751"}})]),_._v(" "),t("h2",{attrs:{id:"连接器"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#连接器"}},[_._v("#")]),_._v(" 连接器")]),_._v(" "),t("p",[_._v("一般的连接命令：")]),_._v(" "),t("div",{staticClass:"language-mysql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[_._v("mysql -h$ip -P$port -u\n")])])]),t("p",[_._v("完成经典的TCP握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。")]),_._v(" "),t("ul",[t("li",[t("p",[_._v('如果用户名或密码不对，你就会收到一个"Access denied for user"的错误，然后客户端程序 结束执行。')])]),_._v(" "),t("li",[t("p",[_._v("如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面 的权限判断逻辑，都将依赖于此时读到的权限。")])])]),_._v(" "),t("p",[_._v("一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不 会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。")]),_._v(" "),t("p",[_._v("连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在"),t("strong",[_._v("show processlist")]),_._v("命令中看到它。")]),_._v(" "),t("p",[_._v("客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数wait_timeout控制 的，默认值是8小时。")]),_._v(" "),t("p",[_._v("尽量使用长连接。")]),_._v(" "),t("p",[_._v("但是全部使用长连接后，你可能会发现，有些时候MySQL占用内存涨得特别快，这是因为 MySQL在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是MySQL异常重启了。")]),_._v(" "),t("p",[_._v("怎么解决这个问题呢？你可以考虑以下两种方案。")]),_._v(" "),t("ol",[t("li",[t("p",[_._v("定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。")])]),_._v(" "),t("li",[t("p",[_._v("如果你用的是MySQL 5.7或更新版本，可以在每次执行一个比较大的操作后，通过执行mysql_reset_connection来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。")])])]),_._v(" "),t("h2",{attrs:{id:"查询缓存"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#查询缓存"}},[_._v("#")]),_._v(" 查询缓存")]),_._v(" "),t("p",[_._v("但是大多数情况下我会建议你不要使用查询缓存， 因为查询缓存往往弊大于利。")]),_._v(" "),t("p",[_._v("查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此 很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库 来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。 比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。")]),_._v(" "),t("p",[_._v("好在MySQL也提供了这种“按需使用”的方式。你可以将参数query_cache_type设置成DEMAND，这样对于默认的SQL语句都不使用查询缓存。而对于你确定要使用查询缓存的语 句，可以用SQL_CACHE显式指定，像下面这个语句一样：")]),_._v(" "),t("div",{staticClass:"language-mysql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[_._v("select SQL_CACHE * from T where ID = 10;\n")])])]),t("p",[_._v("需要注意的是，MySQL 8.0版本直接将查询缓存的整块功能删掉了，也就是说8.0开始彻底没有 这个功能了。")]),_._v(" "),t("h2",{attrs:{id:"分析器"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#分析器"}},[_._v("#")]),_._v(" 分析器")]),_._v(" "),t("h3",{attrs:{id:"词法分析"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#词法分析"}},[_._v("#")]),_._v(" 词法分析")]),_._v(" "),t("p",[_._v("根据输入的字符串和空格进行识别，识别出里面的字符串分别是什么，代表什么。")]),_._v(" "),t("h3",{attrs:{id:"语法分析"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#语法分析"}},[_._v("#")]),_._v(" 语法分析")]),_._v(" "),t("p",[_._v("根据语法规则，判断输入的sql是否满足mysql语法。")]),_._v(" "),t("h2",{attrs:{id:"优化器"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#优化器"}},[_._v("#")]),_._v(" 优化器")]),_._v(" "),t("p",[_._v("优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join） 的时候，决定各个表的连接顺序。")]),_._v(" "),t("h2",{attrs:{id:"执行器"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#执行器"}},[_._v("#")]),_._v(" 执行器")]),_._v(" "),t("p",[_._v("首先判断有没对表T的执行权限。有的话就打开表继续执行。")]),_._v(" "),t("p",[_._v("分为有索引的情况和没索引的情况。")]),_._v(" "),t("p",[_._v("你会在数据库的慢查询日志中看到一个rows_examined的字段，表示这个语句执行过程中扫描了 多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。")]),_._v(" "),t("p",[_._v("在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟引擎扫描行数跟 rows_examined并不是完全相同的。")]),_._v(" "),t("h1",{attrs:{id:"二、日志系统"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#二、日志系统"}},[_._v("#")]),_._v(" 二、日志系统")]),_._v(" "),t("p",[_._v("与查询流程不同，更新流程还涉及两个重要的日志模块。")]),_._v(" "),t("ul",[t("li",[t("p",[_._v("redo log（重做日志）")])]),_._v(" "),t("li",[t("p",[_._v("binlog（归档日志）")])])]),_._v(" "),t("p",[_._v("而粉板和账本配合的整个过程，其实就是MySQL里经常说到的WAL技术，WAL的全称是WriteAhead Logging，它的关键点就是"),t("strong",[_._v("先写日志，再写磁盘")]),_._v("，也就是先写粉板，等不忙的时候再写账本。")]),_._v(" "),t("img",{staticStyle:{zoom:"50%"},attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gvcsomu70rj60u015c41602.jpg",alt:"image-20211012202158612"}}),_._v(" "),t("p",[_._v("MySQL整体来看，其实就有两块：一块是Server层，它主要做的是MySQL功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。上面我们聊到的粉板redo log是 InnoDB引擎特有的日志，而Server层也有自己的日志，称为binlog（归档日志）。")]),_._v(" "),t("p",[_._v("最开始MySQL里并没有InnoDB引擎。MySQL自带的引擎是MyISAM，但是MyISAM没有 crash-safe的能力，binlog日志只能用于归档。而InnoDB是另一个公司以插件形式引入MySQL的，既然只依靠binlog是没有crash-safe能力的，所以InnoDB使用另外一套日志系统— — 也就是 redo log来实现crash-safe能力。")]),_._v(" "),t("p",[_._v("有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个 能力称为crash-safe。")]),_._v(" "),t("p",[_._v("这两种日志有以下三点不同。")]),_._v(" "),t("ol",[t("li",[_._v("redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。")]),_._v(" "),t("li",[_._v("redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。")]),_._v(" "),t("li",[_._v("redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。")])]),_._v(" "),t("p",[_._v('redo log的写入拆成了两个步骤：prepare和commit，是"两阶段提交"。')]),_._v(" "),t("p",[_._v("当你需要扩容的时候，也就是需要再 多搭建一些备库来增加系统的读能力的时候，现在常见的做法也是用"),t("strong",[_._v("全量备份加上应用binlog")]),_._v("来实现的，这个“不一致”就会导致你的线上出现主从数据库不一致的情况。")]),_._v(" "),t("p",[_._v("简单说，redo log和binlog都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保 持逻辑上的一致。")]),_._v(" "),t("p",[_._v("**思考一个问题：**定期全量备份的周期“取决于系统重要性，有的是一天一备，有的是一周一备”。那么在什么场景下，一天一备会比一周一备更有优势呢？或者说，它影响了这个数据库系统的哪个指标？")]),_._v(" "),t("p",[_._v("一天一备，那么如果需要恢复数据的话，只要保证当天的binlog完整即可；一周一备的话就要保证一周的binlog完整；同时频繁全量备份需要更多存储空间，如何选择取决于业务的重要性，对应的指标是"),t("strong",[_._v("RTO")]),_._v("(目标恢复时间)。")]),_._v(" "),t("h1",{attrs:{id:"三、事务隔离"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#三、事务隔离"}},[_._v("#")]),_._v(" 三、事务隔离")]),_._v(" "),t("p",[_._v("提到事务，我们会想到ACID")]),_._v(" "),t("ul",[t("li",[_._v("Atomicity 原子性")]),_._v(" "),t("li",[_._v("Consistency 一致性")]),_._v(" "),t("li",[_._v("Isolation 隔离性")]),_._v(" "),t("li",[_._v("Durability 持久性")])]),_._v(" "),t("p",[_._v("这里主要谈隔离性。")]),_._v(" "),t("p",[_._v("当数据库上有多个事务同时执行的时候，就可能出现脏读（dirty read）、不可重复读（non- repeatable read）、幻读（phantom read）的问题，为了解决这些问题，就有了“隔离级别”的概念。")]),_._v(" "),t("p",[_._v("隔离得越严实，效率就会越低。")]),_._v(" "),t("p",[_._v("SQL标准的事务隔离级别包括：")]),_._v(" "),t("ul",[t("li",[_._v("读未提交（read uncommitted）：一个事务还没提交时，它做的变更就能被别的事务看到。")]),_._v(" "),t("li",[_._v("读提交（read committed）：一个事务提交之后，它做的变更才会被其他事务看到。")]),_._v(" "),t("li",[_._v("可重复读（repeatable read）：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。")]),_._v(" "),t("li",[_._v("串行化（serializable ）：对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。")])]),_._v(" "),t("p",[_._v("在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。"),t("strong",[_._v("在“可重复读”隔离级别下，这个视图是在事务启动时创建的")]),_._v("，整个事务存在期间都用这个视图。**在“读提交”隔离级 别下，这个视图是在每个SQL语句开始执行的时候创建的。**这里需要注意的是，“读未提交”隔离 级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避 免并行访问。")]),_._v(" "),t("p",[_._v("Oracle数据库的默认隔离级别其 实就是“读提交”，因此对于一些从Oracle迁移到MySQL的应用，为保证数据库隔离级别的一致， 你一定要记得将MySQL的隔离级别设置为“读提交”。mysql默认隔离级别是可重复读。")]),_._v(" "),t("p",[_._v("配置的方式是，将启动参数transaction-isolation的值设置成READ-COMMITTED。你可以用 show variables来查看当前的值。")]),_._v(" "),t("p",[_._v("尽量避免长事务。")]),_._v(" "),t("p",[_._v("长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。")]),_._v(" "),t("p",[_._v("在MySQL 5.5及以前的版本，回滚日志是跟数据字典一起放在ibdata文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。我见过数据只有20GB，而回滚段有200GB的库。最终只好为了清理回滚段，重建整个库。")]),_._v(" "),t("p",[_._v("除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库。")]),_._v(" "),t("p",[_._v("MySQL的事务启动方式有以下几种：")]),_._v(" "),t("ol",[t("li",[_._v("显式启动事务语句， begin 或 start transaction。配套的提交语句是commit，回滚语句是rollback。")]),_._v(" "),t("li",[_._v("set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个select语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。")])]),_._v(" "),t("p",[_._v("建议你总是使用set autocommit=1, 通过显式语句的方式来启动事务。")]),_._v(" "),t("h1",{attrs:{id:"四-五、索引"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#四-五、索引"}},[_._v("#")]),_._v(" 四&五、索引")]),_._v(" "),t("p",[_._v("索引场景模型：")]),_._v(" "),t("ul",[t("li",[_._v("哈希表：适用于只有等值查询的场景。")]),_._v(" "),t("li",[_._v("有序数组：在等值查询和范围查询场景中性能优秀。只适用于静态存储引擎，更新数据代价太高。")]),_._v(" "),t("li",[_._v("搜索树：N叉树，读写性能佳，适合磁盘的访问模式，广泛应用在数据库引擎中。")]),_._v(" "),t("li",[_._v("跳表、LSM树。。。")])]),_._v(" "),t("p",[_._v("在MySQL中，索引是在存储引擎层实现的，所以并没有统一的索引标准，即不同存储引擎的索 引的工作方式并不一样。而即使多个存储引擎支持同一种类型的索引，其底层的实现也可能不同。")]),_._v(" "),t("h2",{attrs:{id:"innodb的索引模型"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#innodb的索引模型"}},[_._v("#")]),_._v(" InnoDB的索引模型")]),_._v(" "),t("p",[_._v("InnoDB使用B+树索引模型。")]),_._v(" "),t("p",[_._v("每一个索引在InnoDB里对应一棵B+树。")]),_._v(" "),t("p",[_._v("根据叶子节点的内容，索引类型分为"),t("strong",[_._v("主键索引")]),_._v("和"),t("strong",[_._v("非主键索引")]),_._v("。")]),_._v(" "),t("p",[_._v("主键索引的叶子节点存储的是整行数据。在InnoDB中，主键索引也被称为聚簇索引（clustered index）。")]),_._v(" "),t("p",[_._v("非主键索引的叶子节点存储的是主键的值。在InnoDB中，非主键索引也被称为二级索引（secondary index）。")]),_._v(" "),t("p",[_._v("因此，基于主键索引和普通索引的查询的区别是，主键查询只需要搜索ID这棵B+树，普通索引查询，要先搜索普通索引树，得到ID后，再搜索ID索引树。这个过程称为"),t("strong",[_._v("回表")]),_._v("。")]),_._v(" "),t("p",[_._v("也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。")]),_._v(" "),t("p",[_._v("主键长度越小， 普通索引的叶子节点就越小， 普通索引占用的空间也就越小。")]),_._v(" "),t("p",[_._v("从性能和存储空间方面考量，"),t("strong",[_._v("自增主键")]),_._v("往往是更合理的选择。自增主键也不会造成分裂和合并操作。")]),_._v(" "),t("p",[_._v("Q：通过两个alter 语句重建索引k，以及通过两个alter语句重建主键索引是否合理？")]),_._v(" "),t("p",[_._v("重建索引k的做法是合理的，可以达到省空间的目的。但是，重建主键的过程不合理。不论是删除主键还是创建主键，都会将整个表重建。")]),_._v(" "),t("h2",{attrs:{id:"覆盖索引"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#覆盖索引"}},[_._v("#")]),_._v(" 覆盖索引")]),_._v(" "),t("p",[_._v("由于"),t("strong",[_._v("覆盖索引")]),_._v("可以减少树的搜索次数， 显著提升查询性能， 所以使用覆盖索引是一个常用的性能优化手段。")]),_._v(" "),t("p",[_._v("我们知道，身份证号是市民的唯一标识。也就是说，如果有根据身份证号查询市民信息的需求， 我们只要在身份证号字段上建立索引就够了。而再建立一个（身份证号、姓名）的联合索引，是不是浪费空间？")]),_._v(" "),t("p",[_._v("如果现在有一个高频请求，要根据市民的身份证号查询他的姓名，这个联合索引就有意义了。它 可以在这个高频请求上用到覆盖索引，不再需要回表查整行记录，减少语句的执行时间。")]),_._v(" "),t("p",[_._v("当然，索引字段的维护总是有代价的。因此，在建立冗余索引来支持覆盖索引时就需要权衡考虑 了。")]),_._v(" "),t("h2",{attrs:{id:"最左前缀原则"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#最左前缀原则"}},[_._v("#")]),_._v(" 最左前缀原则")]),_._v(" "),t("p",[_._v("在建立联合索引的时候， 如何安排索引内的字段顺序？")]),_._v(" "),t("p",[_._v("这里我们的评估标准是，索引的复用能力。因为可以支持最左前缀，所以当已经有了(a,b)这个联合索引后，一般就不需要单独在a上建立索引了。因此，第一原则是， 如果通过调整顺序， 可以少维护一个索引， 那么这个顺序往往就是需要优先考虑采用的。")]),_._v(" "),t("p",[_._v("如果不得不维护另一个索引，那么要考虑空间。")]),_._v(" "),t("h2",{attrs:{id:"索引下推"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#索引下推"}},[_._v("#")]),_._v(" 索引下推")]),_._v(" "),t("p",[_._v("在MySQL 5.6之前，只能从ID3开始一个个回表。到主键索引上找出数据行，再对比字段值。")]),_._v(" "),t("p",[_._v("而MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。")]),_._v(" "),t("h1",{attrs:{id:"六、全局锁和表锁"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#六、全局锁和表锁"}},[_._v("#")]),_._v(" 六、全局锁和表锁")]),_._v(" "),t("h2",{attrs:{id:"全局锁"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#全局锁"}},[_._v("#")]),_._v(" 全局锁")]),_._v(" "),t("p",[_._v("根据加锁的范围， MySQL里面的锁大致可以分成"),t("strong",[_._v("全局锁、表级锁和行锁")]),_._v("三类 。")]),_._v(" "),t("p",[_._v("顾名思义，全局锁就是对整个数据库实例加锁。MySQL提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括 建表、修改表结构等）和更新类事务的提交语句。")]),_._v(" "),t("p",[_._v("全局锁的典型使用场景是， 做"),t("strong",[_._v("全库逻辑备份")]),_._v("。 也就是把整库每个表都select出来存成文本。")]),_._v(" "),t("p",[_._v("不加锁的话，备份系统备份的得到的库不是一个逻辑时间点，这个视图是逻辑不一致的。")]),_._v(" "),t("p",[_._v("说到视图你肯定想起来了，我们在前面讲事务隔离的时候，其实是有一个方法能够拿到一致性视 图的，对吧？")]),_._v(" "),t("p",[_._v("是的，就是在可重复读隔离级别下开启一个事务。")]),_._v(" "),t("p",[_._v("官方自带的逻辑备份工具是mysqldump。当mysqldump使用参数–single-transaction的时候，导 数据之前就会启动一个事务，来确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是可以正常更新的。")]),_._v(" "),t("p",[_._v("你一定在疑惑，有了这个功能，为什么还需要FTWRL呢？一致性读是好，一致性读是好， 但前提是引擎要支 持这个隔离级别。 比如，对于MyISAM这种不支持事务的引擎，如果备份过程中有更新，总是 只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用FTWRL命令了。")]),_._v(" "),t("p",[_._v("所以，single-transaction方法只适用于所有的表使用事务引擎的库。 如果有的表使用了不支持事务的引擎，那么备份就只能通过FTWRL方法。这往往是DBA要求业务开发人员使用InnoDB替代MyISAM的原因之一。")]),_._v(" "),t("h2",{attrs:{id:"表级锁"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#表级锁"}},[_._v("#")]),_._v(" 表级锁")]),_._v(" "),t("p",[_._v("MySQL里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。")]),_._v(" "),t("p",[_._v("表锁的语法是 lock tables … read/write。 与FTWRL类似，可以用unlock tables主动释放锁， 也可以在客户端断开的时候自动释放。需要注意，lock tables语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。")]),_._v(" "),t("p",[_._v("另一类表级的锁是 MDL（ metadata lock)。 MDL不需要显式使用，在访问一个表的时候会被 自动加上。MDL的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。")]),_._v(" "),t("p",[_._v("因此，在MySQL 5.5版本中引入了MDL，当对一个表做增删改查操作的时候，加MDL读锁；当 要对表做结构变更操作的时候，加MDL写锁。")]),_._v(" "),t("p",[_._v("Q：如果你要变更的表是一个热点表，虽然数据量不大，但是上面的请求很频 繁，而你不得不加个字段，你该怎么做呢？")]),_._v(" "),t("p",[_._v("比较理想的机制是，在alter table语句里面 设定等待时间，如果在这个指定的等待时间里面能够拿到MDL写锁最好，拿不到也不要阻塞后 面的业务语句，先放弃。之后开发人员或者DBA再通过重试命令重复这个过程。")]),_._v(" "),t("p",[_._v("MariaDB已经合并了AliSQL的这个功能，所以这两个开源分支目前都支持DDL NOWAIT/WAIT n这个语法。")]),_._v(" "),t("h2",{attrs:{id:"小结"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#小结"}},[_._v("#")]),_._v(" 小结")]),_._v(" "),t("ul",[t("li",[_._v("全局锁主要用在逻辑备份过程中。对于全部是InnoDB引擎的库，我建议你选择使用–singletransaction参数，对应用会更友好。")]),_._v(" "),t("li",[t("strong",[_._v("表锁一般是在数据库引擎不支持行锁的时候才会被用到的")]),_._v("。如果你发现你的应用程序里有lock tables这样的语句，你需要追查一下，比较可能的情况是：\n"),t("ul",[t("li",[_._v("要么是你的系统现在还在用MyISAM这类不支持事务的引擎，那要安排升级换引擎；")]),_._v(" "),t("li",[_._v("要么是你的引擎升级了，但是代码还没升级。我见过这样的情况，最后业务开发就是把lock tables 和 unlock tables 改成 begin 和 commit，问题就解决了。")]),_._v(" "),t("li",[_._v("MDL会直到事务提交才释放，在做表结构变更的时候，你一定要小心不要导致锁住线上查询和更新。")])])])]),_._v(" "),t("h1",{attrs:{id:"九、普通索引和唯一索引的选择"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#九、普通索引和唯一索引的选择"}},[_._v("#")]),_._v(" 九、普通索引和唯一索引的选择")]),_._v(" "),t("p",[_._v("由于唯一索引用不上change buffer的优化机制，因此如果业务可以接受，从性能角度出发我建议你优先考虑非唯一索引。")]),_._v(" "),t("h1",{attrs:{id:"十、mysql为什么有时候会选错索引"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#十、mysql为什么有时候会选错索引"}},[_._v("#")]),_._v(" 十、MySQL为什么有时候会选错索引？")]),_._v(" "),t("p",[_._v("由于索引统计的更新机制，统计的行数有时会有偏差。")]),_._v(" "),t("p",[_._v("而且优化器存在选错索引的可能性。优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。在数据库里面，扫描行数是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的CPU资源越少。")]),_._v(" "),t("p",[_._v("扫描行数并不是唯一的判断标准，优化器还会结合是否使用临时表、是否排序等因素进行综合判断。")]),_._v(" "),t("p",[_._v("对于由于索引统计信息不准确导致的问题，你可以用analyze table t 语句来解决。（重新统计索引信息）")]),_._v(" "),t("p",[_._v("而对于其他优化器误判的情况，你可以在应用端用force index来强行指定索引，也可以通过修改语句来引导优化器，还可以通过增加或者删除索引来绕过这个问题。")]),_._v(" "),t("p",[_._v("估计记录数")]),_._v(" "),t("p",[_._v("mysql通过统计信息来估算记录数，这个统计信息就是索引的“区分度”。一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同值的个数，称为“基数”（cardinality）。")]),_._v(" "),t("p",[_._v("可使用show index from t，查看索引的基数。")]),_._v(" "),t("p",[_._v("mysql通过采样统计来得到索引的基数。InnoDB默认选择N个数据页，统计这些页面上的不通值，得到一个平均值，然后乘以这索引的页面数，得到这个索引的基数。当数据行数超过1/M的时候，会自动触发重新做一次统计所有。")]),_._v(" "),t("p",[_._v("在MySQL中，有两种存储索引统计的方式，可以通过设置参数innodb_stats_persistent的值来选择：")]),_._v(" "),t("ul",[t("li",[t("p",[_._v("设置为on的时候，表示统计信息会持久化存储。这时，默认的N是20，M是10。")])]),_._v(" "),t("li",[t("p",[_._v("设置为off的时候，表示统计信息只存储在内存中。这时，默认的N是8，M是16。")])]),_._v(" "),t("li",[t("p",[_._v("由于是采样统计，所以不管N是20还是8，这个基数都是很容易不准的。")])])]),_._v(" "),t("h1",{attrs:{id:"十一、怎么给字符串字段加索引"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#十一、怎么给字符串字段加索引"}},[_._v("#")]),_._v(" 十一、怎么给字符串字段加索引？")]),_._v(" "),t("p",[_._v("mysql支持前缀索引，可以定义字符串的一部分作为索引。默认索引包含整个字符串。")]),_._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("alter")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("table")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("user")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("add")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("index")]),_._v(" index1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("email"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(";")]),_._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("alter")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("table")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("user")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("add")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("index")]),_._v(" index2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("email"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[_._v("6")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(";")]),_._v("\n")])])]),t("p",[_._v("使用前缀索引可以减少空间占用，这是优势。但"),t("strong",[_._v("可能导致查询语句读数据的次数变多")]),_._v("。")]),_._v(" "),t("p",[_._v("因此使用前缀索引，需要定义好长度，达到即省空间，又不用额外增加太多的查询成本。")]),_._v(" "),t("p",[_._v("可以使用一下方法判断前缀的合适长度：(设定一个可以接受的损失比例)")]),_._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("select")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[_._v("count")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("distinct")]),_._v(" email"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("as")]),_._v(" L "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("from")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("user")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(";")]),_._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("select")]),_._v("\n\t"),t("span",{pre:!0,attrs:{class:"token function"}},[_._v("count")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("distinct")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("left")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("emial"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[_._v("4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("as")]),_._v(" L4"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v("\n\t"),t("span",{pre:!0,attrs:{class:"token function"}},[_._v("count")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("distinct")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("left")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("emial"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[_._v("5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("as")]),_._v(" L5"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v("\n\t"),t("span",{pre:!0,attrs:{class:"token function"}},[_._v("count")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("distinct")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("left")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("emial"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[_._v("6")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("as")]),_._v(" L6"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v("\n\t"),t("span",{pre:!0,attrs:{class:"token function"}},[_._v("count")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("distinct")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("left")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("emial"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[_._v("7")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("as")]),_._v(" L7"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("from")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("user")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(";")]),_._v("\n")])])]),t("p",[_._v("此外，使用前缀索引就用不上覆盖索引对查询性能的优化。")]),_._v(" "),t("p",[_._v("前缀多数相同时的索引思路：")]),_._v(" "),t("ul",[t("li",[_._v("倒序存储")]),_._v(" "),t("li",[_._v("增加hash字段，如用crc()得到校验码。")])]),_._v(" "),t("p",[_._v("总结：")]),_._v(" "),t("ol",[t("li",[_._v("直接创建完整索引，这样可能比较占用空间；")]),_._v(" "),t("li",[_._v("创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；")]),_._v(" "),t("li",[_._v("倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；")]),_._v(" "),t("li",[_._v("创建hash字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。")])]),_._v(" "),t("h1",{attrs:{id:"十二、为什么我的sql会-抖-一下"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#十二、为什么我的sql会-抖-一下"}},[_._v("#")]),_._v(" 十二、为什么我的SQL会“抖”一下")]),_._v(" "),t("p",[_._v("当内存数据页跟磁盘数据页内容不一致的时候， 我们称这个内存页为 “ 脏页 ” 。")]),_._v(" "),t("p",[_._v("平时执行很快的更新操作，其实就是在写内存和日志，而 MySQL偶尔“抖”一下的那个瞬间，可能就是在刷脏页（flush）。")]),_._v(" "),t("p",[_._v("什么情况会引发数据库flush？")]),_._v(" "),t("ul",[t("li",[_._v("InnoDB的redo log写满了。这时候系统会停止所有更新操作，把 checkpoint往前推进，redo log留出空间可以继续写。")]),_._v(" "),t("li",[_._v("系统内存不足。需要淘汰一些数据页，如果淘汰的是脏页就要先把脏页写到磁盘。")]),_._v(" "),t("li",[_._v("mysql认为系统空闲时。")]),_._v(" "),t("li",[_._v("mysql正常关闭时。")])]),_._v(" "),t("p",[_._v("所以，刷脏页虽然是常态，但是出现以下这两种情况，都是会明显影响性能的：")]),_._v(" "),t("ol",[t("li",[t("p",[_._v("一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；")])]),_._v(" "),t("li",[t("p",[_._v("日志写满，更新全部堵住，写性能跌为0，这种情况对敏感业务来说，是不能接受的。")])])]),_._v(" "),t("p",[_._v("所以，InnoDB需要有控制脏页比例的机制，来尽量避免上面的这两种情况。")]),_._v(" "),t("p",[_._v("通过innodb_io_capacity告诉InnoDB你的磁盘能力，全力刷脏页时可以多快。建议设为磁盘的IOPS。")]),_._v(" "),t("p",[_._v("参数innodb_max_dirty_pages_pct是脏页比例上限，默认值是75%。")]),_._v(" "),t("p",[_._v("平时要多关注脏页比例， 不要让它经常接近 75%。")]),_._v(" "),t("p",[_._v("innodb_flush_neighbors 参数值为1的时候会有“连坐”机制，值为0时表示不找邻居，自己刷自己的。在MySQL 8.0中，innodb_flush_neighbors参数的默认值已经是0了。")]),_._v(" "),t("h1",{attrs:{id:"十三、为什么表数据删掉一半-表文件大小不变"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#十三、为什么表数据删掉一半-表文件大小不变"}},[_._v("#")]),_._v(" 十三、为什么表数据删掉一半，表文件大小不变？")]),_._v(" "),t("p",[_._v("如果要收缩一个表，只是delete掉表里面不用的数据的话，表文件的大小是不会变的，你还要通过alter table命令重建表，才能达到表文件变小的目的。我跟你介绍了重建 表的两种实现方式，Online DDL的方式是可以考虑在业务低峰期使用的，而MySQL 5.5及之前的 版本，这个命令是会阻塞DML的，这个你需要特别小心。")]),_._v(" "),t("p",[_._v("optimize table、analyze table和alter table这三种方式重建表的区别。")]),_._v(" "),t("ul",[t("li",[_._v("从MySQL 5.6版本开始，alter table t engine = InnoDB（也就是recreate）默认的就是上面图4的流程了；")]),_._v(" "),t("li",[_._v("analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了MDL读锁；")]),_._v(" "),t("li",[_._v("optimize table t 等于recreate+analyze。")])]),_._v(" "),t("h1",{attrs:{id:"十四、count-这么慢-怎么办"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#十四、count-这么慢-怎么办"}},[_._v("#")]),_._v(" 十四、count(*)这么慢，怎么办？")]),_._v(" "),t("ul",[t("li",[_._v("MyISAM表虽然count(*)很快，但是不支持事务；")]),_._v(" "),t("li",[_._v("show table status命令虽然返回很快，但是不准确；")]),_._v(" "),t("li",[_._v("InnoDB表直接count(*)会遍历全表，虽然结果准确，但会导致性能问题。")])]),_._v(" "),t("p",[_._v("用redis或者是用另一张表记录总数，都会出现数据不一致的情况。")]),_._v(" "),t("p",[_._v("把计数放在Redis里面，不能够保证计数和MySQL表里的数据精确一致的原因，是这两个这两个不同的存储构成的系统， 不支持分布式事务， 无法拿到精确一致的视图。")]),_._v(" "),t("p",[_._v("而把计数值也放在 MySQL中，就解决了一致性视图的问题。 InnoDB引擎支持事务，我们利用好事务的原子性和隔离性，就可以简化在业务开发时的逻辑。 这也是InnoDB引擎备受青睐的原因之一。")]),_._v(" "),t("p",[_._v("问题都是由于InnoDB要支持事务，从而导致InnoDB表不能把count(*) 直接存起来，然后查询的时候直接返回形成的。 所谓以子之矛攻子之盾，现在我们就利用“事务”这个特性，把问题解决掉。")]),_._v(" "),t("p",[t("img",{attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gvalxjks5pj61i60u0aca02.jpg",alt:"image-20211010225722719"}})]),_._v(" "),t("p",[_._v("count()的语义。count()是一个聚合函数，对于返回的结果集，一行行地判断，如果count函数的参数不是NULL，累计值就加1，否则不加。最后返回累计值。")]),_._v(" "),t("p",[_._v("所以，count(*)、count(主键id)和count(1) 都表示返回满足条件的结果集的总行数；而count(字段），则表示返回满足条件的数据行里面，参数“字段”不为NULL的总个数。")]),_._v(" "),t("p",[_._v("分析性能差别：")]),_._v(" "),t("ul",[t("li",[_._v("server层要什么就给什么；")]),_._v(" "),t("li",[_._v("InnoDB只给必要的值；")]),_._v(" "),t("li",[_._v("现在的优化器只优化了count(*)的语义为“取行数”，其他“显而易见”的优化并没有做。")])]),_._v(" "),t("p",[_._v("结论是：按照效率排序的话，count(字段)<count(主键id)<count(1)≈count(*)，所以我建议你，尽量使用count(*)。")]),_._v(" "),t("h1",{attrs:{id:"十五、答疑-日志和索引相关"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#十五、答疑-日志和索引相关"}},[_._v("#")]),_._v(" 十五、答疑，日志和索引相关")]),_._v(" "),t("p",[_._v("崩溃恢复时的判断规则：")]),_._v(" "),t("ol",[t("li",[_._v("如果redo log里面的事务是完整的，也就是已经有了commit标识，则直接提交。")]),_._v(" "),t("li",[_._v("如果redo log里面的事务只有完整的prepare，则判断对应的事务binlog是否存在并完整：\n"),t("ol",[t("li",[_._v("如果是，则提交事务。")]),_._v(" "),t("li",[_._v("否则，回滚事务。")])])])]),_._v(" "),t("p",[_._v("mysql怎么知道binlog是否完整？")]),_._v(" "),t("p",[_._v("一个事务的binlog是由完整格式的：")]),_._v(" "),t("ul",[t("li",[_._v("statement格式的binlog，最后会有COMMIT；")]),_._v(" "),t("li",[_._v("row格式的binlog，最后会有一个XID event；")])]),_._v(" "),t("p",[_._v("另外，在MySQL 5.6.2后，还引入了binlog-checksum参数，用来验证binlog内容的正确性。")]),_._v(" "),t("p",[_._v("redo log 和 binlog是怎么关联起来的？")]),_._v(" "),t("p",[_._v("他们有一个共同的数据字段，叫XID，崩溃恢复时，会按顺序扫描redo log：")]),_._v(" "),t("ul",[t("li",[_._v("如果碰到既有prepare，又有commit的redo log，直接提交。")]),_._v(" "),t("li",[_._v("如果碰到只有prepare，没有commit的redo log，就拿着XID去binlog找对应的事务。")])]),_._v(" "),t("h1",{attrs:{id:"十六、order-by是怎么工作的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#十六、order-by是怎么工作的"}},[_._v("#")]),_._v(" 十六、order by是怎么工作的？")]),_._v(" "),t("p",[_._v("通常情况下，全字段排序：")]),_._v(" "),t("ol",[t("li",[t("p",[_._v("初始化sort_buffer，确定放入name、city、age这三个字段；")])]),_._v(" "),t("li",[t("p",[_._v("从索引city找到第一个满足city='杭州’条件的主键id，也就是图中的ID_X；")])]),_._v(" "),t("li",[t("p",[_._v("到主键id索引取出整行，取name、city、age三个字段的值，存入sort_buffer中；")])]),_._v(" "),t("li",[t("p",[_._v("从索引city取下一个记录的主键id；")])]),_._v(" "),t("li",[t("p",[_._v("重复步骤3、4直到city的值不满足查询条件为止，对应的主键id也就是图中的ID_Y；")])]),_._v(" "),t("li",[t("p",[_._v("对sort_buffer中的数据按照字段name做快速排序；")])]),_._v(" "),t("li",[t("p",[_._v("按照排序结果取前1000行返回给客户端。")])])]),_._v(" "),t("p",[_._v("如果mysql认为排序的单行长度太大会采用rowid排序：")]),_._v(" "),t("p",[_._v("（即新的算法放入sort_buffer的字段，只有要排序的列（即name字段）和主键id，然后再从原表取）")]),_._v(" "),t("ol",[t("li",[t("p",[_._v("初始化sort_buffer，确定放入两个字段，即name和id；")])]),_._v(" "),t("li",[t("p",[_._v("从索引city找到第一个满足city='杭州’条件的主键id，也就是图中的ID_X；")])]),_._v(" "),t("li",[t("p",[_._v("到主键id索引取出整行，取name、id这两个字段，存入sort_buffer中；")])]),_._v(" "),t("li",[t("p",[_._v("从索引city取下一个记录的主键id；")])]),_._v(" "),t("li",[t("p",[_._v("重复步骤3、4直到不满足city='杭州’条件为止，也就是图中的ID_Y；")])]),_._v(" "),t("li",[t("p",[_._v("对sort_buffer中的数据按照字段name进行排序；")])]),_._v(" "),t("li",[t("p",[_._v("遍历排序结果，取前1000行，并按照id的值回到原表中取出city、name和age三个字段返回")])])]),_._v(" "),t("p",[_._v("给客户端。")]),_._v(" "),t("p",[_._v("如果MySQL实在是担心排序内存太小，会影响排序效率，才会采用rowid排序算法，这样排序过 程中一次可以排序更多行，但是需要再回到原表去取数据。")]),_._v(" "),t("p",[_._v("如果MySQL认为内存足够大，会优先选择全字段排序，把需要的字段都放到sort_buffer中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据。")]),_._v(" "),t("p",[_._v("这也就体现了MySQL的一个设计思想：如果内存够，如果内存够， 就要多利用内存， 尽量减少磁盘访问。")]),_._v(" "),t("p",[_._v("优化：（索引的维护有代价，需要权衡）")]),_._v(" "),t("ul",[t("li",[_._v("如果从索引上取出来的行，天然就排序好了的话，就可以不用再排序了。可以使用联合索引。")]),_._v(" "),t("li",[_._v("还可以覆盖索引，使其直接返回需要的值。（也是用上联合索引）")])]),_._v(" "),t("h1",{attrs:{id:"十七、如何正确地显示随机消息"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#十七、如何正确地显示随机消息"}},[_._v("#")]),_._v(" 十七、如何正确地显示随机消息")]),_._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[_._v("# 随机选择3个单词")]),_._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("select")]),_._v(" word "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("from")]),_._v(" words "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("order")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("by")]),_._v(" rand"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("limit")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[_._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(";")]),_._v("\n")])])]),t("p",[_._v("这条语句的执行流程是这样的：")]),_._v(" "),t("ol",[t("li",[_._v("创建一个临时表。这个临时表使用的是memory引擎，表里有两个字段，第一个字段是 double类型，为了后面描述方便，记为字段R，第二个字段是varchar(64)类型，记为字段")])]),_._v(" "),t("p",[_._v("W。并且，这个表没有建索引。")]),_._v(" "),t("ol",{attrs:{start:"2"}},[t("li",[_._v("从words表中，按主键顺序取出所有的word值。对于每一个word值，调用rand()函数生成一")])]),_._v(" "),t("p",[_._v("个大于0小于1的随机小数，并把这个随机小数和word分别存入临时表的R和W字段中，到 此，扫描行数是10000。 3. 现在临时表有10000行数据了，接下来你要在这个没有索引的内存临时表上，按照字段R排")]),_._v(" "),t("p",[_._v("序。 4. 初始化 sort_buffer。sort_buffer中有两个字段，一个是double类型，另一个是整型。")]),_._v(" "),t("ol",{attrs:{start:"5"}},[t("li",[t("p",[_._v("从内存临时表中一行一行地取出R值和位置信息（我后面会和你解释这里为什么是“位置信 息”），分别存入sort_buffer中的两个字段里。这个过程要对内存临时表做全表扫描，此时 扫描行数增加10000，变成了20000。")])]),_._v(" "),t("li",[t("p",[_._v("在sort_buffer中根据R的值进行排序。注意，这个过程没有涉及到表操作，所以不会增加扫")])])]),_._v(" "),t("p",[_._v("描行数。")]),_._v(" "),t("ol",{attrs:{start:"7"}},[t("li",[_._v("排序完成后，取出前三个结果的位置信息，依次到内存临时表中取出word值，返回给客户")])]),_._v(" "),t("p",[_._v("端。这个过程中，访问了表的三行数据，总扫描行数变成了20003。")]),_._v(" "),t("p",[_._v("小结：order by rand()使用了内存临时表， 内存临时表排序的时候使用了 rowid排序方法。")]),_._v(" "),t("ul",[t("li",[t("p",[_._v("对于对于 InnoDB表来说 ，执行全字段排序会减少磁盘访问，因此会被优先选择。")])]),_._v(" "),t("li",[t("p",[_._v("而对于内存表， 回表过程只是简单地根据数据行的位 置， 直接访问内存得到数据， 根本不会导致多访问磁盘 。优化器没有了这一层顾虑，那么它 会优先考虑的，就是用于排序的行长度越少越好了，所以，MySQL这时就会选择rowid排序。")])])]),_._v(" "),t("p",[_._v("tmp_table_size配置内存临时表的大小，默认是16M，超过时会转成磁盘临时表。")]),_._v(" "),t("p",[_._v("MySQL 5.6版本引入的一个新的排序算法， 即：优先队列排序算法。（维护了一个堆）")]),_._v(" "),t("p",[_._v("临时文件的算法也就是归并算法。")]),_._v(" "),t("p",[_._v("如果你直接使用order by rand()，这个语句需要Using temporary 和 Using filesort，查询的执行代价往往是比较大的。所以，在设计的时候你要量避开这种写法。")]),_._v(" "),t("p",[_._v("为了达到严格的随机结果：")]),_._v(" "),t("ol",[t("li",[_._v("取到整个表的行数，记作C。")]),_._v(" "),t("li",[_._v("取到Y = floor(C * rand())。floor在这里的作用，就是取整数部分。")]),_._v(" "),t("li",[_._v("再用limit Y, 1取得一行。")])]),_._v(" "),t("h1",{attrs:{id:"十八、为什么逻辑相同的sql语句-性能差异巨大-先pass"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#十八、为什么逻辑相同的sql语句-性能差异巨大-先pass"}},[_._v("#")]),_._v(" 十八、为什么逻辑相同的SQL语句，性能差异巨大（先pass）")]),_._v(" "),t("p",[_._v("小结：对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。")]),_._v(" "),t("h1",{attrs:{id:"十九、为什么只查一行的语句-也执行慢"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#十九、为什么只查一行的语句-也执行慢"}},[_._v("#")]),_._v(" 十九、为什么只查一行的语句，也执行慢？")]),_._v(" "),t("p",[_._v("分析原因时候，一般先执行"),t("code",[_._v("show processlist")]),_._v("，看看当前语句处于什么状态。")]),_._v(" "),t("p",[_._v("第一类：查询长时间不返回")]),_._v(" "),t("ul",[t("li",[t("p",[_._v("等MDL锁")]),_._v(" "),t("p",[_._v("出现Waiting for table metadata lock，表示现在有一个线程正在表t上请求或者持有MDL写锁，把select语句堵住了。")]),_._v(" "),t("p",[_._v("解决：通过查询"),t("code",[_._v("select blocking_pid from sys.schema_table_lock_waits;")]),_._v("查出造成阻塞的process id，把他kill了。")])]),_._v(" "),t("li",[t("p",[_._v("等flush")])]),_._v(" "),t("li",[t("p",[_._v("等行锁")])])]),_._v(" "),t("p",[_._v("第二类：查询慢")]),_._v(" "),t("h1",{attrs:{id:"二十、幻读是什么-有什么问题-还是有点蒙呀"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#二十、幻读是什么-有什么问题-还是有点蒙呀"}},[_._v("#")]),_._v(" 二十、幻读是什么？有什么问题？（还是有点蒙呀）")]),_._v(" "),t("p",[_._v("for update 排他锁")]),_._v(" "),t("p",[_._v("for update仅适用于InnoDB，且必须在事务块(BEGIN/COMMIT)中才能生效。在进行事务操作时，通过“for update”语句，MySQL会对查询结果集中每行数据都添加排他锁，其他线程对该记录的更新与删除操作都会阻塞。排他锁包含行锁、表锁。")]),_._v(" "),t("p",[_._v("lock in share mode 共享锁")]),_._v(" "),t("p",[_._v("幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。")]),_._v(" "),t("p",[_._v("“幻读”做一个说明：")]),_._v(" "),t("ol",[t("li",[t("p",[_._v("在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此， 幻读在“当前读”下才会出现。")])]),_._v(" "),t("li",[t("p",[_._v("上面session B的修改结果，被session A之后的select语句用“当前读”看到，不能称为幻读。 幻读仅专指“新插入的行”。")])])]),_._v(" "),t("p",[_._v("锁的设计是为了保证数据的一致性。而这个一致性，不止是数据库内部数据状态在此 刻的一致性，还包含了数据和日志在逻辑上的一致性。")]),_._v(" "),t("p",[_._v("InnoDB如何解决幻读？")]),_._v(" "),t("p",[_._v("幻读产生的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB只好引入新的锁，也即是间隙锁（Gap Lock）。")]),_._v(" "),t("p",[_._v("间隙锁和行锁合称next-key lock。但其实他们是分开加的。")]),_._v(" "),t("p",[_._v("间隙锁是在可重复读隔离级别下才会生效的。所以，你如果把隔离级别设置为读提交的话， 就没有间隙锁了。但同时，你要解决可能出现的数据和日志不一致问题，需要把binlog格式设置 为row。这也是现在不少公司使用的配置组合。")]),_._v(" "),t("p",[_._v("很多公司使用：读提交隔离级别加binlog_format=row的组合。到底合不合理？")]),_._v(" "),t("p",[_._v("如果读提交隔离级别够用，即业务不需要可重复读的保证，这样考虑到读提交下操作数据的锁范围更小（没有间隙锁），这个选择是合理的。")]),_._v(" "),t("p",[_._v("比如大家都用读提交，可逻辑备份时，mysqldump为什么要把备份线程设置成可重复读？然后，在备份期间，备份线程用的是可重复读，而业务线程使用的是读提交，同时存在两种事务隔离级别会不会有问题？")]),_._v(" "),t("h1",{attrs:{id:"二十一、加锁规则"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#二十一、加锁规则"}},[_._v("#")]),_._v(" 二十一、加锁规则")]),_._v(" "),t("h2",{attrs:{id:"可重复读隔离级别下"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#可重复读隔离级别下"}},[_._v("#")]),_._v(" 可重复读隔离级别下")]),_._v(" "),t("p",[_._v("锁是加在索引上的。")]),_._v(" "),t("p",[_._v("next-key lock=间隙锁+行锁，(]，前开后闭区间。")]),_._v(" "),t("p",[_._v("间隙锁，()，前开后开区间。")]),_._v(" "),t("p",[_._v("行锁就一个。")]),_._v(" "),t("p",[_._v("加锁规则：2个原则，2个优化，1个bug")]),_._v(" "),t("ol",[t("li",[t("p",[_._v("原则1：加锁的基本单位是next-key lock。")])]),_._v(" "),t("li",[t("p",[_._v("原则2：查找过程中访问到的对象才会加锁。")])]),_._v(" "),t("li",[t("p",[_._v("优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁。")])]),_._v(" "),t("li",[t("p",[_._v("优化2：索引上的等值查询，向右遍历时且遇到不满足等值条件的值时，next-key lock退化为间隙锁。")])]),_._v(" "),t("li",[t("p",[_._v("一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。")])])]),_._v(" "),t("h2",{attrs:{id:"读提交隔离级别下"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#读提交隔离级别下"}},[_._v("#")]),_._v(" 读提交隔离级别下")]),_._v(" "),t("p",[_._v("读提交隔离级别的话，去掉间隙锁的部分，剩下行锁的部分。")]),_._v(" "),t("p",[_._v("其实读提交隔离级别在外键场景下还是有间隙锁，相对比较复杂，我们今天先不展开。")]),_._v(" "),t("p",[_._v("另外，在读提交隔离级别下还有一个优化，即：语句执行过程中加上的行锁，在语句执行完成后，就要把“不满足条件的行”上的行锁直接释放了，不需要等到事务提交。")]),_._v(" "),t("p",[_._v("也就是说，读提交隔离级别下，锁的范围更小，锁的时间更短，这也是不少业务都默认使用读提交隔离级别的原因。")]),_._v(" "),t("h1",{attrs:{id:"_24、mysql怎么保持主备一致"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_24、mysql怎么保持主备一致"}},[_._v("#")]),_._v(" 24、mysql怎么保持主备一致？")]),_._v(" "),t("p",[_._v("binlog功不可没。")]),_._v(" "),t("p",[_._v("mysql有容易学习和方便使用高可用架构。几乎所有的高可用架构，都直接依赖于binlog。虽然越来与复杂，但都是从最基本的一主一备演化而来。")]),_._v(" "),t("p",[_._v("在一个主备关系中，每个备库接受主库的binlog执行。只要主库执行更新生成的所有binlog都可以传到备库被正确执行，备库就能达到跟主库一致的状态，这就是"),t("strong",[_._v("最终一致性")]),_._v("。")]),_._v(" "),t("p",[_._v("建议把备库设置成readonly模式。好处如下：")]),_._v(" "),t("ul",[t("li",[_._v("有些运营类的查询语句会再备库查，设置为只读可防止误操作。")]),_._v(" "),t("li",[_._v("防止切换逻辑bug，如切换过程中出现双写，造成主备不一致。")]),_._v(" "),t("li",[_._v("可用readonly状态，判断节点的角色。")])]),_._v(" "),t("p",[_._v("因为readonly设置对super权限角色无效，而用于同步更新的线程就拥有超级权限。")]),_._v(" "),t("p",[_._v("主库和备库之间维持了一个长连接。主库内部有一个线程，专门用于服务备库的这个长连接。")]),_._v(" "),t("p",[_._v("binlog的三种格式：（通过binlog_format属性设置）")]),_._v(" "),t("ul",[t("li",[_._v("statement。记录的是语句原文。可能导致主备不一致。")]),_._v(" "),t("li",[_._v("row。记录了真实删除行的主键id（如果是删除）。占空间，如删除10w条数据。")]),_._v(" "),t("li",[_._v("mixed。前两种的混合。")])]),_._v(" "),t("p",[_._v("现在越来越多的场景要求把mysql的binlog格式设置为row，其中之一好处在于：恢复数据。")]),_._v(" "),t("p",[_._v("实际生产使用比较多的是双M结构，互为主备。相较于MS结构，切换时不用修改主备关系。")]),_._v(" "),t("p",[_._v("mysql通过判断server id的方式，解决循环复制问题。")]),_._v(" "),t("p",[_._v("通过mysqlbinlog工具解析和查看binlog中的内容。")]),_._v(" "),t("h1",{attrs:{id:"_25、mysql如何保证高可用"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_25、mysql如何保证高可用"}},[_._v("#")]),_._v(" 25、mysql如何保证高可用？")]),_._v(" "),t("p",[_._v("只有最终一致性还不够，mysql还要提供高可用。")]),_._v(" "),t("h2",{attrs:{id:"主备延迟"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#主备延迟"}},[_._v("#")]),_._v(" 主备延迟")]),_._v(" "),t("p",[_._v("可通过在备库执行 "),t("code",[_._v("show slave status")]),_._v("显示"),t("code",[_._v("seconds_behind_master")]),_._v("表示当前备库延迟了多少秒。")]),_._v(" "),t("p",[_._v("主备延迟的来源：")]),_._v(" "),t("ul",[t("li",[_._v("备库所在的机器性能比主库的差。（现在一般做对称部署，主备切换）。")]),_._v(" "),t("li",[_._v("备库的压力大。")]),_._v(" "),t("li",[_._v("主库大事务。\n"),t("ul",[t("li",[_._v("因为主库必须等事务执行完成才会写入binlog，再传给备库。")]),_._v(" "),t("li",[_._v("如不要一次性用delete删除太多数据，典型的大事务场景。")]),_._v(" "),t("li",[_._v("如大表DDL也是典型的大事务场景。处理方案：计划内的DDL，建议使用go-ost方案。")])])]),_._v(" "),t("li",[_._v("备库的并行复制能力。")])]),_._v(" "),t("p",[_._v("一般处理：")]),_._v(" "),t("ul",[t("li",[_._v("一主多从。（这里把HA过程中被选成新主库的称为备库，其他的称为从库。备库和从库概念上差不多）")]),_._v(" "),t("li",[_._v("通过binlog输出到外部系统，如hadoop，让外部系统提供统计类查询的能力。")])]),_._v(" "),t("h3",{attrs:{id:"可靠性优先策略"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#可靠性优先策略"}},[_._v("#")]),_._v(" 可靠性优先策略：")]),_._v(" "),t("p",[_._v("双M结构下，主备切换：")]),_._v(" "),t("ol",[t("li",[_._v("判断备库B现在的seconds_behind_master，如果小于某个值（比如5秒）继续下一步，否则")])]),_._v(" "),t("p",[_._v("持续重试这一步；")]),_._v(" "),t("ol",{attrs:{start:"2"}},[t("li",[t("p",[_._v("把主库A改成只读状态，即把readonly设置为true；")])]),_._v(" "),t("li",[t("p",[_._v("判断备库B的seconds_behind_master的值，直到这个值变成0为止；")])]),_._v(" "),t("li",[t("p",[_._v("把备库B改成可读写状态，也就是把readonly 设置为false；")])]),_._v(" "),t("li",[t("p",[_._v("把业务请求切到备库B。")])])]),_._v(" "),t("p",[_._v("这个切换流程，一般是由专门的HA系统来完成的，我们暂时称之为"),t("strong",[_._v("可靠性优先流程")]),_._v("。")]),_._v(" "),t("h3",{attrs:{id:"可用性有先策略"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#可用性有先策略"}},[_._v("#")]),_._v(" 可用性有先策略：")]),_._v(" "),t("p",[_._v("如果我强行把步骤4、5调整到最开始执行，也就是说不等主备数据同步，直接把连接切到备库 B，并且让备库B可以读写，那么系统几乎就没有不可用时间了。")]),_._v(" "),t("p",[_._v("这个切换流程的代价，就是可能出现数据不一 致的情况。")]),_._v(" "),t("p",[_._v("结论：")]),_._v(" "),t("ol",[t("li",[t("p",[_._v("使用row格式的binlog时，数据不一致的问题更容易被发现。而使用mixed或者statement格式的binlog时，数据很可能悄悄地就不一致了。如果你过了很久才发现数据不一致的问题， 很可能这时的数据不一致已经不可查，或者连带造成了更多的数据逻辑不一致。")])]),_._v(" "),t("li",[t("p",[_._v("主备切换的可用性优先策略会导致数据不一致。因此，大多数情况下，我都建议你使用可靠性优先策略。毕竟对数据服务来说的话，数据的可靠性一般还是要优于可用性的。")])])]),_._v(" "),t("p",[_._v("在满足数据可靠性的前提下，MySQL高可用系统的可用性，是依赖于主备延迟的。延迟的时间越小，在主库故障的时候，服务恢复需要的时间就越短，可用性就越高。")]),_._v(" "),t("h1",{attrs:{id:"_26、备库为什么会延迟好几个小时-略看"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_26、备库为什么会延迟好几个小时-略看"}},[_._v("#")]),_._v(" 26、备库为什么会延迟好几个小时？（略看）")]),_._v(" "),t("p",[_._v("简单总结：")]),_._v(" "),t("p",[_._v("介绍了MySQL的各种"),t("strong",[_._v("多线程复制策略")]),_._v("。")]),_._v(" "),t("p",[_._v("为什么要有多线程复制呢？这是因为单线程复制的能力全面低于多线程复制，对于更新压力较大 的主库，备库是可能一直追不上主库的。从现象上看就是，备库上seconds_behind_master的值 越来越大。")]),_._v(" "),t("p",[_._v("大事务不仅会影响到主库，也是造成备库复制延迟的主要原因之一。 因此，在平时的开发工作中，我建议你尽量减少大事务操作，把大事务拆成小事务。")]),_._v(" "),t("p",[_._v("binlog-transaction-dependency-tracking参数：")]),_._v(" "),t("ul",[t("li",[_._v("COMMIT_ORDER")]),_._v(" "),t("li",[_._v("WRITESET")]),_._v(" "),t("li",[_._v("WRITE_SESSIOn")])]),_._v(" "),t("img",{staticStyle:{zoom:"50%"},attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gvm2exp1kjj617h0u0q4p02.jpg",alt:"image-20211020204851918"}}),_._v(" "),t("h1",{attrs:{id:"_27、主库出问题了从库怎么办"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_27、主库出问题了从库怎么办"}},[_._v("#")]),_._v(" 27、主库出问题了从库怎么办？")]),_._v(" "),t("p",[t("img",{attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gvm2gtrqt3j61850u0mzs02.jpg",alt:"image-20211020205044594"}})]),_._v(" "),t("p",[_._v("一主多从基本结构。")]),_._v(" "),t("p",[_._v("将节点B设置成节点A的从库A`，需要执行change master命令。")]),_._v(" "),t("p",[_._v("这条命令有6个参数，其中MASTER_LOG_FILE和MASTER_LOG_POS表示从主库的【文件名】、【日志偏移量】的日志继续同步。")]),_._v(" "),t("p",[_._v("这个pos往往不精确。")]),_._v(" "),t("p",[_._v("通常我们在切换任务时，要先主动跳过这些错误，有两种常用的方法：")]),_._v(" "),t("ul",[t("li",[_._v("主动跳过一个事务"),t("code",[_._v("set global sql_slave_skip_count = 1;start save;")])]),_._v(" "),t("li",[_._v("通过设置"),t("code",[_._v("slave_skip_error")]),_._v("参数，直接设置跳过指定的错误。\n"),t("ul",[t("li",[_._v("1062错误是插入数据时唯一键冲突；")]),_._v(" "),t("li",[_._v("1032错误是删除数据时找不到行。")])])])]),_._v(" "),t("h2",{attrs:{id:"gtid"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#gtid"}},[_._v("#")]),_._v(" GTID")]),_._v(" "),t("p",[_._v("通过sql_slave_skip_counter跳过事务和通过slave_skip_errors忽略错误的方法，虽然都最终可以 建立从库B和新主库A’的主备关系，但这两种操作都很复杂，而且容易出错。所以，MySQL 5.6版本引入了GTID，彻底解决了这个困难。")]),_._v(" "),t("p",[_._v("GTID的全称是Global Transaction Identifier，也就是全局事务ID，是一个事务在提交的时候生成的，是这个事务的唯一标识。")]),_._v(" "),t("p",[t("code",[_._v("GTID=server_uuid:gno")])]),_._v(" "),t("ul",[t("li",[t("p",[_._v("server_uuid是一个实例第一次启动时自动生成的，是一个全局唯一的值；")])]),_._v(" "),t("li",[t("p",[_._v("gno是一个整数，初始值是1，每次提交事务的时候分配给这个事务，并加1。")])])]),_._v(" "),t("p",[_._v("GTID主备复制的用法：")]),_._v(" "),t("p",[_._v("执行change maste，只需使用"),t("code",[_._v("master_auto_position = 1")]),_._v("代替前面的MASTER_LOG_FILE和MASTER_LOG_POS。")]),_._v(" "),t("p",[_._v("在基于GTID的主备关系里，系统认为只要建立主备关系，就必须保证主库发给备库的日志是完整的。因此，如果实例B需要的日志已经不存在，A’就拒绝把日志发给B。")]),_._v(" "),t("p",[_._v("这跟基于位点的主备协议不同。基于位点的协议，是由备库决定的，备库指定哪个位点，主库就发哪个位点，不做日志的完整性判断。")]),_._v(" "),t("h1",{attrs:{id:"_28、读写分离"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_28、读写分离"}},[_._v("#")]),_._v(" 28、读写分离")]),_._v(" "),t("p",[_._v("一主多从架构的应用场景：读写分离。")]),_._v(" "),t("p",[_._v("读写分离的主要目标就是分摊主库的压力。")]),_._v(" "),t("p",[t("img",{attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gvnbh6i76vj314a0mgabo.jpg",alt:"image-20211021224738188"}})]),_._v(" "),t("p",[_._v("客户端主动做读写分离。")]),_._v(" "),t("p",[t("img",{attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gvnbjhiczrj61g80r0dhf02.jpg",alt:"image-20211021225015121"}})]),_._v(" "),t("p",[_._v("中间代理层proxy分发。")]),_._v(" "),t("p",[_._v("方案：")]),_._v(" "),t("ul",[t("li",[_._v("强制走主库方案")]),_._v(" "),t("li",[_._v("sleep方案")]),_._v(" "),t("li",[_._v("判断主备无延迟方案\n"),t("ul",[t("li",[_._v("判断seconds_behind_master 是否等于0")]),_._v(" "),t("li",[_._v("对比位点qu确保主备无延迟")]),_._v(" "),t("li",[_._v("对比GTID集合确保主备无延迟")])])]),_._v(" "),t("li",[_._v("配合semi-sync方案")]),_._v(" "),t("li",[_._v("等主库位点方案")]),_._v(" "),t("li",[_._v("等GTID方案")])]),_._v(" "),t("h2",{attrs:{id:"判断主备无延迟方案"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#判断主备无延迟方案"}},[_._v("#")]),_._v(" 判断主备无延迟方案")]),_._v(" "),t("h2",{attrs:{id:"semi-sync-replication-半同步控制"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#semi-sync-replication-半同步控制"}},[_._v("#")]),_._v(" semi-sync replication 半同步控制")]),_._v(" "),t("ol",[t("li",[t("p",[_._v("事务提交的时候，主库把binlog发给从库；")])]),_._v(" "),t("li",[t("p",[_._v("从库收到binlog以后，发回给主库一个ack，表示收到了；")])]),_._v(" "),t("li",[t("p",[_._v("主库收到这个ack以后，才能给客户端返回“事务完成”的确认。")])])]),_._v(" "),t("p",[_._v("semi-sync配合前面关于位点的判断，就能够确定在从库上执行的查询请求，可以避免过期读。")]),_._v(" "),t("p",[_._v("但是，semi-sync+位点判断的方案，只对一主一备的场景是成立的。在一主多从场景中，主库只 要等到一个从库的ack，就开始给客户端返回确认。")]),_._v(" "),t("p",[_._v("小结一下，semi-sync配合判断主备无延迟的方案，存在两个问题：")]),_._v(" "),t("ol",[t("li",[t("p",[_._v("一主多从的时候，在某些从库执行查询请求会存在过期读的现象；")])]),_._v(" "),t("li",[t("p",[_._v("在持续延迟的情况下，可能出现过度等待的问题。")])])]),_._v(" "),t("p",[_._v("等主库位点方案，就可以解决这两个问题")]),_._v(" "),t("h2",{attrs:{id:"等主库位点方案"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#等主库位点方案"}},[_._v("#")]),_._v(" 等主库位点方案")]),_._v(" "),t("p",[t("code",[_._v("select master_pos_wait(file, pos[, timeout]);")])]),_._v(" "),t("ol",[t("li",[t("p",[_._v("它是在从库执行的；")])]),_._v(" "),t("li",[t("p",[_._v("参数file和pos指的是主库上的文件名和位置；")])]),_._v(" "),t("li",[t("p",[_._v("timeout可选，设置为正整数N表示这个函数最多等待N秒。")])])]),_._v(" "),t("p",[_._v("这个命令正常返回的结果是一个正整数M，表示从命令开始执行，到应用完file和pos表示的 binlog位置，执行了多少事务。")]),_._v(" "),t("p",[_._v("当然，除了正常返回一个正整数M外，这条命令还会返回一些其他结果，包括：")]),_._v(" "),t("ol",[t("li",[t("p",[_._v("如果执行期间，备库同步线程发生异常，则返回NULL；")])]),_._v(" "),t("li",[t("p",[_._v("如果等待超过N秒，就返回-1；")])]),_._v(" "),t("li",[t("p",[_._v("如果刚开始执行的时候，就发现已经执行过这个位置了，则返回0。")])]),_._v(" "),t("li",[t("p",[_._v("trx1事务更新完成后，马上执行show master status得到当前主库执行到的File和Position；")])]),_._v(" "),t("li",[t("p",[_._v("选定一个从库执行查询语句；")])]),_._v(" "),t("li",[t("p",[_._v("在从库上执行select master_pos_wait(File, Position, 1)；")])]),_._v(" "),t("li",[t("p",[_._v("如果返回值是>=0的正整数，则在这个从库执行查询语句；")])]),_._v(" "),t("li",[t("p",[_._v("否则，到主库执行查询语句。")])])]),_._v(" "),t("p",[_._v("如果按照我们设定不允许过期读的要求，就只有两种选择，一种是超时放弃，一种是转到主库查询。具体怎么选择，就需要业务开发同学做好限流策略了。")]),_._v(" "),t("h2",{attrs:{id:"gtid方案"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#gtid方案"}},[_._v("#")]),_._v(" GTID方案")]),_._v(" "),t("p",[_._v("如果你的数据库开启了GTID模式，对应的也有等待GTID的方案。")]),_._v(" "),t("p",[t("code",[_._v("select wait_for_executed_gtid_set(gtid_set, 1);")])]),_._v(" "),t("p",[_._v("这条命令的逻辑是：")]),_._v(" "),t("ol",[t("li",[t("p",[_._v("等待，直到这个库执行的事务中包含传入的gtid_set，返回0；")])]),_._v(" "),t("li",[t("p",[_._v("超时返回1。")])])]),_._v(" "),t("p",[_._v("在前面等位点的方案中，我们执行完事务后，还要主动去主库执行show master status。而 MySQL 5.7.6版本开始，允许在执行完更新类事务后，把这个事务的GTID返回给客户端，这样等GTID的方案就可以减少一次查询。 这时，等GTID的执行流程就变成了：")]),_._v(" "),t("ol",[t("li",[t("p",[_._v("trx1事务更新完成后，从返回包直接获取这个事务的GTID，记为gtid1；")])]),_._v(" "),t("li",[t("p",[_._v("选定一个从库执行查询语句；")])]),_._v(" "),t("li",[t("p",[_._v("在从库上执行 select wait_for_executed_gtid_set(gtid1, 1)；")])]),_._v(" "),t("li",[t("p",[_._v("如果返回值是0，则在这个从库执行查询语句；")])]),_._v(" "),t("li",[t("p",[_._v("否则，到主库执行查询语句。")])])]),_._v(" "),t("p",[_._v("跟等主库位点的方案一样，等待超时后是否直接到主库查询，需要业务开发同学来做限流考虑。")]),_._v(" "),t("p",[_._v("在实际应用中，这几个方案是可以混合使用的。")]),_._v(" "),t("p",[_._v("比如，先在客户端对请求做分类，区分哪些请求可以接受过期读，而哪些请求完全不能接受过期读；然后，对于不能接受过期读的语句，再使用等GTID或等位点的方案。")]),_._v(" "),t("p",[_._v("但话说回来，过期读在本质上是由一写多读导致的。在实际应用中，可能会有别的不需要等待就可以水平扩展的数据库方案，但这往往是用牺牲写性能换来的，也就是需要在读性能和写性能中取权衡。")]),_._v(" "),t("p",[_._v("开源proxy：MariaDB MaxScale")]),_._v(" "),t("h1",{attrs:{id:"_40、innodb和memory引擎"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_40、innodb和memory引擎"}},[_._v("#")]),_._v(" 40、InnoDB和Memory引擎")]),_._v(" "),t("p",[_._v("InnoDB表的数据就放在主键索引树上，主键索引是B+树。")]),_._v(" "),t("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gvqhyxsi7ej60x40fgt9702.jpg",alt:"image-20211024164923563"}}),_._v(" "),t("p",[_._v("Memory引擎的数据和索引是分开的。")]),_._v(" "),t("p",[_._v("内存表的数据部分以数组的形式单独存放，而主键id索引里，存放的是每个数据的位置。"),t("strong",[_._v("主键id是hash索引")]),_._v("，索引上的key不是有序的。")]),_._v(" "),t("img",{staticStyle:{zoom:"67%"},attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gvqhzjei4tj614e0mwgmq02.jpg",alt:"image-20211024164956388"}}),_._v(" "),t("p",[_._v("可见，InnoDB和Memory引擎的数据组织方式是不同的：")]),_._v(" "),t("ul",[t("li",[t("p",[_._v("InnoDB引擎把数据放在主键索引上，其他索引上保存的是主键id。这种方式，我们称之为"),t("strong",[_._v("索引组织表")]),_._v(" （Index Organizied Table）。")])]),_._v(" "),t("li",[t("p",[_._v("而Memory引擎采用的是把数据单独存放，索引上保存数据位置的数据组织形式，我们称之 为"),t("strong",[_._v("堆组织表")]),_._v(" （Heap Organizied Table）。")])])]),_._v(" "),t("p",[_._v("这两个引擎的一些典型不同：")]),_._v(" "),t("ol",[t("li",[_._v("InnoDB表的数据总是有序存放的，而内存表的数据就是按照写入顺序存放的；")]),_._v(" "),t("li",[_._v("当数据文件有空洞的时候，InnoDB表在插入新数据的时候，为了保证数据有序性，只能在固定的位置写入新值，而内存表找到空位就可以插入新值；")]),_._v(" "),t("li",[_._v("数据位置发生变化的时候，InnoDB表只需要修改主键索引，而内存表需要修改所有索引；")]),_._v(" "),t("li",[_._v("InnoDB表用主键索引查询时需要走一次索引查找，用普通索引查询的时候，需要走两次索引查找。而内存表没有这个区别，所有索引的“地位”都是相同的。")]),_._v(" "),t("li",[_._v("InnoDB支持变长数据类型，不同记录的长度可能不同；内存表不支持Blob 和 Text字段，并且即使定义了varchar(N)，实际也当作char(N)，也就是固定长度字符串来存储，因此内存表的每行数据长度相同。")])]),_._v(" "),t("h2",{attrs:{id:"hash索引和b-tree索引"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hash索引和b-tree索引"}},[_._v("#")]),_._v(" hash索引和b-tree索引")]),_._v(" "),t("p",[_._v("实际上，内存表也是自持B-Tree索引的。")]),_._v(" "),t("p",[_._v("在我们的一般印象中，内存表的优势是速度快，其中一个原因就是Memory引擎支持hash索引。更重要的原因是，内存表的所有数据都保存在内存上，而内存的读写速度总是比磁盘快。")]),_._v(" "),t("p",[_._v("但不建议在生产环境上使用内存表，主要有2个原因：")]),_._v(" "),t("ol",[t("li",[_._v("锁粒度问题。\n"),t("ol",[t("li",[_._v("内存表不支持行锁，只支持表锁。")])])]),_._v(" "),t("li",[_._v("数据持久化问题")])]),_._v(" "),t("p",[_._v("建议把普通内存表都用InnoDB表代替。")]),_._v(" "),t("p",[_._v("例外的场景：内存临时表。内存表支持hash索引，这个特性利用起来，对复杂查询的加速效果还是很不错的。")]),_._v(" "),t("h1",{attrs:{id:"_40、insert语句的锁为什么这么多-初略总结"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_40、insert语句的锁为什么这么多-初略总结"}},[_._v("#")]),_._v(" 40、insert语句的锁为什么这么多？（初略总结）")]),_._v(" "),t("p",[_._v("MySQL对自增主键锁做了优化，尽量在申请到自增id以后，就释放自增锁。")]),_._v(" "),t("p",[_._v("普通情况下，insert语句是一个很轻量的操作。")]),_._v(" "),t("p",[_._v("特殊情况下，如：")]),_._v(" "),t("p",[_._v("insert …select 是很常见的在两个表之间拷贝数据的方法。你需要注意，在可重复读隔离级别下，这个语句会给select的表里扫描到的记录和间隙加读锁。 而如果insert和select的对象是同一个表，则有可能会造成循环写入。这种情况下，我们需要引入")]),_._v(" "),t("p",[_._v("用户临时表来做优化。")]),_._v(" "),t("p",[_._v("insert 语句如果出现唯一键冲突，会在冲突的唯一值上加共享的next-key lock(S锁)。因此，碰到")]),_._v(" "),t("p",[_._v("由于唯一键约束导致报错后，要尽快提交或回滚事务，避免加锁时间过长。")]),_._v(" "),t("h1",{attrs:{id:"_43、要不要使用分区表"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_43、要不要使用分区表"}},[_._v("#")]),_._v(" 43、要不要使用分区表？")]),_._v(" "),t("p",[_._v("分区表有什么问题，为什么很多公司规范不让使用分区表呢？")]),_._v(" "),t("p",[_._v("分区表的组织形式：")]),_._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("CREATE")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("TABLE")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("`")]),_._v("t"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("`")])]),_._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("\n\t"),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("`")]),_._v("ftime"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("`")])]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("datetime")]),_._v(" NOTNULL"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v("\n  "),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("`")]),_._v("c"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("`")])]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[_._v("11")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("DEFAULT")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[_._v("NULL")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("KEY")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),t("span",{pre:!0,attrs:{class:"token identifier"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("`")]),_._v("ftime"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("`")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("ENGINE")]),t("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("InnoDB")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("DEFAULT")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("CHARSET")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),_._v(" latin1\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("PARTITION")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("BY")]),_._v(" RANGE"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("YEAR")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),_._v("ftime"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("PARTITION")]),_._v(" p_2017 "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("VALUES")]),_._v(" LESS THAN "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[_._v("2017")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("ENGINE")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("InnoDB")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v("\n "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("PARTITION")]),_._v(" p_2018 "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("VALUES")]),_._v(" LESS THAN "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[_._v("2018")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("ENGINE")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("InnoDB")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v("\n "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("PARTITION")]),_._v(" p_2019 "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("VALUES")]),_._v(" LESS THAN "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[_._v("2019")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("ENGINE")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("InnoDB")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),_._v("\n "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("PARTITION")]),_._v(" p_others "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("VALUES")]),_._v(" LESS THAN MAXVALUE "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("ENGINE")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[_._v("=")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("InnoDB")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(";")]),_._v("\n \n "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("insert")]),_._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("into")]),_._v(" t "),t("span",{pre:!0,attrs:{class:"token keyword"}},[_._v("value")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[_._v("'2017-4-1'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[_._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[_._v("'2018-4-1'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[_._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[_._v(";")]),_._v(" \n")])])]),t("p",[_._v("在表t中初始化插入了两行记录，按照定义的分区规则，这两行记录分别落在p_2018和p_2019 这两个分区上。")]),_._v(" "),t("p",[_._v("这个表包含了一个.frm文件和4个.ibd文件，每个分区对应一个.ibd文件。也就是说：")]),_._v(" "),t("ul",[t("li",[_._v("对于引擎层来说，这是4个表；")]),_._v(" "),t("li",[_._v("对于Server层来说，这是1个表。")])]),_._v(" "),t("p",[_._v("我们使用分区表的一个重要原因就是单表过大。那么，如果不使用分区表的话，我们就是要使用手动分表的方式。")]),_._v(" "),t("p",[_._v("分区表和手工分表，一个是由server层来决定使用哪个分区，一个是由应用层代码来决定使用哪 个分表。因此，从引擎层看，这两种方式也是没有差别的。")]),_._v(" "),t("p",[_._v("其实这两个方案的区别，主要是在server层上。从server层看，我们就不得不提到分区表一个被广为诟病的问题：打开表的行为。")]),_._v(" "),t("ol",[t("li",[t("p",[_._v("MySQL在第一次打开分区表的时候，需要访问所有的分区；")])]),_._v(" "),t("li",[t("p",[_._v("在server层，认为这是同一张表，因此所有分区共用同一个MDL锁；")])]),_._v(" "),t("li",[t("p",[_._v("在引擎层，认为这是不同的表，因此MDL锁之后的执行过程，会根据分区表规则，只访问必要的分区。")])])]),_._v(" "),t("h2",{attrs:{id:"分区表的应用场景"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#分区表的应用场景"}},[_._v("#")]),_._v(" 分区表的应用场景")]),_._v(" "),t("p",[_._v("分区表的一个显而易见的优势是对业务透明，相对于用户分表来说，使用分区表的业务代码更简洁。还有，分区表可以很方便的清理历史数据。")]),_._v(" "),t("p",[_._v("如果一项业务跑的时间足够长，往往就会有根据时间删除历史数据的需求。这时候，按照时间分区的分区表，就可以直接通过"),t("strong",[_._v("alter table t drop partition")]),_._v("这个语法删掉分区，从而删掉过期的历史数据。")]),_._v(" "),t("p",[_._v("这个alter table t drop partition …操作是直接删除分区文件，效果跟drop普通表类似。与使用delete语句删除数据相比，优势是速度快、对系统影响小。")]),_._v(" "),t("p",[_._v("我们以范围分区（range）为例和你介绍的。实际上，MySQL还支持hash分区、 list分区等分区方法。你可以在需要用到的时候，再翻翻"),t("a",{attrs:{href:"https://dev.mysql.com/doc/refman/8.0/en/partitioning-types.html",target:"_blank",rel:"noopener noreferrer"}},[_._v("手册"),t("OutboundLink")],1),_._v("。")]),_._v(" "),t("p",[_._v("实际使用时，分区表跟用户分表比起来，有两个绕不开的问题：一个是第一次访问的时候需要访问所有分区，另一个是共用MDL锁。")]),_._v(" "),t("p",[_._v("因此，如果要使用分区表，就不要创建太多的分区。我见过一个用户做了按天分区策略，然后预先创建了10年的分区。这种情况下，访问分区表的性能自然是不好的。这里有两个问题需要注意：")]),_._v(" "),t("ol",[t("li",[t("p",[_._v("分区并不是越细越好。实际上，单表或者单分区的数据"),t("strong",[_._v("一千万行")]),_._v("，只要没有特别大的索引， 对于现在的硬件能力来说都已经是小表了。")])]),_._v(" "),t("li",[t("p",[t("strong",[_._v("分区也不要提前预留太多")]),_._v("，在使用之前预先创建即可。比如，如果是按月分区，每年年底时再把下一年度的12个新分区创建上即可。对于没有数据的历史分区，要"),t("strong",[_._v("及时的drop掉")]),_._v("。")])])]),_._v(" "),t("p",[_._v("至于分区表的其他问题，比如查询需要跨多个分区取数据，查询性能就会比较慢，基本上就不是分区表本身的问题，而是数据量的问题或者说是使用方式的问题了。")]),_._v(" "),t("p",[_._v("当然，如果你的团队已经维护了成熟的分库分表中间件，用业务分表，对业务开发同学没有额外的复杂性，对DBA也更直观，自然是更好的。")])])}),[],!1,null,null,null);t.default=a.exports}}]);