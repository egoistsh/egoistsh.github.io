[{"categories":["技术笔记"],"content":"编译器和解释器 类型1：C、C++ 类型2：JavaScript、Python、PHP 类型3：Java 对于类型1，我们一般称为编译型语言，也就是需要用到编译器进行编译。 对于类型2，我们一般称为解释型语言，或是脚本语言，也就是要用解释器进行解释。 编译器与解释器就类似于笔译工作者与口译工作者的区别，编译器就是笔译工作者，而解释器就是口译工作者。 编译器在编译的过程中，读入源程序文件，输出一份等价的二进制可执行文件，就和笔译工作者一样，他们都会输出一份翻译后的文件。 解释器在解释的过程中，读入源程序文件，输出的是执行的结果，就和口译工作者一样，他们输出的是已经完成翻译的结果。 解释器： 优点：跨平台、启动速度快、开发效率高 缺点：执行速度慢，执行效率低 编译器： 优点：执行速度快、执行效率高 缺点：平台相关性高，编译速度（启动速度）慢，开发效率低 Java既有编译器（不止一个）又有解释器。 Java中编译器比较多，它包含一个前端编译器，一个后端编译器（JIT）以及一个静态预编译器（AOT）。 前端编译器的功能是从源代码生成Java字节码，也就是中间代码； 后端编译器，也叫作即时编译器（JIT）它是包含在了JVM中，用于在执行的过程中，将热点代码（也就是执行次数比较多的代码）转化为本地机器码，并做一些优化，以加速执行效率。 静态预编译器（AOT）它是直接将java源代码编译成本地机器码，也就是传统意义上的编译器，但用的不多，因为这样会使java的一些特性丢失。 Java中的解释器与JIT一起打包，作为JVM中的执行引擎，解释器主要将字节码进行解释执行，同时配合JIT进行代码的优化操作。 java解释器就是把在java虚拟机上运行的目标代码（字节码）解释成为具体平台的机器码的程序。即jdk或jre目录下bin目录中的java.exe文件，而javac.exe是编译器。 运行java程序的过程是先用javac编译，然后用java解释。而一经编译成功后，就可以直接用java.exe随处解释运行了。 JVM负责运行字节码：JVM把每一条要执行的字节码交给解释器，翻译成对应的机器码，然后由解释器执行。JVM解释执行字节码文件就是JVM操作Java解释器进行解释执行字节码文件的过程。 Java内存区域 Java把控制内存的权利交给了Java 虚拟机，一旦出现内存泄漏和溢出方面的问题，如果不了解虚拟机是怎样使用内存的，那排查错误、修正问题将成为一项艰难的工作。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:1:0","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"运行时数据区 《Java虚拟机规范》 ：“概念模型”这个词会经常被提及， 它代表了所有虚拟机的统一外观， 但各款具体的Java虚拟机并不 一定要完全照着概念模型的定义来进行设计， 可能会通过一些更高效率的等价方式去实现它。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:2:0","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"程序计数器 当前线程所执行的字节码的行号。字节码解释器就是通过改变这个计数器的值来选取下一条需要执行的字节码指令。 程序计数器主要有两个作用： 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。 注意：程序计数器是唯一一个不会出现 OutOfMemoryError 的内存区域，它的生命周期随着线程的创建而创建，随着线程的结束而死亡。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:2:1","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"Java虚拟机栈 描述的是Java方法执行的线程内存模型，每个方法被执行时，Java虚拟机都会同步创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态连接、方法出口等信息。每个方法从被调用到执行完毕的过程，就对应这一个栈帧在虚拟机栈的入栈和出栈过程。 局部变量表主要存放了编译期可知的各种数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference 类型，它不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）。 Java 虚拟机栈会出现两种错误：StackOverFlowError 和 OutOfMemoryError。 StackOverFlowError： 若 Java 虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 StackOverFlowError 错误。 OutOfMemoryError： Java 虚拟机栈的内存大小可以动态扩展， 如果虚拟机在动态扩展栈时无法申请到足够的内存空间，则抛出OutOfMemoryError异常。 HotSpot虚拟机的栈容量是不可以动态扩展的， 以前的Classic虚拟机倒是可以。 所以在HotSpot虚拟机上是不会由于虚拟机栈无法扩展而导致OutOfMemoryError异常——只要线程申请栈空间成功了就不会有OOM， 但是如果申请时就失败， 仍然是会出现OOM异常的。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:2:2","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"本地方法栈 本地方法栈（Native Method Stacks） 与虚拟机栈所发挥的作用是非常相似的， 其区别只是虚拟机栈为虚拟机执行Java方法（也就是字节码） 服务， 而本地方法栈则是为虚拟机使用到的本地（Native）方法服务。 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:2:3","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"堆 Java 虚拟机所管理的内存中最大的一块，Java 堆是所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。 Java 世界中“几乎”所有的对象都在堆中分配，但是，随着 JIT 编译器的发展与逃逸分析技术逐渐成熟，栈上分配、标量替换优化技术将会导致一些微妙的变化，所有的对象都分配到堆上也渐渐变得不那么“绝对”了。从 JDK 1.7 开始已经默认开启逃逸分析，如果某些方法中的对象引用没有被返回或者未被外面使用（也就是未逃逸出去），那么对象可以直接在栈上分配内存。 Java 堆是垃圾收集器管理的主要区域，因此也被称作GC 堆（Garbage Collected Heap）。从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以 Java 堆还可以细分为：新生代和老年代；再细致一点有：Eden 空间、From Survivor、To Survivor 空间等。进一步划分的目的是更好地回收内存，或者更快地分配内存。 从回收内存的角度看， 由于现代垃圾收集器大部分都是基于分代收集理论设计的， 所以Java堆中经常会出现“新生代”“老年代”“永久代”“Eden空间”“From Survivor空间”“To Survivor空间”等名词， 这些区域划分仅仅是一部分垃圾收集器的共同特性或者说设计风格而已， 而非某个Java虚拟机具体实现的固有内存布局， 更不是《Java虚拟机规范》 里对Java堆的进一步细致划分。 不少资料上经常写着类似于“Java虚拟机的堆内存分为新生代、 老年代、 永久代、 Eden、 Survivor……”这样的内容。 在十年之前（以G1收集器的出现为分界） ， 作为业界绝对主流的HotSpot虚拟机， 它内部的垃圾收集器全部都基于“经典分代”[3]来设计， 需要新生代、 老年代收集器搭配才能工作， 但现在不可同日而语，也出现了不采用分代设计的垃圾回收器。 在 JDK 7 版本及 JDK 7 版本之前，堆内存被通常分为下面三部分： 新生代内存(Young Generation) 老生代(Old Generation) 永生代(Permanent Generation) JDK 8 版本之后方法区（HotSpot 的永久代）被彻底移除了（JDK1.7 就已经开始了），取而代之是元空间，元空间使用的是直接内存。 上图所示的 Eden 区、两个 Survivor 区都属于新生代（为了区分，这两个 Survivor 区域按照顺序被命名为 from 和 to），中间一层属于老年代。 大部分情况，对象都会首先在 Eden 区域分配，在一次新生代垃圾回收后，如果对象还存活，则会进入 s0 或者 s1，并且对象的年龄还会加 1(Eden 区-\u003eSurvivor 区后对象的初始年龄变为 1)，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。 Hotspot 遍历所有对象时，按照年龄从小到大对其所占用的大小进行累积，当累积的某个年龄大小超过了 survivor 区的一半时，取这个年龄和 MaxTenuringThreshold 中更小的一个值，作为新的晋升年龄阈值。 堆这里最容易出现的就是 OutOfMemoryError 错误，并且出现这种错误之后的表现形式还会有几种，比如： java.lang.OutOfMemoryError: GC Overhead Limit Exceeded ： 当 JVM 花太多时间执行垃圾回收并且只能回收很少的堆空间时，就会发生此错误。 java.lang.OutOfMemoryError: Java heap space :假如在创建新的对象时, 堆内存中的空间不足以存放新创建的对象, 就会引发此错误。(和配置的最大堆内存有关，且受制于物理内存大小。最大堆内存可通过-Xmx参数配置，-Xms设置初始堆内存，若没有特别配置，将会使用默认值，详见：Default Java 8 max heap size (opens new window)) ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:2:4","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"方法区 方法区与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然 Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做 Non-Heap（非堆），目的应该是与 Java 堆区分开来。 说到方法区， 不得不提一下“永久代”这个概念， 尤其是在JDK 8以前， 许多Java程序员都习惯在HotSpot虚拟机上开发、 部署程序， 很多人都更愿意把方法区称呼为“永久代”（Permanent Generation） ， 或将两者混为一谈。 本质上这两者并不是等价的， 因为仅仅是当时的HotSpot虚拟机设计团队选择把收集器的分代设计扩展至方法区， 或者说使用永久代来实现方法区而已， 这样使得HotSpot的垃圾收集器能够像管理Java堆一样管理这部分内存， 省去专门为方法区编写内存管理代码的工作。 但是对于其他虚拟机实现， 譬如BEA JRockit、 IBM J9等来说， 是不存在永久代的概念的。 原则上如何实现方法区属于虚拟机实现细节， 不受《Java虚拟机规范》 管束， 并不要求统一。 但现在回头来看， 当年使用永久代来实现方法区的决定并不是一个好主意， 这种设计导致了Java应用更容易遇到内存溢出的问题（永久代有-XX： MaxPermSize的上限， 即使不设置也有默认大小， 而J9和JRockit只要没有触碰到进程可用内存的上限， 例如32位系统中的4GB限制， 就不会出问题） ， 而且有极少数方法（例如String::intern()） 会因永久代的原因而导致不同虚拟机下有不同的表现。 当Oracle收购BEA获得了JRockit的所有权后， 准备把JRockit中的优秀功能， 譬如Java Mission Control管理工具， 移植到HotSpot虚拟机时， 但因为两者对方法区实现的差异而面临诸多困难。 考虑到HotSpot未来的发展， 在JDK 6的时候HotSpot开发团队就有放弃永久代， 逐步改为采用本地内存（Native Memory） 来实现方法区的计划了[1]， 到了JDK 7的HotSpot， 已经把原本放在永久代的字符串常量池、 静态变量等移出， 而到了JDK 8， 终于完全废弃了永久代的概念， 改用与JRockit、 J9一样在本地内存中实现的元空间（Metaspace） 来代替， 把JDK 7中永久代还剩余的内容（主要是类型信息） 全部移到元空间中。 //JDK 1.8 之前永久代还没被彻底移除的时候通常通过下面这些参数来调节方法区大小 -XX:PermSize=N //方法区 (永久代) 初始大小 -XX:MaxPermSize=N //方法区 (永久代) 最大大小,超过这个值将会抛出 OutOfMemoryError 异常:java.lang.OutOfMemoryError: PermGen JDK 1.8 的时候，方法区（HotSpot 的永久代）被彻底移除了（JDK1.7 就已经开始了），取而代之是元空间，元空间使用的是直接内存。 //一些常用参数： -XX:MetaspaceSize=N //设置 Metaspace 的初始（和最小大小） -XX:MaxMetaspaceSize=N //设置 Metaspace 的最大大小 与永久代很大的不同就是，如果不指定大小的话，随着更多类的创建，虚拟机会耗尽所有可用的系统内存。 运行时常量池是方法区的一部分。Class 文件中除了有类的版本、字段、方法、接口等描述信息外，还有常量池表（用于存放编译期生成的各种字面量和符号引用）。既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 错误。 JDK1.7 之前运行时常量池逻辑包含字符串常量池存放在方法区, 此时 hotspot 虚拟机对方法区的实现为永久代。 JDK1.7字符串常量池被从方法区拿到了堆中, 这里没有提到运行时常量池,也就是说字符串常量池被单独拿到堆,运行时常量池剩下的东西还在方法区, 也就是 hotspot 中的永久代。 JDK1.8 hotspot 移除了永久代用元空间(Metaspace)取而代之, 这时候字符串常量池还在堆, 运行时常量池还在方法区, 只不过方法区的实现从永久代变成了元空间(Metaspace)。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:2:5","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"直接内存 直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用。而且也可能导致 OutOfMemoryError 错误出现。 JDK1.4 中新加入的 NIO(New Input/Output) 类，引入了一种基于通道（Channel）与缓存区（Buffer）的 I/O 方式，它可以直接使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样就能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆之间来回复制数据。 本机直接内存的分配不会受到 Java 堆的限制，但是，既然是内存就会受到本机总内存大小以及处理器寻址空间的限制。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:2:6","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"Hotspot虚拟机对象探秘 基于实用优先的原则， 以最常用的虚拟机HotSpot和最常用的内存区域Java堆为例， 深入探讨一下HotSpot虚拟机在Java堆中对象分配、 布局和访问的全过程。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:3:0","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"对象的创建 类加载检查：虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。 分配内存： 分配方式：有“指针碰撞”和“空闲列表”两种，取决于Java堆是否规整，这又由垃圾回收器是否带有压缩整理功能决定。 虚拟机保证线程安全： CAS+失败重试： CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。 TLAB（本地线程分配缓存）： 为每一个线程预先在 Eden 区分配一块儿内存，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配。 初始化零值 设置对象头：例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的 GC 分代年龄等信息。 这些信息存放在对象头中。 另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。 执行init方法 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:3:1","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"对象的内存布局 在HotSpot虚拟机中，对象在堆内存中的存储布局可以分为三个部分：对象头、实例数据和对齐填充。 Hotspot 虚拟机的对象头包括两部分信息，第一部分用于存储对象自身的运行时数据（哈希码、GC 分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等等），官方称为“Mark Word”。另一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是那个类的实例。 实例数据部分是对象真正存储的有效信息，也是在程序中所定义的各种类型的字段内容。 对齐填充部分不是必然存在的，也没有什么特别的含义，仅仅起占位作用。 因为 Hotspot 虚拟机的自动内存管理系统要求对象起始地址必须是 8 字节的整数倍，换句话说就是对象的大小必须是 8 字节的整数倍。而对象头部分正好是 8 字节的倍数（1 倍或 2 倍），因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:3:2","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"对象的访问定位 Java程序会通过栈上reference数据来操作堆上的具体对象。 对象的访问方式由虚拟机的实现决定：主流的访问方式主要有使用句柄和直接指针两种。 这两种对象访问方式各有优势。使用句柄来访问的最大好处是 reference 中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，而 reference 本身不需要修改。使用直接指针访问方式最大的好处就是速度快，它节省了一次指针定位的时间开销。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:3:3","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"字符串问题 直接使用双引号声明出来的String对象会直接存储在常量池中。 如果不是用双引号声明的String对象，可以使用String提供的intern方法。intern 方法会从字符串常量池中查询当前字符串是否存在，若不存在就会将当前字符串放入常量池中。 （String.intern() 是一个 Native 方法，它的作用是：如果运行时常量池中已经包含一个等于此 String 对象内容的字符串，则返回常量池中该字符串的引用；如果没有，JDK1.7 之前（不包含 1.7）的处理方式是在常量池中创建与此 String 内容相同的字符串，并返回常量池中创建的字符串的引用，JDK1.7 以及之后，字符串常量池被从方法区拿到了堆中，jvm 不会在常量池中创建该对象，而是将堆中这个对象的引用直接放到常量池中，减少不必要的内存开销。） 对于基本数据类型来说，比较的是值。对于引用数据类型来说，比较的是对象的内存地址。 在编译过程中，Javac 编译器会进行一个叫做 常量折叠(Constant Folding) 的代码优化。常量折叠会把常量表达式的值求出来作为常量嵌在最终生成的代码中，这是 Javac 编译器会对源代码做的极少量优化措施之一(代码优化几乎都在即时编译器中进行)。 一般来说，我们要尽量避免通过 new 的方式创建字符串。使用双引号声明的 String 对象（ String s1 = \"java\" ）更利于让编译器有机会优化我们的代码，同时也更易于阅读。 被 final 关键字修改之后的 String 会被编译器当做常量来处理，编译器程序编译期就可以确定它的值，其效果就想到于访问常量。 String s1 = new String(“abc”);这句话创建了几个字符串对象？ 会创建 1 或 2 个字符串： 如果字符串常量池中已存在字符串常量“abc”，则只会在堆空间创建一个字符串常量“abc”。 如果字符串常量池中没有字符串常量“abc”，那么它将首先在字符串常量池中创建，然后在堆空间中创建，因此将创建总共 2 个字符串对象。 Java 基本类型的包装类的大部分都实现了常量池技术。 Byte,Short,Integer,Long 这 4 种包装类默认创建了数值 [-128，127] 的相应类型的缓存数据，Character 创建了数值在 [0,127] 范围的缓存数据，Boolean 直接返回 True Or False。 两种浮点数类型的包装类 Float,Double 并没有实现常量池技术。 记住：所有整型包装类对象之间值的比较，全部使用 equals 方法比较。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:3:4","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"OutOfMemoryError异常 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:4:0","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"Java堆溢出 将堆的最小值-Xms参数与最大值-Xmx参数设置为一样的话可避免堆自动扩展，即设置为不可扩展。 要解决这个内存区域的异常， 常规的处理方法是首先通过内存映像分析工具（如Eclipse Memory Analyzer） 对Dump出来的堆转储快照进行分析。 第一步首先应确认内存中导致OOM的对象是否是必要的， 也就是要先分清楚到底是出现了内存泄漏（Memory Leak） 还是内存溢出（Memory Overflow） 。 如果是内存泄漏， 可进一步通过工具查看泄漏对象到GC Roots的引用链， 找到泄漏对象是通过怎样的引用路径、 与哪些GC Roots相关联， 才导致垃圾收集器无法回收它们， 根据泄漏对象的类型信息以及它到GC Roots引用链的信息， 一般可以比较准确地定位到这些对象创建的位置， 进而找出产生内存泄漏的代码的具体位置。 如果不是内存泄漏， 换句话说就是内存中的对象确实都是必须存活的， 那就应当检查Java虚拟机的堆参数（-Xmx与-Xms） 设置， 与机器的内存对比， 看看是否还有向上调整的空间。 再从代码上检查是否存在某些对象生命周期过长、 持有状态时间过长、 存储结构设计不合理等情况， 尽量减少程序运行期的内存消耗。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:4:1","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"虚拟机栈或本地方法栈溢出 由于HotSpot虚拟机并不区分虚拟机栈和本地方法栈，所以栈容量只由 -Xss参数决定。 关于虚拟机栈和本地方法栈， 在《Java虚拟机规范》 中描述了两种异常： 如果线程请求的栈深度大于虚拟机所允许的最大深度， 将抛出StackOverflowError异常。 如果虚拟机的栈内存允许动态扩展， 当扩展栈容量无法申请到足够的内存时， 将抛出OutOfMemoryError异常。 《Java虚拟机规范》 明确允许Java虚拟机实现自行选择是否支持栈的动态扩展， 而HotSpot虚拟机的选择是不支持扩展， 所以除非在创建线程申请内存时就因无法获得足够内存而出现OutOfMemoryError异常， 否则在线程运行时是不会因为扩展而导致内存溢出的， 只会因为栈容量无法容纳新的栈帧而导致StackOverflowError异常。 出现StackOverflowError异常时， 会有明确错误堆栈可供分析， 相对而言比较容易定位到问题所在。 如果使用HotSpot虚拟机默认参数， 栈深度在大多数情况下（因为每个方法压入栈的帧大小并不是一样的， 所以只能说大多数情况下） 到达1000~2000是完全没有问题， 对于正常的方法调用（包括不能做尾递归优化的递归调用） ，这个深度应该完全够用了。 但是， 如果是建立过多线程导致的内存溢出， 在不能减少线程数量或者更换64位虚拟机的情况下， 就只能通过减少最大堆和减少栈容量来换取更多的线程。 这种通过“减少内存”的手段来解决内存溢出的方式， 如果没有这方面处理经验， 一般比较难以想到， 这一点读者需要在开发32位系统的多线程应用时注意。 也是由于这种问题较为隐蔽， 从JDK 7起， 以上提示信息中“unable to create native thread”后面， 虚拟机会特别注明原因可能是“possiblyout of memory or process/resource limits reached”。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:4:2","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"方法区和运行时常量池溢出 以下面的例子为例： String::intern()是一个本地方法， 它的作用是如果字符串常量池中已经包含一个等于此String对象的字符串， 则返回代表池中这个字符串的String对象的引用； 否则， 会将此String对象包含的字符串添加到常量池中， 并且返回此String对象的引用。 自JDK 7起， 原本存放在永久代的字符串常量池被移至Java堆之中。 当前的很多主流框架， 如Spring、 Hibernate对类进行增强时， 都会使用到CGLib这类字节码技术， 当增强的类越多， 就需要越大的方法区以保证动态生成的新类型可以载入内存。 方法区溢出也是一种常见的内存溢出异常， 一个类如果要被垃圾收集器回收， 要达成的条件是比较苛刻的。 在JDK 8以后， 永久代便完全退出了历史舞台， 元空间作为其替代者登场。 在默认设置下， 正常的动态创建新类型已经很难再迫使虚拟机产生方法区的溢出异常了。 不过为了让使用者有预防实际应用里出现的破坏性的操作， HotSpot还是提供了一些参数作为元空间的防御措施， 主要包括： -XX：MaxMetaspaceSize： 设置元空间最大值， 默认是-1， 即不限制， 或者说只受限于本地内存大小。 -XX：MetaspaceSize： 指定元空间的初始空间大小， 以字节为单位， 达到该值就会触发垃圾收集进行类型卸载， 同时收集器会对该值进行调整： 如果释放了大量的空间， 就适当降低该值； 如果释放了很少的空间， 那么在不超过-XX： MaxMetaspaceSize（如果设置了的话） 的情况下， 适当提高该值。 -XX：MinMetaspaceFreeRatio： 作用是在垃圾收集之后控制最小的元空间剩余容量的百分比， 可减少因为元空间不足导致的垃圾收集的频率。 类似的还有-XX： Max-MetaspaceFreeRatio， 用于控制最大的元空间剩余容量的百分比。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:4:3","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"本机直接内存溢出 直接内存（Direct Memory） 的容量大小可通过-XX： MaxDirectMemorySize参数来指定， 如果不去指定， 则默认与Java堆最大值（由-Xmx指定） 一致。 由直接内存导致的内存溢出， 一个明显的特征是在Heap Dump文件中不会看见有什么明显的异常情况， 如果读者发现内存溢出之后产生的Dump文件很小， 而程序中又直接或间接使用了DirectMemory（典型的间接使用就是NIO） ， 那就可以考虑重点检查一下直接内存方面的原因了。 JVM垃圾回收 问题： 内存是如何分配和回收的？ 哪些内存需要回收？ 什么时候回收？ 如何回收？ parNew 和parallel scavenge 的区别是？ ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:4:4","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"垃圾回收算法 标记-清除 Mark-Sweep 标记-复制：常用于新生代 标记-整理 Mark-Compact 分代回收：只是根据对象存活周期的不同将内存分为几块。一般将 java 堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:5:0","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"并行和并发 并行（Parallel） ：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行，可能会交替执行），用户程序在继续运行，而垃圾收集器运行在另一个 CPU 上。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:6:0","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"垃圾回收器图解 Serial 是单线程的收集器 ParNew 收集器实质上是Serial收集器的多线程并行版本。除了同时使用多条线程进行垃圾收集之外， 其余的行为包括Serial收集器可用的所有控制参数（例如： -XX： SurvivorRatio、 -XX：PretenureSizeThreshold、 -XX： HandlePromotionFailure等） 、 收集算法、 Stop The World、 对象分配规则、 回收策略等都与Serial收集器完全一致， 在实现上这两种收集器也共用了相当多的代码。 ParNew收集器除了支持多线程并行收集之外， 其他与Serial收集器相比并没有太多创新之处。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:7:0","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"垃圾回收器分类 经典垃圾回收器 新生代 Serial：新生代采用标记-复制算法，老年代采用标记-整理算法。 ParNew：serial的多线程版 Parallel Scavenge：新生代采用标记-复制算法，老年代采用标记-整理算法。 Parallel Scavenge 收集器关注点是吞吐量（高效率的利用 CPU）。CMS 等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是 CPU 中用于运行用户代码的时间与 CPU 总消耗时间的比值。 Parallel Scavenge 收集器提供了很多参数供用户找到最合适的停顿时间或最大吞吐量，如果对于收集器运作不太了解，手工优化存在困难的时候，使用 Parallel Scavenge 收集器配合自适应调节策略，把内存管理优化交给虚拟机去完成也是一个不错的选择。 老年代： Serial Old Parallel Old：多线程+标记整理 CMS：Concurrent Mark Sweep，采用标记-清除算法。目标最短回收停顿时间。 G1：面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足 GC 停顿时间要求的同时,还具备高吞吐量性能特征.（低停顿+高吞吐）。G1 从整体来看是基于“标记-整理”算法实现的收集器；从局部上来看是基于“标记-复制”算法实现的。 G1 收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的 Region(这也就是它的名字 Garbage-First 的由来) 。 低延迟垃圾回收器 ZGC：基于Region 内存布局，不设分代，使用了读屏障、染色指针和内存多重映射等技术实现可并发的标记-整理算法，以低延迟为首要目标。 Shenandoah CMS缺点： 对 CPU 资源敏感； 无法处理浮动垃圾； 它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。 Shenandoah与G1的3个明显不同： 支持并发的整理算法（最重要）。G1的回收阶段是可以多线程并行的，但不能与用户线程并发。 目前默认不使用分代回收 摒弃G1中耗费大量内存和计算资源去维护的记忆集，使用“连接矩阵”的全局数据结构来记录跨Region的引用关系。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:8:0","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"默认垃圾回收器： JDK8 默认使用的是 Parallel Scavenge + Parallel Old。但一般不用这个。常用ParNew+CMS吧（因为是唯一搭配呀） JDK9~16 默认G1 在JVM中是+XX配置实现的搭配组合： -XX:+UseSerialGC，虚拟机运行在Client模式下的默认值，Serial+Serial Old。 -XX:+UseParNewGC，ParNew+Serial Old，在JDK1.8被废弃，在JDK1.7还可以使用。 -XX:+UseConcMarkSweepGC，ParNew+CMS+Serial Old。 -XX:+UseParallelGC，虚拟机运行在Server模式下的默认值，Parallel Scavenge+Serial Old(PS Mark Sweep)。 -XX:+UseParallelOldGC，Parallel Scavenge+Parallel Old。 -XX:+UseG1GC，G1+G1。 堆内存常见分配策略： 对象优先分配在eden区 大对象直接分配到老年代。大对象就是需要大量连续内存空间的对象（比如：字符串、数组）。 长期存活的对象进入老年代 空间分配担保：目的是确保Minor GC之前老年代有足够空间容纳新生代所有对象 JDK 6 Update 24 之前，在发生 Minor GC 之前，虚拟机必须先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果这个条件成立，那这一次 Minor GC 可以确保是安全的。如果不成立，则虚拟机会先查看 -XX:HandlePromotionFailure 参数的设置值是否允许担保失败(Handle Promotion Failure);如果允许，那会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试进行一次 Minor GC，尽管这次 Minor GC 是有风险的;如果小于，或者 -XX: HandlePromotionFailure 设置不允许冒险，那这时就要改为进行一次 Full GC。 JDK 6 Update 24之后的规则变为只要老年代的连续空间大于新生代对象总大小或者历次晋升的平均大小，就会进行 Minor GC，否则将进行 Full GC。 动态对象年龄判定：Hotspot 遍历所有对象时，按照年龄从小到大对其所占用的大小进行累积，当累积的某个年龄大小超过了 survivor 区的 50% 时（默认值是 50%，可以通过 -XX:TargetSurvivorRatio=percent 来设置 ），取这个年龄和 MaxTenuringThreshold（默认15岁） 中更小的一个值，作为新的晋升年龄阈值”。 GC分类 Partial GC: Minor GC/Young GC Major GC/Old GC Mixed GC：对整个新生代和老年代进行垃圾回收 Full GC：收集整个Java堆和方法区 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:9:0","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"如何判断一个对象已经无效？ 引用计数法 实现简单，效率高，但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它很难解决对象之间相互循环引用的问题。 可达性分析法 通过一系列的称为 “GC Roots” 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:10:0","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"可作为GC Roots的对象 虚拟机栈（栈帧中的本地变量表）中引用的对象 本地方法栈（Native方法）中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 所有被同步锁持有的对象 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:11:0","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"引用 JDK1.2 之前，Java 中引用的定义很传统：如果 reference 类型的数据存储的数值代表的是另一块内存的起始地址，就称这块内存代表一个引用。 JDK1.2 以后，Java 对引用的概念进行了扩充，将引用分为强引用、软引用、弱引用、虚引用四种（引用强度逐渐减弱） 强引用（StrongReference） 以前我们使用的大部分引用实际上都是强引用，这是使用最普遍的引用。如果一个对象具有强引用，那就类似于必不可少的生活用品，垃圾回收器绝不会回收它。当内存空间不足，Java 虚拟机宁愿抛出 OutOfMemoryError 错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足问题。 软引用（SoftReference） 如果一个对象只具有软引用，那就类似于可有可无的生活用品。**如果内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存。**只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。 软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收，JAVA 虚拟机就会把这个软引用加入到与之关联的引用队列中。 弱引用（WeakReference） 如果一个对象只具有弱引用，那就类似于可有可无的生活用品。弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。 弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java 虚拟机就会把这个弱引用加入到与之关联的引用队列中。 虚引用（PhantomReference） “虚引用\"顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收。 虚引用主要用来跟踪对象被垃圾回收的活动。 虚引用与软引用和弱引用的一个区别在于： 虚引用必须和引用队列（ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。程序如果发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。 特别注意，在程序设计中一般很少使用弱引用与虚引用，使用软引用的情况较多，这是因为软引用可以加速 JVM 对垃圾内存的回收速度，可以维护系统的运行安全，防止内存溢出（OutOfMemory）等问题的产生。 你会使用软引用和弱引用吗？软引用和弱引用的例子不错。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:12:0","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"常量池的位置 JDK1.7 之前运行时常量池逻辑包含字符串常量池存放在方法区, 此时 hotspot 虚拟机对方法区的实现为永久代。 JDK1.7 字符串常量池被从方法区拿到了堆中, 这里没有提到运行时常量池,也就是说字符串常量池被单独拿到堆,运行时常量池剩下的东西还在方法区, 也就是 hotspot 中的永久代 。 JDK1.8 hotspot 移除了永久代用元空间(Metaspace)取而代之, 这时候字符串常量池还在堆, 运行时常量池还在方法区, 只不过方法区的实现从永久代变成了元空间(Metaspace) 假如在字符串常量池中存在字符串 “abc”，如果当前没有任何 String 对象引用该字符串常量的话，就说明常量 “abc” 就是废弃常量，如果这时发生内存回收的话而且有必要的话，“abc” 就会被系统清理出常量池了。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:13:0","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"如何判断一个类是无用的类 方法区主要回收的是无用的类，那么如何判断一个类是无用的类的呢？ 判定一个常量是否是“废弃常量”比较简单，而要判定一个类是否是“无用的类”的条件则相对苛刻许多。类需要同时满足下面 3 个条件才能算是 “无用的类” ： 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。 加载该类的 ClassLoader 已经被回收。 该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 虚拟机可以对满足上述 3 个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样不使用了就会必然被回收。 虚拟机性能监控、故障处理工具 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:14:0","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"6个常用的命令行工具： 工具 功能 jps 虚拟机进程状况工具。可列出正在运行的虚拟机进程，并现实虚拟机执行主类。 jstat 虚拟机统计信息监视工具。虚拟机信息主要有3类：类加载、垃圾收集、运行期编译状况 jinfo Java配置信息工具。实时查看和调整虚拟机各项参数。 jmap Java内存映像工具。用于生成堆转储快照（heap dump或dump文件）。 jhat 虚拟机堆转储快照分析工具。搭配jmap使用，分析jmap生成的堆转储快照。一般不用，用VisualVM或其他。 jstack Java堆栈跟踪工具。用于生成虚拟机当前时刻的线程快照（threaddump或javacore文件）。线程快照就是当前虚拟机内每一条线程正在执行的方法的堆栈的集合。 其他工具： 工具 功能 java 用于运行class文件或jar文件 javac 编译器，将.java文件编译成.class javap 用于分析字节码。反编译得到字节码指令。也可用其他工具将class文件转换成特定平台上的汇编代码。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:15:0","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"4个常用的可视化工具： 可视化工具 功能 JHSDB 基于服务性代理的调试工具 JConsole Java监视与管理控制台 VisualVM 多合-故障处理工具 Java Mission Control 可持续在线的监控工具 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:16:0","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"JMX JMX（Java Management Extensions）， Java 管理扩展，用来管理和监测 Java 程序。最常用到的就是对于 JVM 的监测和管理，比如 JVM 内存、CPU 使用率、线程数、垃圾收集情况等等。另外，还可以用作日志级别的动态修改，比如 log4j 就支持 JMX 方式动态修改线上服务的日志级别。最主要的还是被用来做各种监控工具，比如 Spring Boot Actuator、JConsole、VisualVM 等。 JMX 既是 Java 管理系统的一个标准，一个规范，也是一个接口，一个框架。有标准、有规范是为了让开发者可以定制开发自己的扩展功能，而且作为一个框架来讲，JDK 已经帮我们实现了常用的功能，尤其是对 JVM 的监控和管理。 https://www.cnblogs.com/fengzheng/p/13431845.html 类加载机制 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:17:0","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"类文件结构 可用 javap 分析class文件。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:18:0","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"虚拟机类加载机制 Java虚拟机把描述类的数据从class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这个过程被称作虚拟机的类加载机制。 与那些在编译器需要进行连接的语言不同，在Java语言里，类型的加载、连接和初始化都是在程序运行期间完成的。 一个类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期将会经历7个阶段。 加载、 验证、 准备、 初始化和卸载这五个阶段的顺序是确定的， 类型的加载过程必须按照这种顺序按部就班地开始， 而解析阶段则不一定： 它在某些情况下可以在初始化阶段之后再开始，这是为了支持Java语言的运行时绑定特性（也称为动态绑定或晚期绑定） 。 对于什么时候开始类加载过程的第一个阶段“加载”，《Java虚拟机规范》没有强制约束。 但对于初始化阶段，则严格规定了有且只有以下六种情况必须对类进行“初始化”（而加载、验证、准备自然需要在此之前开始）： 遇到 new、getstatic、putstatic、invokestatic这四条字节码指令时。能够生成这四条指令的典型Java代码场景有： 使用new关键字实例化对象时。 读取或设置一个类型的静态字段（被final修饰、已在编译器把结果放入常量池的静态字段除外）的时候。 调用一个类型的静态方法时。 使用 java.lang.reflect包的方法对类型进行反射调用时。 当初始化类时，如果发现其父类还没进行过初始化，则需要先触发其父类的初始化。 当虚拟机启动时，用户需要指定一个要执行的主类（包含main()的那个类），虚拟机会先初始化这个类。 当使用JDK 7新加入的动态语言支持时， 如果一个java.lang.invoke.MethodHandle实例最后的解析结果为REF_getStatic、 REF_putStatic、 REF_invokeStatic、 REF_newInvokeSpecial四种类型的方法句柄， 并且这个方法句柄对应的类没有进行过初始化， 则需要先触发其初始化。 当一个接口中定义了JDK 8加入的默认方法（被default修饰的接口方法）。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:19:0","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"类加载的过程 类加载的全过程：加载、验证、准备、解析和初始化五个阶段。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:20:0","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"加载 这里的加载（Loading）阶段是指整个类加载（Class Loading）过程中的一个阶段。 虚拟机需要完成三件事： 通过一个类的全限定名来获取定义此类的二进制字节流。 将这个字节流所代表的静态存储结构转换为方法区的运行时数据结构。 在内存中生成一个代表这个类的 java.lang.Class对象，作为方法区这个类的各种数据的访问入口。 加载阶段结束后， Java虚拟机外部的二进制字节流就按照虚拟机所设定的格式存储在方法区之中了， 方法区中的数据存储格式完全由虚拟机实现自行定义， 《Java虚拟机规范》 未规定此区域的具体数据结构。 类型数据妥善安置在方法区之后， 会在Java堆内存中实例化一个java.lang.Class类的对象，这个对象将作为程序访问方法区中的类型数据的外部接口。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:20:1","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"验证 验证是连接阶段的第一步， 这一阶段的目的是确保Class文件的字节流中包含的信息符合《Java虚拟机规范》 的全部约束要求， 保证这些信息被当作代码运行后不会危害虚拟机自身的安全。 从整体上看， 验证阶段大致上会完成下面四个阶段的检验动作： 文件格式验证、 元数据验证、 字节码验证和符号引用验证。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:20:2","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"准备 准备阶段是正式为类中定义的变量（即静态变量， 被static修饰的变量） 分配内存并设置类变量初始值的阶段。 这时候进行内存分配的仅包括类变量， 而不包括实例变量， 实例变量将会在对象实例化时随着对象一起分配在Java堆中。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:20:3","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"解析 解析阶段是Java虚拟机将常量池内的符号引用替换为直接引用的过程。 符号引用（Symbolic References） ： 符号引用以一组符号来描述所引用的目标， 符号可以是任何形式的字面量， 只要使用时能无歧义地定位到目标即可。 符号引用与虚拟机实现的内存布局无关， 引用的目标并不一定是已经加载到虚拟机内存当中的内容。 各种虚拟机实现的内存布局可以各不相同，但是它们能接受的符号引用必须都是一致的， 因为符号引用的字面量形式明确定义在《Java虚拟机规范》 的Class文件格式中。eg：在Class文件中 CONSTANT_Class_info、CONSTANT_Fieldref_info、 CONSTANT_Methodref_info等类型的常量出现。 直接引用（Direct References） ： 直接引用是可以直接指向目标的指针、 相对偏移量或者是一个能间接定位到目标的句柄。 直接引用是和虚拟机实现的内存布局直接相关的， 同一个符号引用在不同虚拟机实例上翻译出来的直接引用一般不会相同。 如果有了直接引用， 那引用的目标必定已经在虚拟机的内存中存在。 解析动作主要针对类或接口、 字段、 类方法、 接口方法、 方法类型、 方法句柄和调用点限定符这7类符号引用进行， 分别对应于常量池的CONSTANT_Class_info、 CON-STANT_Fieldref_info、CONSTANT_Methodref_info、 CONSTANT_InterfaceMethodref_info、CONSTANT_MethodType_info、 CONSTANT_MethodHandle_info、 CONSTANT_Dyna-mic_info和CONSTANT_InvokeDynamic_info 8种常量类型。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:20:4","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"初始化 在之前类加载动作中，除了在加载阶段应用程序可以通过自定义类加载器的方式局部参与外，其余动作都完全由Java虚拟机来主导控制。直到初始化阶段，Java虚拟机才真正可是执行类中编写的Java程序代码，将主导权交给应用程序。 进行准备阶段时， 变量已经赋过一次系统要求的初始零值， 而在初始化阶段， 则会根据程序员通过程序编码制定的主观计划去初始化类变量和其他资源。 我们也可以从另外一种更直接的形式来表达： 初始化阶段就是执行类构造器\u003cclinit\u003e()方法的过程。 \u003cclinit\u003e()并不是程序员在Java代码中直接编写的方法， 它是Javac编译器的自动生成物。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:20:5","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"类加载器 Java虚拟机设计团队有意把类加载阶段中的“通过一个类的全限定名来获取描述该类的二进制字节流”这个动作放到Java虚拟机外部去实现， 以便让应用程序自己决定如何去获取所需的类。 实现这个动作的代码被称为“类加载器”（Class Loader） 。 对于任意一个类，都必须由加载它的类加载器和这个类本身一起共同确立其在Java虚拟机中的唯一性。 每一个类加载器，都拥有一个独立的类名词空间。 比较两个类是否“相等”，只有在这两个类是由同一个类加载器加载的前提下才有意义。否则，即使这两个类来源于同一个Class文件，被同一个Java虚拟机加载，只要加载它们的类加载器不同，那这两个类就必定不相等。 这里所指的“相等”， 包括代表类的Class对象的equals()方法、 isAssignableFrom()方法、 isInstance()方法的返回结果， 也包括了使用instanceof关键字做对象所属关系判定等各种情况。 从Java虚拟机的角度来看，只存在两种不同的类加载器： 启动类加载器（Bootstrap ClassLoader）：这个类加载器是使用C++实现的，是虚拟机自身的一部分。 其他所有的类加载器，这些类加载器都由Java实现的，独立于虚拟机外部，并且全部继承自抽象类 java.lang.ClassLoader 自JDK 1.2以来，Java一直保持着三层类加载器、双亲委派的类加载架构。（在Java模块化后有一些调整，但主体结构没变）。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:21:0","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"三层类加载器 JDK 9 之前： 绝大多数Java程序都会使用到以下3个系统提供的类加载器来进行加载。 启动类加载器 Bootstrap Class Loader：负责加载存放在 \u003cJAVA_HOME\u003e\\lib目录，或被 -Xbootclasspath参数所指定的路径中存放的，并且是Java虚拟机能识别的类库加载到虚拟机的内存中。（eg：rt.jar、tools.jar） 扩展类加载器 Extension Class Loader：负责加载 \u003cJAVA_HOME\u003e\\lib\\ext目录，或被 java.ext.dirs系统变量所指定的路径中所有的类库。 应用程序类加载器/系统类加载器 Application Class Loader：负责加载用户类路径（ClassPath）上所有的类库。如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 如果有需要，还可以自定义类加载器。eg：增加除了磁盘位置之外的Class文件来源， 或者通过类加载器实现类的隔离、 重载等功能。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:21:1","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"双亲委派模型（Parents Delegation Model） 各种类加载器支给件的层次关系就被称为类加载器的双亲委派模型。 双亲委派模型要求除了顶层的启动类加载器外，其余的类加载器都应有自己的父类加载器。不过这里类加载器之间的父子关系一般不是继承（inheritance）的关系来实现的，而是使用组合（composition）关系来复用父类加载器的代码。 **双亲委派模型的工作过程是：**如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到最顶层的启动类加载器中，只有当父类加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去完成加载。 使用双亲委派模型来组织类加载器之间的关系， 一个显而易见的好处就是Java中的类随着它的类加载器一起具备了一种带有优先级的层次关系。 例如类java.lang.Object， 它存放在rt.jar之中， 无论哪一个类加载器要加载这个类， 最终都是委派给处于模型最顶端的启动类加载器进行加载， 因此Object类在程序的各种类加载器环境中都能够保证是同一个类。 双亲委派模型的实现： //java.lang.ClassLoader的loadClass() protected synchronized Class\u003c?\u003e loadClass(String name, boolean resolve) throws ClassNotFoundException { // 首先， 检查请求的类是否已经被加载过了 Class c = findLoadedClass(name); if (c == null) { try { if (parent != null) { c = parent.loadClass(name, false); } else { c = findBootstrapClassOrNull(name); }} catch (ClassNotFoundException e) { // 如果父类加载器抛出ClassNotFoundException // 说明父类加载器无法完成加载请求 }i f (c == null) { // 在父类加载器无法加载时 // 再调用本身的findClass方法来进行类加载 c = findClass(name); } }i f (resolve) { resolveClass(c); }return c; } 先检查请求加载的类型是否已经被加载过， 若没有则调用父加载器的loadClass()方法， 若父加载器为空则默认使用启动类加载器作为父加载器。 假如父类加载器加载失败， 抛出ClassNotFoundException异常的话， 才调用自己的findClass()方法尝试进行加载。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:21:2","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"Java模块化系统 JDK 9 中引入了Java模块化系统（Java Platform Module System, JPMS）。 （模块化到底怎么样，没看懂） 为了保证兼容性， JDK 9并没有从根本上动摇从JDK 1.2以来运行了二十年之久的三层类加载器架构以及双亲委派模型。 但是为了模块化系统的顺利施行， 模块化下的类加载器仍然发生了一些应该被注意到变动， 主要包括以下几个方面： 扩展类加载器（Extension Class Loader） 被平台类加载器（Platform Class Loader） 取代。 JDK 9中虽然仍然维持着三层类加载器和双亲委派的架构， 但类加载的委派关系也发生了变动。 当平台及应用程序类加载器收到类加载请求， 在委派给父加载器加载前， 要先判断该类是否能够归属到某一个系统模块中， 如果可以找到这样的归属关系， 就要优先委派给负责那个模块的加载器完成加载。 在Java模块化系统明确的规定了三个类加载器负责各自加载的模块。 ​ Java内存模型 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:21:3","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"硬件的效率与一致性 基于告诉缓存的存储交互很好的解决了处理器与内存速度之间的矛盾，但带来了一个新问题：缓存一致性（Cache Coherence）。为了解决一致性问题，需要各个处理器访问缓存时都遵循一些协议。这类协议有：MSI、MESI、MOSI。。。 Java虚拟机也有自己的内存模型，并且和这里的内存访问操作及硬件的缓存操作觉有高度的可类比性。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:22:0","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"Java内存模型 Java Memory Model，JMM 这里的主内存、工作内存与Java内存区域中的Java堆、栈、方法区等不是一个概念，没有关系。 Java内存模型规定了所有的变量都存储在主内存中。 每条线程还有自己的工作内存，线程中的工作内存中保存了被该线程使用的变量的主内存副本，线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写主内存中的数据。 不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成。 这里说的变量与java编程中的变量有所区别，它包括了实例字段、静态字段和构成数组对象的元素，但是不包括局部变量与方法参数，因为是线程私有的，不会被共享，不会存在竞争问题。 对于主内存和工作内存之间的交互协议，Java内存模型中定义了8种操作来完成，Java虚拟机实现时必须保证这8种操作每一个都是原子的。后来，简化为 read, write, lock, unlock 四种。 volatile 可以说是Java虚拟机提供的最轻量级的同步机制。当一个变量被定为成 volatile 之后，它将具备两个特性： 保证变量对所有线程的可见性。（并不保证原子性，即使编译出来只有一条字节码指令，也不意味着这条指令就是一个原子操作） 禁止指令重排序优化。 大多数情况下 volatile 的总开下比锁要低，因此我们在 volatile 与锁的选择中，唯一判断依据便是 volatile的语义能否满足使用场景的需求。 对于 volatile 变量的特殊规则： 在工作内存中，每次使用前都必须先从主内存刷新最新的值，保证能看起其他线程对变量所做的修改。 在工作内存中，每次修改后都必须立刻同步回主内存中，保证其他线程可以看到自己对变量的修改。 修饰的变量不会被指令重排序优化，从而保证代码的执行顺序与程序的顺序相同。 原子性： 尽管虚拟机未把 lock 和 unlock 操作直接开放给用户使用，但是却提供了更高层次的字节码指令 monitorenter 和 monitorexit 来隐式的使用这两个操作。这两个字节码指令反映到java代码中就是同步快synchronized关键字。 可见性： 除了 volatile 之外，Java还有两个关键字可以实现可见性，synchronized 和 final。 final 的可见性是指：被final修饰的字段在构造器中一旦被初始化完成，并且构造没有把 this 的引用传递出去，那么在其他线程中就能看见 final 字段的值。 有序性： 如果在本线程内观察，所有操作都是有序的。 如果在一个线程观察另一个线程，所有的操作都是无序的。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:23:0","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"先行发生（Happens-Before）原则 如果Java 内存模型中所有的有序性都只靠 volatile 和 synchronized 来完成，那么很多操作将会变得非常啰嗦。 而Java通过先行发生（Happens-Before）原则，对数据是否存在竞争，线程是否安全进行了判断。 先行发生是指：Java内存模型中定义的两项操作之间的偏序关系，如果操作A先行发生与操作B，那就是说在发送操作B之前，操作A产生的影响能被操作B观察到。影响包括修改了内存中共享变量的值、发送了消息、调用了方法等。 以下是Java内存模型中的先行发生关系：（如果两个操作之间的关系不在此列， 无法从下列规则推导出来， 则它们就没有顺序性保障， 虚拟机可以对它们随意地进行重排序。） 程序次序规则 Program Order Rule：在一个线程内，按照控制流程顺序，书写在前面的操作先行发生与书写在后面的操作 管程锁定规则 Monitor Lock Rule：一个unlock 操作先行发生与后面对同一个锁的lock操作。 线程启动规则 Thread Start Rule：Thread对象的start()方法先行发生与此线程的每一个动作。 线程终止规则 Thead Termination Rule：线程中的所有操作都先行发生于对此线程的终止检测，可以通过 Thread::jion() 方法是否结束、Thread::isAlive()的返回值等手段检测线程是否已经终止执行。 线程中断规则 Thread Interruption Rule：对线程interrput()方法的调用先行发生于被中断线程的代码检测到众中断事件的发生，可以通过 Thread::interrupted()方法检测到是否有中断发生。 对象终结规则 Finalize Rule：一个对象的初始化完成（构造函数执行结束）先行发生于它的finalize()方法的开始。 传递性 Transitivity：如果操作A先行发生与操作B，操作B先行发生与操作C，那么操作A先行发生于操作C。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:24:0","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"Java 与线程 线程是比进程更轻量级的调度执行单位，引入了线程，可以把一个进程的资源分配和执行调度分开，各个线程既可以共享进程资源（内存地址、文件I/O等），又可以独立调度。 目前线程是Java进行处理器资源调度的最基本单位。 主流Java虚拟机的线程模型都是基于操作系统原生线程模型来实现的，即采用1：1线程模型。 阻塞和等待的区别： 阻塞：在等待获取一个排他锁，这个事件将在另一个线程放弃这个锁的时候发生 等待：则是在等待一段时间，或者唤醒动作的发生。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:25:0","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"Java 与协程【不是很理解】 1： 1的内核线程模型是如今Java虚拟机线程实现的主流选择， 但是这种映射到操作系统上的线程天然的缺陷是切换、 调度成本高昂， 系统能容纳的线程数量也很有限。 传统的Java Web服务器的线程池的容量通常在几十个到两百之间， 当程序员把数以百万计的请求往线程池里面灌时， 系统即使能处理得过来， 但其中的切换损耗也是相当可观的。 内核线程的调度成本主要来自于用户态与核心态之间的状态转换， 而这两种状态转换的开销主要来自于响应中断、 保护和恢复执行现场的成本。 后来， 操作系统开始提供多线程的支持， 靠应用自己模拟多线程的做法自然是变少了许多， 但也并没有完全消失， 而是演化为用户线程继续存在。 由于最初多数的用户线程是被设计成协同式调度（Cooperative Scheduling） 的， 所以它有了一个别名——“协程”（Coroutine） 。 又由于这时候的协程会完整地做调用栈的保护、 恢复工作， 所以今天也被称为“有栈协程”（Stackfull Coroutine） ， 起这样的名字是为了便于跟后来的“无栈协程”（Stackless Coroutine） 区分开。 无栈协程不是本节的主角， 不过还是可以简单提一下它的典型应用， 即各种语言中的await、 async、 yield这类关键字。 无栈协程本质上是一种有限状态机， 状态保存在闭包里， 自然比有栈协程恢复调用栈要轻量得多， 但功能也相对更有限。 对于有栈协程， 有一种特例实现名为纤程（Fiber） ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:26:0","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"线程安全 线程安全的实现方法： ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:27:0","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"互斥同步（阻塞同步） 互斥是手段，同步是目的。 临界区（critical section）、互斥量（mutex）、信号量（semaphore）都是常见的互斥实现方法。 在Java中，最基本的互斥同步手段就是 synchronized ，这是一种块结构（block structured）的同步语法。 synchronized 经过javac 编译后，会在同步块前后分别形成 monitorenter 和monitorexit两个字节码指令。这两个字节码指令都需要一个reference类型的参数来指明要锁定和解锁的对象。如果代码中synchronized明确指明了对象参数，那就以这个对象的引用作为reference（即获得的是你传入的，传入对象就是对象锁【this也是对象锁】，传入类就是类锁），如果没有明确指定，将根据synchronized修饰的方法类型（实例方法还是类方法），来决定是获取对象实例还是类型对应的Class对象来作为线程要持有的锁（即修饰实例方法获取的是对象锁，修饰静态方法获取的是类锁）。 被 synchronized 修饰的同步块对同一条线程来说是可重入的。这意味着同一线程反复进入同步块也不会出现把自己锁死的情况。 被 synchronized 修饰的同步块在持有锁的线程执行完毕并释放锁之前，会无条件的阻塞后面其他线程的进入。 JDK 5起，Java提供了java.util.concurrent包（J.U.T包），其中java.util.concurrent.locks.Lock接口便成了Java的另一种全新的互斥同步手段。基于Lock接口，用户能够以非块结构（Non-Block Structured）来实现互斥同步，从而摆脱语言特性的束缚，在类库层面去实现同步。 重入锁（ReentrantLock）是Lock接口最常见的一种实现。在基本用法上，ReentrantLock 和 synchronized相似，只是写法稍微不同，且 ReentrantLock 比 synchronized 多了一些高级功能，主要有3项： 等待可中断 可实现公平锁 可绑定多个条件 JDK 6 开始对synchronized进行了锁优化，ReentrantLock 和 synchronized 的性能基本能持平，因此性能已不再是选择 ReentrantLock 或 synchronized 的判断因素。 推荐在 synchronized 和 ReentrantLock 都能满足的场景优先使用 synchronized，原因如下： synchronized 足够清晰，简单。 Lock要确保在finally中释放锁。synchronized由Java虚拟机来保证。 从长远看，Java虚拟机更容易针对synchronized进行优化。因为Java虚拟机通过在线程和对象的元数据中记录synchronized中锁的相关信息，使用Lock的话，Java虚拟机很难得知具体哪些锁对象是由特定线程所持有的。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:27:1","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"非阻塞同步 互斥同步面临的主要问题是进行线程阻塞和唤醒锁带来的性能开销，因此这种同步也被称为阻塞同步（Blocking Synchronization），属于悲观的并发策略。 非阻塞同步（Non-Blocking Synchronization）是基于冲突检测的乐观并发策略，冲突了再进行补偿，最常用的补偿措施是不断重试，直到没有竞争的共享数据位置。也称为无锁（Lock-Free）编程。 乐观并发策略需要依赖硬件指令集的发展，因为要保证操作和冲突检测这两个步骤具备原子性。 这类指令通常用： 测试并设置（Test and Set） 获取并增加（Fetch and Increment） 交换（Swap） 比较并交换（Compare and Swap，CAS） 加载链接/条件存储（Load Linked/Store Conditional，LL/SC） Java里最终暴露出来的是CAS操作，CAS指令需要有3个操作数，分别是变量的内存地址V，旧的预期值A，准备设置的新值B。CAS指令执行时，当且仅当V符合A时，处理器才会用B更新V的值，否则不执行更新。但无论是否执行更新，都会返回V的旧值。 在JDK 5之后， Java类库中才开始使用CAS操作， 该操作由sun.misc.Unsafe类里面的compareAndSwapInt()和compareAndSwapLong()等几个方法包装提供。 HotSpot虚拟机在内部对这些方法做了特殊处理， 即时编译出来的结果就是一条平台相关的处理器CAS指令， 没有方法调用的过程。 不过由于Unsafe类在设计上就不是提供给用户程序调用的类（Unsafe::getUnsafe()的代码中限制了只有启动类加载器（Bootstrap ClassLoader） 加载的Class才能访问它） ， 因此在JDK 9之前只有Java类库可以使用CAS， 譬如J.U.C包里面的整数原子类， 其中的compareAndSet()和getAndIncrement()等方法都使用了Unsafe类的CAS操作来实现。 而如果用户程序也有使用CAS操作的需求， 那要么就采用反射手段突破Unsafe的访问限制， 要么就只能通过Java类库API来间接使用它。 直到JDK 9之后， Java类库才在VarHandle类里开放了面向用户程序使用的CAS操作。 为了解决CAS的ABA问题，J.U.C包提供了一个带有标记的原子引用类AtomicStampedReference，它可以通过控制变量值的版本来保证CAS的正确性。不管目前这个类相当鸡肋，大部分情况下ABA问题不会影响程序并发的正确性，如果需要解决ABA问题，采用传统的互斥同步可能会比原子类更高效。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:27:2","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"无同步方案 线程本地存储（Thread Local Storage）：如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码能否保证只在同一个线程中执行。如果能保证，就可以把共享数据的可见范围限制在同一个线程之内，这样无须同步也能保证线程之间不出现数据竞争的问题。 符合这种特点的应用并不少见，大部分使用消费队列的架构模式（eg：生产者-消费者模式）都会将产品的消费过程限制在一个线程中消费完，其中最重要的一种应用实例就是经典Web交互模型中的“一个请求对应一个服务器线程”（Thread-pre-Request）的处理方式，这种处理方式的广泛应用使得很多Web服务端应用都可以使用线程本地存储来解决线程安全问题。 Java中，如果一个变量要被多线程访问，可以使用 volatile将其声明为“易变的”。如果一个变量只要被某个线程独享，可以通过 java.lang.ThreadLocal类来实现线程本地存储的功能。每一个线程的Thread对象中都有一个ThreadLocalMap对象，这个对象存储了一组以ThreadLocal.threadLocalHashCode为键，以本地线程变量为值的键值对，ThreadLocal对象就是当前线程的ThreadLocalMap的访问入口，每一个ThreadLocal对象都包含了一个独一无二的threadLocalHashCode，这个值就可以在线程键值对中找到对应的本地线程变量。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:27:3","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"锁优化 JDK 6，虚拟机团队锁进行了多种优化，有： 适应性自旋 Adaptive Spinning 锁消除 Lock Elimination 锁膨胀 Lock Coarsening 轻量级锁 Lightweight Locking 偏向锁 Biased Locking ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:28:0","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"自旋锁与自适应自旋 互斥同步对性能最大的影响是阻塞的实现， 挂起线程和恢复线程的操作都需要转入内核态中完成， 这些操作给Java虚拟机的并发性能带来了很大的压力。 同时， 我们注意到在许多应用上， 共享数据的锁定状态只会持续很短的一段时间， 为了这段时间去挂起和恢复线程并不值得。如果物理机器有一个以上的处理器或者处理器核心， 能让两个或以上的线程同时并行执行， 我们 就可以让后面请求锁的那个线程“稍等一会”， 但不放弃处理器的执行时间， 看看持有锁的线程是否很快就会释放锁。 为了让线程等待， 我们只须让线程执行一个忙循环（自旋） ， 这项技术就是所谓的自旋锁。 自旋锁在1.4.2中就引进了，不过默认是关闭的。JDK 6开始改为默认开启。默认自旋10次。 JDK 6 对自旋锁的优化，引入了自适应的自旋。自适应自旋意味着自旋次数不再是固定的了，由前一次在同一个锁上的自旋时间以及锁的拥有者的状态决定。如果同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，进而允许自旋等待持续更长的时间。如果队友某个锁，自旋很少成功获得过锁，那以后要获取这个锁将可能直接省略自旋过程。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:28:1","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"锁消除 锁消除是指虚拟机即时编译器在运行时，对一些代码要求同步，但是对被检测到不可能存在共享数据竞争的锁进行消除。 锁消除的主要判断依据来源于逃逸分析的数据支持。 如果判断到一段代码，在堆上的所有数据都不会逃逸出去被其他线程访问到，那就可以把他们当做栈上数据对待，认为他们是线程私有的，同步加锁自然就不用再进行了。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:28:2","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"锁粗化 如果虚拟机检测到有一串零碎的操作都对同一个对象加锁，就会把加锁同步的范围粗化到整个操作序列的外部。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:28:3","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"轻量级锁 轻量级锁并不是来替代重量级锁的，它的设计初衷是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量的性能消耗。 在代码即将进入同步块时，如果此同步对象没有被锁定（锁标志位为“01”状态），虚拟机首先将在当前线程的栈帧中简历一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝。 然后虚拟机将使用 CAS操作尝试把对象的Mark Word更新为指向Lock Record 的指针。 如果更新动作成功了，代表该线程拥有了这个对象的锁，并且对象Mark Word的锁标志位（Mark Word的最后两个比特）将变为“00”，表示此对象正处于轻量级锁定状态。 如果更新操作失败了，意味着有线程与当前线程竞争该对象的锁。虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是，说明当前线程已经拥有了这个对象的锁，直接进入同步块。否则说明这个锁对象给其他线程抢占了，此时轻量级锁升级为重量级锁，锁标志位状态变为“10”。 轻量级锁能提升程序同步性能的依据是“对于绝大部分的锁，在整个同步周期内都是不存在竞争的”。如果没有竞争，轻量级锁便通过CAS操作成功避免了使用互斥量的开销。但如果确实存在锁竞争，除了互斥量本身的开销外，还额外发生了CAS的开销。因此在有竞争的情况下，轻量级锁反而会比传统的重量级锁更慢。 ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:28:4","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["技术笔记"],"content":"偏向锁 偏向锁的目的是消除数据在无竞争情况下的同步原语。如果说轻量级锁是在无竞争的情况下使用CAS操作去消除同步使用的互斥量，那偏向锁就是在无竞争情况下把整个同步都消除掉，连CAS操作都不做。 这个锁会偏向于第一个获得它的线程，如果在接下来的执行过程中，该锁一直没有被其他的线程获取，则持有偏向锁的线程将永远不需要再进行同步。 偏向锁默认是开启的。当锁对象第一次被线程获取时，虚拟机会把对象头中的标志位设置为“01”、把偏向模式设置为1，表示进入偏向模式。同时使用CAS操作把获取到这个锁的线程ID记录在对象的Mark Word中。果CAS操作成功， 持有偏向锁的线程以后每次进入这个锁相关的同步块时， 虚拟机都可以不再进行任何同步操作（例如加锁、 解锁及对Mark Word的更新操作等）。 一旦出现另外一个线程去尝试获取这个锁的情况， 偏向模式就马上宣告结束。 根据锁对象目前是否处于被锁定的状态决定是否撤销偏向（偏向模式设置为“0”） ， 撤销后标志位恢复到未锁定（标志位为“01”） 或轻量级锁定（标志位为“00”） 的状态， 后续的同步操作就按照上面介绍的轻量级锁那样去执行。 如果程序中大多数的锁都总是被多个不同的线程访问，那么偏向模式就是多余的。有时使用参数 -XX:-UseBisedLocking=false来禁止偏向锁优化反而可以提升性能。 （JDK 15 废弃偏向锁） ","date":"2022-04-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/:28:5","tags":["JVM"],"title":"《深入理解Java虚拟机-第三版》-note","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%AC%E4%B8%89%E7%89%88-note/"},{"categories":["生活"],"content":"语法 ","date":"2022-03-31","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.4-note/:1:0","tags":["日语"],"title":"《大家的日语》No.4-note","uri":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.4-note/"},{"categories":["生活"],"content":"今　ー時ー分です 時（じ） 分（ふん）。具体的分要特殊记忆。 eg：今何時ですか。 ７時10分です。 ","date":"2022-03-31","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.4-note/:1:1","tags":["日语"],"title":"《大家的日语》No.4-note","uri":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.4-note/"},{"categories":["生活"],"content":"动词ます/动词ません/动词ました/动词ませんでした ","date":"2022-03-31","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.4-note/:1:2","tags":["日语"],"title":"《大家的日语》No.4-note","uri":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.4-note/"},{"categories":["生活"],"content":"名词（时间）に动词 表示动作进行的时间。 eg：６時半に起きます。 特殊的时间词后面不加に（eg：きょう、あした。。。） 有些可加可不加（eg：〜曜日） ","date":"2022-03-31","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.4-note/:1:3","tags":["日语"],"title":"《大家的日语》No.4-note","uri":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.4-note/"},{"categories":["生活"],"content":"名词から名词まだ から表示起点（时间、场所） まだ表示终点（时间、场所） 可一起使用，也可单独使用。 eg： ９時から５時まで勉強します。 大阪から東京まで3時間かかります。 ","date":"2022-03-31","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.4-note/:1:4","tags":["日语"],"title":"《大家的日语》No.4-note","uri":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.4-note/"},{"categories":["生活"],"content":"名词と名词 表示“和” ","date":"2022-03-31","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.4-note/:1:5","tags":["日语"],"title":"《大家的日语》No.4-note","uri":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.4-note/"},{"categories":["生活"],"content":"〜ね 大変ですね。 ","date":"2022-03-31","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.4-note/:1:6","tags":["日语"],"title":"《大家的日语》No.4-note","uri":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.4-note/"},{"categories":["生活"],"content":"单词 起きます（おきます） 寝ます（ねます） 働きます（はたらきます） 休みます（やすみます） 勉強します（べんきょうします） 終わります（おわります） デパート（department） 百货商店 銀行（ぎんこう） 郵便局（ゆうびんきょく） 図書館（としょかん） 美術館（びじゅつかん） 今（いま） ー時（じ） ー分（ふん） 半（はん） 何時（なんじ） 何分（なんぷん） 午前（ごぜん） 上午 午後（ごご） 下午 朝（あさ） 早晨 昼（ひる） 白天 晩（ばん） 晚上 夜（よる） 晚上 一昨日（おととい） 前天 昨日（きのう） 昨天 今日（きょう） 今天 明日（あした） 明天 明後日（あさって） 后天 今朝（けさ） 今天早上 今晩（こんばん） 今天晚上 休み（やすみ） 休息 昼休み（ひるやすみ）午休 試験（しけん） 会議（かいぎ） 映画（えいが） ","date":"2022-03-31","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.4-note/:2:0","tags":["日语"],"title":"《大家的日语》No.4-note","uri":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.4-note/"},{"categories":["生活"],"content":"语法 ","date":"2022-03-30","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.3-note/:1:0","tags":["日语"],"title":"《大家的日语》No.3-note","uri":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.3-note/"},{"categories":["生活"],"content":"ここ／そこ／あそこ／こちら／そちら／あちら ","date":"2022-03-30","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.3-note/:1:1","tags":["日语"],"title":"《大家的日语》No.3-note","uri":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.3-note/"},{"categories":["生活"],"content":"名词 は 场所あです。 表示场所、人或物等存在的地方。 ","date":"2022-03-30","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.3-note/:1:2","tags":["日语"],"title":"《大家的日语》No.3-note","uri":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.3-note/"},{"categories":["生活"],"content":"どこ／どちら ","date":"2022-03-30","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.3-note/:1:3","tags":["日语"],"title":"《大家的日语》No.3-note","uri":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.3-note/"},{"categories":["生活"],"content":"名词 の 名词 ","date":"2022-03-30","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.3-note/:1:4","tags":["日语"],"title":"《大家的日语》No.3-note","uri":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.3-note/"},{"categories":["生活"],"content":"こ／そ／あ／ど　一览表 こ系列 そ系列 あ系列 ど系列 物 これ それ あれ どれ 物、人 この名词 その名词 あの名词 どの名词 场所 ここ そこ あそこ どこ 方向、场所（郑重） こちら そちら あちら どちら ","date":"2022-03-30","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.3-note/:1:5","tags":["日语"],"title":"《大家的日语》No.3-note","uri":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.3-note/"},{"categories":["生活"],"content":"お〜 放在与说话人或第三者有关的事物之前，表达说话人的敬意。 「お」国はどちらですか。 ","date":"2022-03-30","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.3-note/:1:6","tags":["日语"],"title":"《大家的日语》No.3-note","uri":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.3-note/"},{"categories":["生活"],"content":"单词 ここ そこ あそこ どこ こちら そちら あちら どちら 教室（きょうしつ） 食堂（しょくどう） 事務所（じむしょ） 会議室（かいぎしつ） 受付（うけつけ） 接待处 ロビー（lobby） 部屋（へや） 房间 トイレ（toilet） お手洗い（おてあらい） 洗手间 階段（かいだん） 楼梯 エレベーター（elevator） 电梯 エスカレーター（escalator） 自动扶梯 自動販売機（じどうはんばいき） 電話（でんわ） 「お」国（くに） 会社（かいしゃ） うち 家 靴（くつ） 鞋 ネクタイ（neckite） 领带 ワイン（wine）葡萄酒 売り場（うりば） 销售柜台 地下（ちか） ー階（かい） ー层 何階（なんがい） 几层 ー円（えん） いくら 多少钱 百（ひゃく） 千（せん） 万（まん） すみません。 どうも。 いらっしゃいませ。 欢迎光临。 「〜を」見せてください。 请让我看一下~。 じゃ 「〜を」ください。 请给我~。 イタリア（Italy） 意大利 スイス（Swiss） 瑞士 フランス（France） 法国 バンコク（Bangkok） 曼谷 ベルリン（Berlin） 柏林 ","date":"2022-03-30","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.3-note/:2:0","tags":["日语"],"title":"《大家的日语》No.3-note","uri":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.3-note/"},{"categories":["技术笔记"],"content":"阻塞IO 服务端处理客户端的连接和请求主要阻塞在2个地方： accept()：阻塞建立连接 read()：阻塞读数据 网卡到内核缓冲区阻塞 内核缓冲区到用户缓冲区阻塞 // old listenfd = socket(); // 打开一个网络通信端口 bind(listenfd); // 绑定 listen(listenfd); // 监听 while(1) { connfd = accept(listenfd); // 阻塞建立连接 int n = read(connfd, buf); // 阻塞读数据 doSomeThing(buf); // 利用读到的数据做些什么 close(connfd); // 关闭连接，循环等待下一个连接 } 改进：采用多线程，为每个客户端创建一个线程。但此时的read()还是阻塞的。 // 改进 while(1) { connfd = accept(listenfd); thread_create(dowork); } void dowork() { int n = read(connfd, buf); dosomething(buf); close(connfd); } ","date":"2022-03-29","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B5%85%E8%B0%88io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/:1:0","tags":["IO"],"title":"浅谈IO多路复用","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B5%85%E8%B0%88io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/"},{"categories":["技术笔记"],"content":"非阻塞IO 要实现非阻塞IO需要操作系统提供一个非阻塞的read()：在没有数据到达时，立即返回-1（非阻塞）；当数据已到达内核缓冲区时，调用read()还是阻塞的。 改进：为每个客户端创建一个线程，服务器线程资源很快会被耗尽。可以每accept一个客户端连接后，将文件描述符放到一个数组中。然后通过一个线程不断遍历这个数组，调用每一个非阻塞的read方法。这样就成功只用一个线程处理了多个客户端连接。 while(1) { for(fd \u003c-- fdlist) { if(read(fd) != -1) { doSomeThing(); } } } 但每次遍历遇到 read 返回 -1 时仍然是一次浪费资源的系统调用。 ","date":"2022-03-29","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B5%85%E8%B0%88io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/:2:0","tags":["IO"],"title":"浅谈IO多路复用","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B5%85%E8%B0%88io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/"},{"categories":["技术笔记"],"content":"IO多路复用 让操作系统提供函数，将一批文件描述符通过系统调用传给内核，由内核去遍历。 通过一个进程监听多个文件描述符，一旦某个文件描述符准备就绪，就通知程序。 ","date":"2022-03-29","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B5%85%E8%B0%88io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/:3:0","tags":["IO"],"title":"浅谈IO多路复用","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B5%85%E8%B0%88io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/"},{"categories":["技术笔记"],"content":"select select 是操作系统提供的系统调用函数，通过它，我们可以把一个文件描述符的数组发给操作系统， 让操作系统去遍历，确定哪个文件描述符可以读写， 然后告诉我们去处理。 //一个线程不断接受客户端连接，并把 socket 文件描述符放到一个 list 里 while(1) { connfd = accept(listenfd); fcntl(connfd, F_SETFL, O_NONBLOCK); fdlist.add(connfd); } //一个线程不再自己遍历，而是调用 select，将这批文件描述符 list 交给操作系统去遍历。 while(1) { nready = select(list); // 用户层依然要遍历，只不过少了很多无效的系统调用 for(fd \u003c-- fdlist) { if(fd != -1) { // 只读已就绪的文件描述符 read(fd, buf); // 总共只有 nready 个已就绪描述符，不用过多遍历 if(--nready == 0) break; } } } 细节（缺点）： select 调用需要传入 fd 数组，需要拷贝一份到内核，高并发场景下这样的拷贝消耗的资源是惊人的。 select 在内核层仍然是通过遍历的方式检查文件描述符的就绪状态，是个同步过程，只不过无系统调用切换上下文的开销。 select 仅仅返回可读文件描述符的个数，具体哪个可读还是要用户自己遍历。 ","date":"2022-03-29","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B5%85%E8%B0%88io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/:3:1","tags":["IO"],"title":"浅谈IO多路复用","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B5%85%E8%B0%88io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/"},{"categories":["技术笔记"],"content":"poll poll 基于链表存储，解决了select最大连接数（1024）的限制。 ","date":"2022-03-29","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B5%85%E8%B0%88io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/:3:2","tags":["IO"],"title":"浅谈IO多路复用","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B5%85%E8%B0%88io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/"},{"categories":["技术笔记"],"content":"epoll 解决select/poll的问题： 内核中保存一份文件描述符集合，无需用户每次都重新传入，只需告诉内核修改的部分即可。 内核不再通过轮询的方式找到就绪的文件描述符，而是通过异步 IO 事件唤醒。 内核仅会将有 IO 事件的文件描述符返回给用户，用户也无需遍历整个文件描述符集合。 //创建一个 epoll 句柄 int epoll_create(int size); //向内核添加、修改或删除要监控的文件描述符。 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); //类似发起了 select() 调用 int epoll_wait(int epfd, struct epoll_event *events, int max events, int timeout); ","date":"2022-03-29","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B5%85%E8%B0%88io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/:3:3","tags":["IO"],"title":"浅谈IO多路复用","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B5%85%E8%B0%88io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/"},{"categories":["技术笔记"],"content":"参考文章 你管这破玩意叫 IO 多路复用？ 彻底理解 IO 多路复用实现机制 ","date":"2022-03-29","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B5%85%E8%B0%88io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/:4:0","tags":["IO"],"title":"浅谈IO多路复用","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E6%B5%85%E8%B0%88io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/"},{"categories":["生活"],"content":"语法 これ、それ、あれ この、その、あの　+ N. そうです 〜か、〜か 名词 の名词 代替名词使用的の お〜 そうですか ","date":"2022-03-28","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.2-note/:1:0","tags":["日语"],"title":"《大家的日语》No.2-note","uri":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.2-note/"},{"categories":["生活"],"content":"单词 本（ほん） 辞書（じしょ） 雑誌（ざっし） 新聞（しんぶん） ノート 手帳（てちょう） 名刺（めいし） カード 鉛筆（えんぴつ） シャープペンシル 鍵（かぎ） 時計（とけい） 傘（かさ） 鞄（かばん） テレビ ラジオ カメラ コンピューター 車（くるま） 机（つくえ） 椅子（いす） チョコレート コーヒー 【お】土産（みやげ） 英語（えいご） 日本語（にほんご） 〜ご なん そう あのう えぅ どうぞ 【どうも】ありがとう【ございましす】。 そうですか。 違います。（ちがいます） これから　お世話に　なります。（おせわになります。） こちらこそ　【どうぞ】　よろしく【お願いします】。 ","date":"2022-03-28","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.2-note/:2:0","tags":["日语"],"title":"《大家的日语》No.2-note","uri":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.2-note/"},{"categories":["生活"],"content":"语法 名词 は 名词 です 名词 は 名词 じゃ（では）ありません 名词 は 名词 ですか 名词も 名词の名词 〜さん ","date":"2022-03-28","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.1-note/:1:0","tags":["日语"],"title":"《大家的日语》No.1-note","uri":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.1-note/"},{"categories":["生活"],"content":"单词 私（わたし） 貴方（あなた） あの人（あのひと）、あの方（あのかた） 〜さん 〜ちゃん 〜人（じん） 先生（せんせい） 教師（きょうし） 学生（がくせい） 会社員（かいしゃいん） 研究者（けんきゅうしゃ） 大学（だいがく） 病院（びょういん） 誰（だれ）、何方（どなた） ー歳（ーさい） 何歳（なんさい）、おいくつ はい いいえ 初めまして。 〜からきました。 【どうぞ】よろしく【お願いします】。 失礼ですか。 お名前は？ こちらは〜さんです。 アメリカ イギリス インド インドネシア 韓国 タイ 中国 日本 ブラジレ ","date":"2022-03-28","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.1-note/:2:0","tags":["日语"],"title":"《大家的日语》No.1-note","uri":"/posts/%E7%94%9F%E6%B4%BB/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%97%A5%E8%AF%ADno.1-note/"},{"categories":["生活"],"content":"AはBです です才是谓语，表示“是”。 は没有意义。 A、B为名词或代词。 ","date":"2022-03-22","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E6%97%A5%E8%AF%AD%E8%AF%AD%E6%B3%95%E7%AC%94%E8%AE%B0%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0ing/:1:0","tags":["日语"],"title":"日语语法笔记","uri":"/posts/%E7%94%9F%E6%B4%BB/%E6%97%A5%E8%AF%AD%E8%AF%AD%E6%B3%95%E7%AC%94%E8%AE%B0%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0ing/"},{"categories":["生活"],"content":"AはBではありません ではありません一定要连着使用。 口语化：AはBじゃありません 打字打促音时前面加x。 ","date":"2022-03-22","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E6%97%A5%E8%AF%AD%E8%AF%AD%E6%B3%95%E7%AC%94%E8%AE%B0%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0ing/:2:0","tags":["日语"],"title":"日语语法笔记","uri":"/posts/%E7%94%9F%E6%B4%BB/%E6%97%A5%E8%AF%AD%E8%AF%AD%E6%B3%95%E7%AC%94%E8%AE%B0%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0ing/"},{"categories":["生活"],"content":"AはBですか か：疑问助词，置于句末，表示疑问。 ","date":"2022-03-22","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E6%97%A5%E8%AF%AD%E8%AF%AD%E6%B3%95%E7%AC%94%E8%AE%B0%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0ing/:3:0","tags":["日语"],"title":"日语语法笔记","uri":"/posts/%E7%94%9F%E6%B4%BB/%E6%97%A5%E8%AF%AD%E8%AF%AD%E6%B3%95%E7%AC%94%E8%AE%B0%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0ing/"},{"categories":["生活"],"content":"一般疑问句 A与B都是名词，无特殊疑问词出现。 eg： あなたは李先生ですか。 肯定回答：はい、そです。 否定回答：いいえ、そうではありません。 ​ いいえ、そうじゃありません。 ","date":"2022-03-22","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E6%97%A5%E8%AF%AD%E8%AF%AD%E6%B3%95%E7%AC%94%E8%AE%B0%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0ing/:3:1","tags":["日语"],"title":"日语语法笔记","uri":"/posts/%E7%94%9F%E6%B4%BB/%E6%97%A5%E8%AF%AD%E8%AF%AD%E6%B3%95%E7%AC%94%E8%AE%B0%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0ing/"},{"categories":["生活"],"content":"特殊疑问句 B为特殊疑问词。 特殊疑问词： 何（なん）：什么 どなた：哪位、谁 誰（だれ）：谁 いつ：什么时候 どこ：哪里 どれ：哪个 どう：如何 eg：先生のかばんはだれですか。 ","date":"2022-03-22","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E6%97%A5%E8%AF%AD%E8%AF%AD%E6%B3%95%E7%AC%94%E8%AE%B0%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0ing/:3:2","tags":["日语"],"title":"日语语法笔记","uri":"/posts/%E7%94%9F%E6%B4%BB/%E6%97%A5%E8%AF%AD%E8%AF%AD%E6%B3%95%E7%AC%94%E8%AE%B0%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0ing/"},{"categories":["生活"],"content":"AのB 特殊疑问词可以配合の使用，如“谁的”。 これはだれの写真ですか。 ","date":"2022-03-22","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E6%97%A5%E8%AF%AD%E8%AF%AD%E6%B3%95%E7%AC%94%E8%AE%B0%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0ing/:4:0","tags":["日语"],"title":"日语语法笔记","uri":"/posts/%E7%94%9F%E6%B4%BB/%E6%97%A5%E8%AF%AD%E8%AF%AD%E6%B3%95%E7%AC%94%E8%AE%B0%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0ing/"},{"categories":["生活"],"content":"AもBです も：提示助词，表示“也”。 AもBです。 AもBではありません。 eg： 私は中国人です。 あの人も中国人です。 ","date":"2022-03-22","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E6%97%A5%E8%AF%AD%E8%AF%AD%E6%B3%95%E7%AC%94%E8%AE%B0%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0ing/:5:0","tags":["日语"],"title":"日语语法笔记","uri":"/posts/%E7%94%9F%E6%B4%BB/%E6%97%A5%E8%AF%AD%E8%AF%AD%E6%B3%95%E7%AC%94%E8%AE%B0%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0ing/"},{"categories":["生活"],"content":"AはBにあります 存在句。 に：提示事物存在的地点。 あります：在。 A为人和动物之外的事物。 B为表示地点的名词或代词。 肯定形式：AはBにあります。A在B处。 否定形式：AはBにありません。 疑问形式：Aはどこにありますか。 eg：学校（がっこう）は山（やま）の前にあります。 表示方位的名词： 前（まえ） 後ろ（うしろ） 上（うえ）、 下（した） 左（ひだり） 右（みぎ） そば 隣（となり） ","date":"2022-03-22","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E6%97%A5%E8%AF%AD%E8%AF%AD%E6%B3%95%E7%AC%94%E8%AE%B0%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0ing/:6:0","tags":["日语"],"title":"日语语法笔记","uri":"/posts/%E7%94%9F%E6%B4%BB/%E6%97%A5%E8%AF%AD%E8%AF%AD%E6%B3%95%E7%AC%94%E8%AE%B0%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0ing/"},{"categories":["生活"],"content":"AにBがあります 表示：在A处存在B。在…有… 存在句。が提示句子主语。 否定形式：AにBがありません 疑问形式：Aに何がありますか？在A处有什么？ ","date":"2022-03-22","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E6%97%A5%E8%AF%AD%E8%AF%AD%E6%B3%95%E7%AC%94%E8%AE%B0%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0ing/:7:0","tags":["日语"],"title":"日语语法笔记","uri":"/posts/%E7%94%9F%E6%B4%BB/%E6%97%A5%E8%AF%AD%E8%AF%AD%E6%B3%95%E7%AC%94%E8%AE%B0%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0ing/"},{"categories":["生活"],"content":"AやBなど や：并列助词，前后连接两个代表性的事物，暗示还有其他。 など：副词。等等，之类的。 CにAやBなどがあります。C处有A和B之类的等等东西存在。 eg：机（つくえ）の上（うえ）に本やノートなどがあります。 ","date":"2022-03-22","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E6%97%A5%E8%AF%AD%E8%AF%AD%E6%B3%95%E7%AC%94%E8%AE%B0%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0ing/:8:0","tags":["日语"],"title":"日语语法笔记","uri":"/posts/%E7%94%9F%E6%B4%BB/%E6%97%A5%E8%AF%AD%E8%AF%AD%E6%B3%95%E7%AC%94%E8%AE%B0%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0ing/"},{"categories":["生活"],"content":"AにBが+数量+あります 表示：在A处有x个B 日语中，句子的补语（数量、状态、方向）在谓语动词之前。 eg：五階にトイレが二つあります。在五楼卫生间有2个。 図書館（としょかん）に本がたくさんあります。图书馆的书有很多。 提问用いくつ eg：机の上に鍵（かぎ）がいくつありますか。 たくさん：许多 何に（なんに） 何台（なんだい） 何本（なんほん） 何〜（なん〜） ","date":"2022-03-22","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E6%97%A5%E8%AF%AD%E8%AF%AD%E6%B3%95%E7%AC%94%E8%AE%B0%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0ing/:9:0","tags":["日语"],"title":"日语语法笔记","uri":"/posts/%E7%94%9F%E6%B4%BB/%E6%97%A5%E8%AF%AD%E8%AF%AD%E6%B3%95%E7%AC%94%E8%AE%B0%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0ing/"},{"categories":["好文转载"],"content":"一、前言 在一次新功能上线过程中，出现线程池提交任务抛出 RejectedExecutionException 异常，即任务提交执行了拒绝策略的操作。查看业务情况和线程池配置，发现并行执行的任务数是小于线程池最大线程数的，为此展开了一次线程池问题排查历程。 ","date":"2022-03-21","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/:1:0","tags":["问题排查","线程池"],"title":"一次线上线程池任务问题处理历程","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/"},{"categories":["好文转载"],"content":"二、业务情景 ","date":"2022-03-21","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/:2:0","tags":["问题排查","线程池"],"title":"一次线上线程池任务问题处理历程","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/"},{"categories":["好文转载"],"content":"2.1. 任务描述 每次执行一组任务，一组任务最多有 15 个，多线程执行，每个线程处理一个任务；每次执行完一组任务后，再执行下一组，不存在上一组的任务和下一组一起执行的情况。 ","date":"2022-03-21","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/:2:1","tags":["问题排查","线程池"],"title":"一次线上线程池任务问题处理历程","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/"},{"categories":["好文转载"],"content":"2.2. 任务提交流程 ","date":"2022-03-21","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/:2:2","tags":["问题排查","线程池"],"title":"一次线上线程池任务问题处理历程","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/"},{"categories":["好文转载"],"content":"2.3. 线程池配置 \u003cbean id=\"executor\" class=\"org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor\"\u003e \u003cproperty name=\"corePoolSize\" value=\"14\"/\u003e \u003cproperty name=\"maxPoolSize\" value=\"30\"/\u003e \u003cproperty name=\"queueCapacity\" value=\"1\"/\u003e \u003c/bean\u003e ","date":"2022-03-21","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/:2:3","tags":["问题排查","线程池"],"title":"一次线上线程池任务问题处理历程","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/"},{"categories":["好文转载"],"content":"三、出现问题 执行过程中出现 RejectedExecutionException 异常，由于是采用的是默认拒绝策略 AbortPolicy，因此，可以明确知道任务是提交到线程池后，线程池资源已满，导致任务被拒绝。 ","date":"2022-03-21","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/:3:0","tags":["问题排查","线程池"],"title":"一次线上线程池任务问题处理历程","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/"},{"categories":["好文转载"],"content":"四、问题排查 ","date":"2022-03-21","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/:4:0","tags":["问题排查","线程池"],"title":"一次线上线程池任务问题处理历程","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/"},{"categories":["好文转载"],"content":"4.1. 检查线程池配置 任务最多 15 个一组，核心线程有 14 个，阻塞队列是 1，最大线程 30，理论上 14 个核心线程+1 个阻塞队列即可完成一组任务，连非核心线程都无需使用，为什么会出现线程被占满的情况？ ","date":"2022-03-21","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/:4:1","tags":["问题排查","线程池"],"title":"一次线上线程池任务问题处理历程","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/"},{"categories":["好文转载"],"content":"4.2. 检查业务代码 检查是否存在线程池被多处使用，或者有多批任务被同时执行的情况，并没有发现错误； ","date":"2022-03-21","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/:4:2","tags":["问题排查","线程池"],"title":"一次线上线程池任务问题处理历程","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/"},{"categories":["好文转载"],"content":"4.3. 线下重现 配置线程池 \u003cbean id=\"executor\" class=\"org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor\"\u003e \u003cproperty name=\"corePoolSize\" value=\"14\"/\u003e \u003cproperty name=\"maxPoolSize\" value=\"30\"/\u003e \u003cproperty name=\"queueCapacity\" value=\"1\"/\u003e \u003c/bean\u003e 建立 demo 代码 @RunWith(SpringRunner.class) @SpringBootTest public class SpringBootStartApplicationTests { @Resource private ThreadPoolTaskExecutor executor; @Test public void contextLoads() throws Exception { // 一共 10 批任务 for(int i = 0; i \u003c 10; i++) { // 每次执行一批任务 doOnceTasks(); System.out.println(\"---------------------------------------\" + i); } } /** * 每次完成 15 个任务后，再进行下一次任务 */ private void doOnceTasks(){ List\u003cFuture\u003e futureList = Lists.newArrayListWithCapacity(15); for(int i = 0; i \u003c 15; ++i){ Future future = executor.submit(()-\u003e{ // 随机睡 0-5 秒 int sec = new Double(Math.random() * 5).intValue(); LockSupport.parkNanos(sec * 1000 * 1000 * 1000); System.out.println(Thread.currentThread().getName() + \" end\"); }); futureList.add(future); } // 等待所有任务执行结束 for(Future future : futureList){ try { future.get(); } catch (Exception e) { e.printStackTrace(); } } } } 异常重现 ","date":"2022-03-21","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/:4:3","tags":["问题排查","线程池"],"title":"一次线上线程池任务问题处理历程","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/"},{"categories":["好文转载"],"content":"五、线程池源码阅读 ","date":"2022-03-21","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/:5:0","tags":["问题排查","线程池"],"title":"一次线上线程池任务问题处理历程","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/"},{"categories":["好文转载"],"content":"5.1. 线程池执行任务流程 当工作线程数 \u003c corePoolSize 时，新创建一个新线程执行新提交任务，即使此时线程池中存在空闲线程； 当工作线程数 == corePoolSize 时，新提交任务将被放入 workQueue 中； 当 workQueue 已满，且工作线程数 \u003c maximumPoolSize 时，新提交任务会创建新的非核心线程执行任务； 当 workQueue 已满，且 工作线程数==maximumPoolSize 时，新提交任务由 RejectedExecutionHandler 处理； ","date":"2022-03-21","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/:5:1","tags":["问题排查","线程池"],"title":"一次线上线程池任务问题处理历程","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/"},{"categories":["好文转载"],"content":"5.2. execute 线程池提交任务源码 class ThreadPoolExecutor{ public void execute(Runnable command) { // 提交任务不能为 null if (command == null) throw new NullPointerException(); // 获取控制位 ctl 的值 int c = ctl.get(); // work 线程数 \u003c 核心线程数 if (workerCountOf(c) \u003c corePoolSize) { // 直接创建核心线程，执行任务 if (addWorker(command, true)) return; /* 因为没有使用锁，可能会出现并发创建核心线程； 走到这里，说明核心线程已经创建满了，此时，重新获取控制位 ctl 的值 */ c = ctl.get(); } // 如果线程池还是 RUNNING 状态，并且任务成功提交到阻塞队列中 if (isRunning(c) \u0026\u0026 workQueue.offer(command)) { int recheck = ctl.get(); // double-check，再检查一次线程池状态 // 如果线程池变成非 RUNNING 状态，则回滚刚才新加的任务 if (! isRunning(recheck) \u0026\u0026 remove(command)) // 从阻塞队列中移除任务成功，使用拒绝策略执行任务 reject(command); // 如果工作线程数==0，则添加一个线程 // 主要是兼容核心线程数==0 的情况 else if (workerCountOf(recheck) == 0) addWorker(null, false); } /* 到达这里，则说明核心线程数已满，且阻塞队列已满 尝试创建非核心线程执行任务 */ else if (!addWorker(command, false)) // 非核心线程创建失败了，说明是线程数以达到 maximumPoolSize，此时执行拒绝策略 reject(command); } } ","date":"2022-03-21","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/:5:2","tags":["问题排查","线程池"],"title":"一次线上线程池任务问题处理历程","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/"},{"categories":["好文转载"],"content":"5.3. addWorker 添加 worker 线程 class ThreadPoolExecutor{ /** * 添加一个 worker 线程 * @param firstTask 第一个要执行的 task * @param core 是否是核心线程 * @return 创建成功还是失败 */ private boolean addWorker(Runnable firstTask, boolean core) { // 定义了一个 retry 标签 retry: for (;;) { // 获取控制位 int c = ctl.get(); // 获取运行状态 int rs = runStateOf(c); /** * rs \u003e= SHUTDOWN：即非 RUNNING 状态，只有 RUNNING \u003c SHUTDOWN * ! (rs == SHUTDOWN \u0026\u0026 firstTask == null \u0026\u0026 ! workQueue.isEmpty()) * 等价于 非 SHUTDOWN 态 || firstTask != null || workQueue.isEmpty() * 非 SHUTDOWN 态 == true：SHUTDOWN 态之后的状态，都不允许再添加 worker 线程了，直接返回 false； * 非 SHUTDOWN 态 == false || (firstTask != null) == true：SHUTDOWN 状态下，不允许再添加任务了，返回 false； * 非 SHUTDOWN 态 == false || (firstTask != null) == false || workQueue.isEmpty() == true：SHUTDOWN 状态，没提交新任务，阻塞队列又是空的，没必要再添加线程了 */ if (rs \u003e= SHUTDOWN \u0026\u0026 ! (rs == SHUTDOWN \u0026\u0026 firstTask == null \u0026\u0026 ! workQueue.isEmpty())) return false; // CAS 创建 worker 线程 for (;;) { // 获取线程数 int wc = workerCountOf(c); /* 当前线程数大于最大值 或 当前创建的是核心线程，但线程数量已经\u003e=核心线程数 或 当前创建非核心线程，但线程数量已经\u003e=maximumPoolSize */ if (wc \u003e= CAPACITY || wc \u003e= (core ? corePoolSize : maximumPoolSize)) // 不创建，直接返回 false return false; // cas 修改 ctl 中的线程数，线程数+1 if (compareAndIncrementWorkerCount(c)) // cas 修改成功，break goto 结束循环（不会再进入标签下的循环） break retry; // 达到这里，说明 cas 增加线程数 1 失败了，此时进行尝试 c = ctl.get(); // 先判断一下线程池状态有没有改变，如果改变了，则 continue goto（会再进入标签下的循环） // 跳转到最外层的循环，重新检测线程池的状态值 if (runStateOf(c) != rs) continue retry; } } boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try { // 创建 worker 对象 w = new Worker(firstTask); // 获取 worker 的线程 final Thread t = w.thread; if (t != null) { // 加锁 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // 获取线程池状态 int rs = runStateOf(ctl.get()); /* 线程池是 RUNNING 状态 或 SHUTDOWN 态 且 firstTask == null（这种情况是需要创建线程，消费队列中剩余的任务） */ if (rs \u003c SHUTDOWN || (rs == SHUTDOWN \u0026\u0026 firstTask == null)) { // 线程是活动状态，则不合法，因为线程是刚创建的，应该是 NEW 状态 if (t.isAlive()) throw new IllegalThreadStateException(); // 将 worker 添加到 list 中 workers.add(w); // largestPoolSize 记录该线程池使用过程中，达到最大的线程数 int s = workers.size(); if (s \u003e largestPoolSize) largestPoolSize = s; // worker 添加成功，workerAdded 置为 true workerAdded = true; } } finally { mainLock.unlock(); } // worker 添加成功，此时就可以启动线程 if (workerAdded) { t.start(); // 启动线程成功，workerStarted 置为 true workerStarted = true; } } } finally { // 如果 worker 启动失败，则移除它 if (! workerStarted) // workers 移除新加的 worker，并在 ctl 中将 work 线程数量-1 addWorkerFailed(w); } return workerStarted; } } ","date":"2022-03-21","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/:5:3","tags":["问题排查","线程池"],"title":"一次线上线程池任务问题处理历程","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/"},{"categories":["好文转载"],"content":"六、问题定位 ","date":"2022-03-21","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/:6:0","tags":["问题排查","线程池"],"title":"一次线上线程池任务问题处理历程","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/"},{"categories":["好文转载"],"content":"6.1. 定位执行拒绝策略入口 执行拒绝策略的位置只有这两个地方，在这两个地方打上断点，执行 demo，结果发现拒绝策略是在第二处执行的； ","date":"2022-03-21","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/:6:1","tags":["问题排查","线程池"],"title":"一次线上线程池任务问题处理历程","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/"},{"categories":["好文转载"],"content":"6.2. 定位执行拒绝策略原因 进入 addWorker 方法，只有这两个地方返回 false，创建线程失败，打断点，执行 demo，发现是在第二处返回 false 的； ","date":"2022-03-21","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/:6:2","tags":["问题排查","线程池"],"title":"一次线上线程池任务问题处理历程","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/"},{"categories":["好文转载"],"content":"七、问题确认 确实是创建的 worker 线程已经达到最大线程数，无法再创建，然后执行拒绝策略的，为什么会被创建到最大呢，每组任务最大只有 15 个，为什么会用到非核心线程？ ","date":"2022-03-21","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/:7:0","tags":["问题排查","线程池"],"title":"一次线上线程池任务问题处理历程","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/"},{"categories":["好文转载"],"content":"八、定位原因 ","date":"2022-03-21","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/:8:0","tags":["问题排查","线程池"],"title":"一次线上线程池任务问题处理历程","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/"},{"categories":["好文转载"],"content":"8.1. 分析 execute 方法 在添加非核心线程前，先尝试将任务放到阻塞队列中，如果阻塞队列已满，则尝试添加非核心线程，也就是说，创建非核心线程时：workQueue.offer(command) == false，即阻塞队列已满； ","date":"2022-03-21","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/:8:1","tags":["问题排查","线程池"],"title":"一次线上线程池任务问题处理历程","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/"},{"categories":["好文转载"],"content":"8.2. 猜测原因 因为我们阻塞队列只有 1，会不会提交任务的速度比线程从阻塞队列取任务的速度快，进而导致创建非核心线程执行任务，最终的结果就是：在多批任务之后，再无非核心线程可创建，导致执行拒绝策略。 ","date":"2022-03-21","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/:8:2","tags":["问题排查","线程池"],"title":"一次线上线程池任务问题处理历程","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/"},{"categories":["好文转载"],"content":"8.3. 原因验证 8.3.1 阻塞队列选择 查看 Spring 的 ThreadPoolTaskExecutor 源码，发现如果阻塞队列数量\u003e0，则使用 LinkedBlockingQueue，否则使用 SynchronousQueue。 8.3.2 LinkedBlockingQueue 查看 LinkedBlockingQueue#take 方法，如果队列已空，则所有取元素的线程会阻塞在一个 Lock 的 notEmpty 等待条件上，等有元素入队时，只会调用 signal 方法唤醒一个线程取元素，而不是所有线程。 class LinkedBlockingQueue{ private void signalNotEmpty() { final ReentrantLock takeLock = this.takeLock; // 加锁 takeLock.lock(); try { // 唤醒一个 take 线程 notEmpty.signal(); } finally { takeLock.unlock(); } } } 因为一个线程从唤醒到执行是有一段时间间隔的，阻塞被唤醒后，还要等待获取 cpu 时间片，而主线程一直在发布任务，此时就会造成队列中的元素来不及消费，只能创建非核心线程消费的现象。 ","date":"2022-03-21","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/:8:3","tags":["问题排查","线程池"],"title":"一次线上线程池任务问题处理历程","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/"},{"categories":["好文转载"],"content":"九、解决方式 ","date":"2022-03-21","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/:9:0","tags":["问题排查","线程池"],"title":"一次线上线程池任务问题处理历程","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/"},{"categories":["好文转载"],"content":"9.1. 使用 SynchronousQueue 使用 SynchronousQueue，即阻塞队列大小设置为 0，原因在于：SynchronousQueue 和 LinkedBlockingQueue 维度不一致，SynchronousQueue 是根据是否有等待线程而决定是否入队成功，而 LinkedBlockingQueue 是根据缓冲区，而不管是否已经有等待线程。 SynchronousQueue LinkedBlockingQueue ","date":"2022-03-21","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/:9:1","tags":["问题排查","线程池"],"title":"一次线上线程池任务问题处理历程","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/"},{"categories":["好文转载"],"content":"9.2. 根据业务情况配置阻塞队列 对于我们的业务情况，因为任务最多只有 15 个，将阻塞队列大小设置为 15，这样就保证了不会出现任务被拒绝。 原文地址：https://xiaomi-info.github.io/2019/12/19/theadpool-rejected-task/ ","date":"2022-03-21","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/:9:2","tags":["问题排查","线程池"],"title":"一次线上线程池任务问题处理历程","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E5%8E%86%E7%A8%8B/"},{"categories":["好文转载"],"content":"2012 年，刚刚建立的字节跳动便开启了 A/B 测试之旅，随着今日头条、抖音、西瓜视频等全线业务的使用，将 A/B 测试应用在产品命名、交互设计、推荐算法、用户增长、广告优化和市场活动等各方面决策上。据今年 4 月字节跳动旗下火山引擎技术开放日上透露的数据显示，字节跳动每天同时进行的 A/B 测试达到上万场，单日新增实验数量超过 1500 个，覆盖 400 多项业务。随着公司发展，这些数字还在不断扩大，仅最近一年就已经做了 40 万次 A/B 测试。 那么在字节跳动里，支撑这些测试的技术平台是怎么炼出来的？我们采访了字节跳动 A/B 实验平台技术负责人王珂，通过他的回复我们可以得到一个初步的了解。王珂将在 2021 年 10 月 21-23 日QCon上海站分享主题为《字节跳动 A/B 测试平台演进历史及实践》的演讲，更多内容可以通过观看演讲进行了解。 嘉宾简介：王珂，字节跳动 A/B 实验平台技术负责人。目前就职于字节跳动数据平台，负责内部 A/B 实验平台的研发，支撑内部各个业务线的 A/B 实验需求，在 A/B 实验领域有比较深入的理解。曽经任职于亚马逊中国库存健康优化团队，有多年大数据及服务架构经验。 InfoQ： 有说法是目前这种形式的 A/B 测试最早出现于 1990 年代，您认为其核心原理这么多年是否有改变？ 王珂： 核心原理基本没有发生什么改变，仍然是依赖随机采样获取两个样本集合，施加不同的策略，采集结果比较和分析。如果要说变化，更多的是应对实际的 A/B 测试场景，在测试方式、指标设计和显著性分析方法等细节上有了更多的探索和演进。 InfoQ： 能否以一个简单的例子，说明 A/B 测试如何工作？ 王珂： 简单来说，一个 A/B 测试生命周期大致分三个部分：A/B 测试设计（包括测试内容、预期收益、测试时长、测试流量、观测指标等的确认）、A/B 测试执行（利用 A/B 测试平台的能力完成分流、配置分发、数据回收等）、A/B 测试结果分析（产出指标数据，显著性分析，多维下探等，最后形成分析报告）。 InfoQ： A/B 测试适合哪些场景？能运行 A/B 测试需要哪些必备条件？字节跳动的 A/B 测试平台主要适用于什么场景？ 王珂： 通常而言，可以将样本随机划分为互不相关的两组，同时施加不同策略，并可以提供量化指标衡量策略效果的，都可以进行 A/B 测试。比较典型的如政策调整，无法随机将民众划分为两部分，一部分执行新政策一部分执行旧政策，这种就不适合进行传统意义的 A/B 测试，而通常会尝试在一个城市试点新政策，通过 DID 或者 SCM 等分析方法检验效果。 字节跳动的 A/B 测试平台立足于服务和支撑字节跳动内各大业务线的 A/B 测试需求，当前主要适用于算法迭代、产品演化、智慧运营等场景，未来也会随公司的脚步覆盖更多的场景。 InfoQ： 字节跳动的 A/B 测试平台有哪几个主要部分组成，整个平台大概经历了什么样的迭代过程？ 王珂： 经过多年的迭代，字节跳动 A/B 测试平台由最初服务于推荐算法迭代，到现在包含 A/B 测试、配置发布、自动调参和探索实验室四大部分，覆盖了 A/B 测试的整个生命周期。 InfoQ： 数据采集部分，一般平台使用的是埋点或日志数据，那么字节跳动的平台是通过什么方法实现的？ 王珂： 我们的平台也是基本基于埋点和日志数据来生产测试数据的。在字节跳动，埋点和日志数据汇集都有系统化的解决方案，使得我们的 A/B 测试平台可以比较容易的给出 A/B 测试结果。 InfoQ： 是否有一些测试比较复杂？字节跳动如何降低复杂性，让业务人员易于理解和使用？ 王珂： 会遇到一些比较复杂的场景，平台也会尝试优化产品以降低使用门槛。一个比较典型的案例是算法侧的超参选择。在机器学习模型中经常会遇到一些超参，需要算法工程师凭借经验和 A/B 测试结果来调整这些超参的取值。传统做法下，算法工程师需要花几个月的时间，通过不停的 A/B 测试对比调整遴选合适的超参取值。为降低该场景的使用复杂性，字节跳动的 A/B 测试平台通过一些统计学方法，自动化的循环执行 A/B 测试，分析测试结果，预测最优解取值，协助算法工程师寻找到合适的超参，使得调参耗时由几个月缩减到几个礼拜。这也就是我们的自动调参系统。 InfoQ： 人们在做 A/B 测试时会犯哪些常犯的错误/陷阱？ 王珂： 比较常见的是“连续观测”。举个夸张点的例子就是，一个 A/B 测试启动起来，使用者每天都会过来看一下是不是指标有显著正向；直到突然有一天，指标正向了，使用者开心的关掉 A/B 测试，撰写上线报告。这种连续观测，一旦显著立即决策的做法会令使用者拿到错误结论的风险大幅度上升，是不可取的。因此在字节跳动，A/B 测试使用方式的宣讲是我们需要例行去做的很重要的一个事情。 InfoQ： A/B 测试，可能因为不同的受众行为不同，对一家公司有效的东西不一定对另一家公司有效。那么字节跳动的 A/B 测试平台如何具备普适性？ 王珂： 一方面，字节跳动的 A/B 测试始终以平台的方式将 A/B 测试做合理抽象，向不同的业务场景提供测试能力，考虑到公司较为复杂的产品矩阵，A/B 测试平台从诞生至今的一路迭代中始终站在 A/B 测试最基本的抽象上，以保证其普适性。 另一方面，像指标体系等与业务场景关联密切的资产，我们既要考虑它可能不具备普适性，而需要做到因业务而异；也要考虑到相似的业务线可能会重复建设相似的指标体系。因此，能够“将经验复制一份”也是我们平台需要频繁考虑的东西。 InfoQ： A/B 测试平均耗费时长是多少？如何减少“延时”，以比较快的速度得到结果，这方面您们有哪些可供大家参考的经验？ 王珂： 不同场景，不同目的下，A/B 测试需要进行的时间也会有比较大的差异。例如搜索算法的小流量测试是为了快速探索算法迭代的可行性，几天或几个小时便能给出有价值的结果；而产品界面的变更，为了规避所谓的新奇效应，避免有些用户出于好奇心而带来的短期指标上扬，测试可能会开启几个礼拜甚至几个月。比较典型的 A/B 测试通常会持续 1-3 个礼拜。 通常而言一个 A/B 测试需要耗费多久，和 A/B 测试内容、测试设计有关。相比而言，减少一个 A/B 测试消耗的时间不如提升 A/B 测试的并发性，让系统同时容纳更多的 A/B 测试，对产品的整体迭代效率提升更加有益。 InfoQ： 字节跳动 A/B 测试平台有哪些未来规划？ 王珂： 有三个比较重要的方向是我们的 A/B 测试平台在当前比较关注，在未来会加大力度投入的。 一个是对 A/B 测试分析能力的更大力度支持。开 A/B 测试在字节跳动相对是比较容易的，但是 A/B 测试分析和更多有价值信息的挖掘却没有那么容易。曾经有一个测试，指标上看并没有显著的提升，然而在一个特殊的维度上我们发现了显著的效果，进一步分析推理之后我们对策略进行了调整，最后还是拿到了比较大的收益。由此可见分析能力对于测试平台而言的重要性。 另一个是场景化支撑的能力。字节跳动的产品矩阵复杂度越来越高，不同的业务领域对 A/B 测试有着不同的诉求，相较于能力堆砌功能强大的巨无霸，一个清新简洁切合业务属性的系统对于业务迭代效率的提升更加有益，这也是我们架构演进的必经之路。 最后一个也是最重要的一个，是方法论的探索和储备，拓宽 A/B 测试的边界，应对今天和明天我们在业务上会遇到的新问题，例如在社交领域如何更好的解决网络效应等。 原文地址：https://www.infoq.cn/article/t7hcvlteucsrodrht1ff ","date":"2022-03-15","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E5%B9%B4-40-%E4%B8%87%E6%AC%A1%E5%AE%9E%E9%AA%8C%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8-ab-%E6%B5%8B%E8%AF%95%E5%B9%B3%E5%8F%B0%E6%98%AF%E6%80%8E%E4%B9%88%E7%82%BC%E5%87%BA%E6%9D%A5%E7%9A%84/:0:0","tags":["A/B Test"],"title":"一年 40 万次实验，字节跳动 A/B 测试平台是怎么炼出来的？","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/%E4%B8%80%E5%B9%B4-40-%E4%B8%87%E6%AC%A1%E5%AE%9E%E9%AA%8C%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8-ab-%E6%B5%8B%E8%AF%95%E5%B9%B3%E5%8F%B0%E6%98%AF%E6%80%8E%E4%B9%88%E7%82%BC%E5%87%BA%E6%9D%A5%E7%9A%84/"},{"categories":["好文转载"],"content":"前言 在使用spring框架的日常开发中，bean之间的循环依赖太频繁了，spring已经帮我们去解决循环依赖问题，对我们开发者来说是无感知的，下面具体分析一下spring是如何解决bean之间循环依赖，为什么要使用到三级缓存，而不是二级缓存 ","date":"2022-03-14","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/spring-%E4%B8%BA%E4%BD%95%E9%9C%80%E8%A6%81%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E8%80%8C%E4%B8%8D%E6%98%AF%E4%BA%8C%E7%BA%A7%E7%BC%93%E5%AD%98/:1:0","tags":["spring"],"title":"Spring 为何需要三级缓存解决循环依赖，而不是二级缓存？","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/spring-%E4%B8%BA%E4%BD%95%E9%9C%80%E8%A6%81%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E8%80%8C%E4%B8%8D%E6%98%AF%E4%BA%8C%E7%BA%A7%E7%BC%93%E5%AD%98/"},{"categories":["好文转载"],"content":"bean生命周期 首先大家需要了解一下bean在spring中的生命周期，bean在spring的加载流程，才能够更加清晰知道spring是如何解决循环依赖的 我们在spring的BeanFactory工厂列举了很多接口，代表着bean的生命周期，我们主要记住的是我圈红线圈出来的接口, 再结合spring的源码来看这些接口主要是在哪里调用的 AbstractAutowireCapableBeanFactory类的doCreateBean方法是创建bean的开始，我们可以看到首先需要实例化这个bean，也就是在堆中开辟一块内存空间给这个对象，createBeanInstance方法里面逻辑大概就是采用反射生成实例对象，进行到这里表示对象还并未进行属性的填充，也就是@Autowired注解的属性还未得到注入 我们可以看到第二步就是填充bean的成员属性，populateBean方法里面的逻辑大致就是对使用到了注入属性的注解就会进行注入，如果在注入的过程发现注入的对象还没生成，则会跑去生产要注入的对象，第三步就是调用initializeBean方法初始化bean，也就是调用我们上述所提到的接口 可以看到initializeBean方法中，首先调用的是使用的Aware接口的方法，我们具体看一下invokeAwareMethods方法中会调用Aware接口的那些方法 我们可以知道如果我们实现了BeanNameAware，BeanClassLoaderAware，BeanFactoryAware三个Aware接口的话，会依次调用setBeanName(), setBeanClassLoader(), setBeanFactory()方法，再看applyBeanPostProcessorsBeforeInitialization源码 发现会如果有类实现了BeanPostProcessor接口，就会执行postProcessBeforeInitialization方法，这里需要注意的是：如果多个类实现BeanPostProcessor接口，那么多个实现类都会执行postProcessBeforeInitialization方法，可以看到是for循环依次执行的，还有一个注意的点就是如果加载A类到spring容器中，A类也重写了BeanPostProcessor接口的postProcessBeforeInitialization方法，这时要注意A类的postProcessBeforeInitialization方法并不会得到执行，因为A类还未加载完成，还未完全放到spring的singletonObjects一级缓存中。 再看一个注意的点 可以看到ApplicationContextAwareProcessor也实现了BeanPostProcessor接口，重写了postProcessBeforeInitialization方法，方法里面并调用了invokeAwareInterfaces方法，而invokeAwareInterfaces方法也写着如果实现了众多的Aware接口，则会依次执行相应的方法，值得注意的是ApplicationContextAware接口的setApplicationContext方法，再看一下invokeInitMethods源码 发现如果实现了InitializingBean接口，重写了afterPropertiesSet方法，则会调用afterPropertiesSet方法，最后还会调用是否指定了init-method，可以通过标签，或者@Bean注解的initMethod指定，最后再看一张applyBeanPostProcessorsAfterInitialization源码图 发现跟之前的postProcessBeforeInitialization方法类似，也是循环遍历实现了BeanPostProcessor的接口实现类，执行postProcessAfterInitialization方法。整个bean的生命执行流程就如上面截图所示，哪个接口的方法在哪里被调用，方法的执行流程 最后，对bean的生命流程进行一个流程图的总结 ","date":"2022-03-14","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/spring-%E4%B8%BA%E4%BD%95%E9%9C%80%E8%A6%81%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E8%80%8C%E4%B8%8D%E6%98%AF%E4%BA%8C%E7%BA%A7%E7%BC%93%E5%AD%98/:2:0","tags":["spring"],"title":"Spring 为何需要三级缓存解决循环依赖，而不是二级缓存？","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/spring-%E4%B8%BA%E4%BD%95%E9%9C%80%E8%A6%81%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E8%80%8C%E4%B8%8D%E6%98%AF%E4%BA%8C%E7%BA%A7%E7%BC%93%E5%AD%98/"},{"categories":["好文转载"],"content":"三级缓存解决循环依赖 上一小节对bean的生命周期做了一个整体的流程分析，对spring如何去解决循环依赖的很有帮助。前面我们分析到填充属性时，如果发现属性还未在spring中生成，则会跑去生成属性对象实例 我们可以看到填充属性的时候，spring会提前将已经实例化的bean通过ObjectFactory半成品暴露出去，为什么称为半成品是因为这时候的bean对象实例化，但是未进行属性填充，是一个不完整的bean实例对象 spring利用singletonObjects, earlySingletonObjects, singletonFactories三级缓存去解决的，所说的缓存其实也就是三个Map 可以看到三级缓存各自保存的对象，这里重点关注二级缓存earlySingletonObjects和三级缓存singletonFactory，一级缓存可以进行忽略。前面我们讲过先实例化的bean会通过ObjectFactory半成品提前暴露在三级缓存中 singletonFactory是传入的一个匿名内部类，调用ObjectFactory.getObject()最终会调用getEarlyBeanReference方法。再来看看循环依赖中是怎么拿其它半成品的实例对象的。 我们假设现在有这样的场景AService依赖BService，BService依赖AService AService首先实例化，实例化通过ObjectFactory半成品暴露在三级缓存中 填充属性BService，发现BService还未进行过加载，就会先去加载BService 再加载BService的过程中，实例化，也通过ObjectFactory半成品暴露在三级缓存 填充属性AService的时候，这时候能够从三级缓存中拿到半成品的ObjectFactory 拿到ObjectFactory对象后，调用ObjectFactory.getObject()方法最终会调用getEarlyBeanReference()方法，getEarlyBeanReference这个方法主要逻辑大概描述下如果bean被AOP切面代理则返回的是beanProxy对象，如果未被代理则返回的是原bean实例，这时我们会发现能够拿到bean实例(属性未填充)，然后从三级缓存移除，放到二级缓存earlySingletonObjects中，而此时B注入的是一个半成品的实例A对象，不过随着B初始化完成后，A会继续进行后续的初始化操作，最终B会注入的是一个完整的A实例，因为在内存中它们是同一个对象。下面是重点，我们发现这个二级缓存好像显得有点多余，好像可以去掉，只需要一级和三级缓存也可以做到解决循环依赖的问题？？？ 只要两个缓存确实可以做到解决循环依赖的问题，但是有一个前提这个bean没被AOP进行切面代理，如果这个bean被AOP进行了切面代理，那么只使用两个缓存是无法解决问题，下面来看一下bean被AOP进行了切面代理的场景 我们发现AService的testAopProxy被AOP代理了，看看传入的匿名内部类的getEarlyBeanReference返回的是什么对象 发现singletonFactory.getObject()返回的是一个AService的代理对象，还是被CGLIB代理的。再看一张再执行一遍singletonFactory.getObject()返回的是否是同一个AService的代理对象 我们会发现再执行一遍singleFactory.getObject()方法又是一个新的代理对象，这就会有问题了，因为AService是单例的，每次执行singleFactory.getObject()方法又会产生新的代理对象，假设这里只有一级和三级缓存的话，我每次从三级缓存中拿到singleFactory对象，执行getObject()方法又会产生新的代理对象，这是不行的，因为AService是单例的，所有这里我们要借助二级缓存来解决这个问题，将执行了singleFactory.getObject()产生的对象放到二级缓存中去，后面去二级缓存中拿，没必要再执行一遍singletonFactory.getObject()方法再产生一个新的代理对象，保证始终只有一个代理对象。还有一个注意的点 既然singleFactory.getObject()返回的是代理对象，那么注入的也应该是代理对象，我们可以看到注入的确实是经过CGLIB代理的AService对象。所以如果没有AOP的话确实可以两级缓存就可以解决循环依赖的问题，如果加上AOP，两级缓存是无法解决的，不可能每次执行singleFactory.getObject()方法都给我产生一个新的代理对象，所以还要借助另外一个缓存来保存产生的代理对象 ","date":"2022-03-14","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/spring-%E4%B8%BA%E4%BD%95%E9%9C%80%E8%A6%81%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E8%80%8C%E4%B8%8D%E6%98%AF%E4%BA%8C%E7%BA%A7%E7%BC%93%E5%AD%98/:3:0","tags":["spring"],"title":"Spring 为何需要三级缓存解决循环依赖，而不是二级缓存？","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/spring-%E4%B8%BA%E4%BD%95%E9%9C%80%E8%A6%81%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E8%80%8C%E4%B8%8D%E6%98%AF%E4%BA%8C%E7%BA%A7%E7%BC%93%E5%AD%98/"},{"categories":["好文转载"],"content":"总结 前面先讲到bean的加载流程，了解了bean加载流程对spring如何解决循环依赖的问题很有帮助，后面再分析到spring为什么需要利用到三级缓存解决循环依赖问题，而不是二级缓存。网上可以试试AOP的情形，实践一下就能明白二级缓存为什么解决不了AOP代理的场景了 在工作中，一直认为编程代码不是最重要的，重要的是在工作中所养成的编程思维。 原文地址：https://www.cnblogs.com/semi-sub/p/13548479.html ","date":"2022-03-14","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/spring-%E4%B8%BA%E4%BD%95%E9%9C%80%E8%A6%81%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E8%80%8C%E4%B8%8D%E6%98%AF%E4%BA%8C%E7%BA%A7%E7%BC%93%E5%AD%98/:4:0","tags":["spring"],"title":"Spring 为何需要三级缓存解决循环依赖，而不是二级缓存？","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/spring-%E4%B8%BA%E4%BD%95%E9%9C%80%E8%A6%81%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E8%80%8C%E4%B8%8D%E6%98%AF%E4%BA%8C%E7%BA%A7%E7%BC%93%E5%AD%98/"},{"categories":["技术笔记"],"content":"快排基本思想 先从数组中找一个基准数 将其他比它小的元素移动到左边，比它大的元素移动到右边，从而把数组拆分成两个部分 再对左右区间重复第二部，直到各区间只有一个数为止 ","date":"2022-02-20","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E6%80%BB%E7%BB%93/:1:0","tags":["数据结构与算法"],"title":"快速排序总结","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E6%80%BB%E7%BB%93/"},{"categories":["技术笔记"],"content":"快排实现–双指针： class Solution { public int[] sortArray(int[] nums) { quickSort(nums, 0, nums.length-1); return nums; } public void quickSort(int[] nums, int low, int hight) { if (low \u003c hight) { int index = partition(nums, low, hight); quickSort(nums, low, index - 1); quickSort(nums, index + 1, hight); } } public int partition(int[] nums, int low, int hight) { int pivot = nums[low]; int start = low; while (low \u003c hight) { //一定要先右边 while (low \u003c hight \u0026\u0026 nums[hight] \u003e= pivot) hight--; while (low \u003c hight \u0026\u0026 nums[low] \u003c= pivot) low++; swap(nums, low, hight); } swap(nums, start, low); return low; } public void swap(int[] nums, int i, int j) { int temp = nums[i]; nums[i] = nums[j]; nums[j] = temp; } } ","date":"2022-02-20","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E6%80%BB%E7%BB%93/:2:0","tags":["数据结构与算法"],"title":"快速排序总结","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E6%80%BB%E7%BB%93/"},{"categories":["技术笔记"],"content":"快排复杂度分析 最好时间复杂度：$O(nlogn)$ 最坏时间复杂度：$O(n^2)$ 平均时间复杂度：$O(nlogn)$ 最好空间复杂度：$O(logn)$ 最坏空间复杂度：$O(n)$ 平均空间复杂度：$O(logn)$ 是否稳定：不稳定 ","date":"2022-02-20","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E6%80%BB%E7%BB%93/:3:0","tags":["数据结构与算法"],"title":"快速排序总结","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E6%80%BB%E7%BB%93/"},{"categories":["技术笔记"],"content":"快排迭代写法–借助栈 class Solution { public int[] sortArray(int[] nums) { Stack\u003cInteger\u003e stack = new Stack\u003c\u003e(); stack.push(nums.length - 1); stack.push(0); while (!stack.isEmpty()) { int low = stack.pop(); int hight = stack.pop(); if (low \u003c hight) { int index = partition(nums, low, hight); stack.push(index - 1); stack.push(low); stack.push(hight); stack.push(index + 1); } } return nums; } public int partition (int[] nums, int low, int hight) { int pivot = nums[low]; int start = low; while (low \u003c hight) { while (low \u003c hight \u0026\u0026 nums[hight] \u003e= pivot) hight--; while (low \u003c hight \u0026\u0026 nums[low] \u003c= pivot) low++; if (low \u003e= hight) break; swap(nums, low, hight); } swap(nums,start,low); return low; } public void swap (int[] nums, int i, int j) { int temp = nums[i]; nums[i] = nums[j]; nums[j] = temp; } } ","date":"2022-02-20","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E6%80%BB%E7%BB%93/:4:0","tags":["数据结构与算法"],"title":"快速排序总结","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E6%80%BB%E7%BB%93/"},{"categories":["技术笔记"],"content":"快排和归并比较 快排和归并排序都用到了分治思想。 但归并排序是自下到上的，先处理子问题，然后再合并。 快速排序是由上到下的，先分区，然后再处理子问题。 归并排序是稳定的、时间复杂度为$O(nlogn)$的排序算法，但它是非原地排序算法，因为合并函数需要利用辅助数组保存元素。 快排通过原地分区函数，可以实现原地排序，解决了归并排序占用太多内存的问题。 原地排序就是指在排序过程中不申请多余的存储空间，只利用原来存储待排数据的存储空间进行比较和交换的数据排序。 ","date":"2022-02-20","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E6%80%BB%E7%BB%93/:5:0","tags":["数据结构与算法"],"title":"快速排序总结","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E6%80%BB%E7%BB%93/"},{"categories":["技术笔记"],"content":"快排优化 ","date":"2022-02-20","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E6%80%BB%E7%BB%93/:6:0","tags":["数据结构与算法"],"title":"快速排序总结","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E6%80%BB%E7%BB%93/"},{"categories":["技术笔记"],"content":"三数取中法 我们常选nums[low]作为基准值，当面对特殊情况，如数组为正序或逆序时，我们则需要递归调用n-1次，每次只交换了一个元素。因此我们要尽量避免选取序列的最大值或最小值作为基准值。 因此采用三数取中法，选取3个元素中的中间值放到nums[low]，作为基准值。 只需加上： int mid = low + hight \u003e\u003e\u003e 1; if (nums[low] \u003e nums[hight]) swap(nums, low, hight); if (nums[mid] \u003e nums[hight]) swap(nums, mid ,hight); if (nums[mid] \u003e nums[low]) swap(nums, mid, low); class Solution { public int[] sortArray(int[] nums) { quickSort(nums,0,nums.length-1); return nums; } public void quickSort (int[] nums, int low, int hight) { if (low \u003c hight) { int index = partition(nums,low,hight); quickSort(nums,low,index-1); quickSort(nums,index+1,hight); } } public int partition (int[] nums, int low, int hight) { //三数取中，大家也可以使用其他方法 int mid = low + ((hight-low) \u003e\u003e 1); if (nums[low] \u003e nums[hight]) swap(nums,low,hight); if (nums[mid] \u003e nums[hight]) swap(nums,mid,hight); if (nums[mid] \u003e nums[low]) swap(nums,mid,low); //下面和之前一样，仅仅是多了上面几行代码 int pivot = nums[low]; int start = low; while (low \u003c hight) { while (low \u003c hight \u0026\u0026 nums[hight] \u003e= pivot) hight--; while (low \u003c hight \u0026\u0026 nums[low] \u003c= pivot) low++; if (low \u003e= hight) break; swap(nums, low, hight); } swap(nums,start,low); return low; } public void swap (int[] nums, int i, int j) { int temp = nums[i]; nums[i] = nums[j]; nums[j] = temp; } } ","date":"2022-02-20","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E6%80%BB%E7%BB%93/:6:1","tags":["数据结构与算法"],"title":"快速排序总结","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E6%80%BB%E7%BB%93/"},{"categories":["技术笔记"],"content":"和插入排序搭配使用 插入排序在元素个数少时效率最高，比快速排序还快。 所以可以设置一个阈值，当元素个数大于阈值时使用快排，小于阈值时用插入排序。这里阈值设置为7。 class Solution { private static final int INSERTION_SORT_MAX_LENGTH = 7; public int[] sortArray(int[] nums) { quickSort(nums,0,nums.length-1); return nums; } public void quickSort (int[] nums, int low, int hight) { if (hight - low \u003c= INSERTION_SORT_MAX_LENGTH) { insertSort(nums,low,hight); return; } int index = partition(nums,low,hight); quickSort(nums,low,index-1); quickSort(nums,index+1,hight); } public int partition (int[] nums, int low, int hight) { //三数取中，大家也可以使用其他方法 int mid = low + ((hight-low) \u003e\u003e 1); if (nums[low] \u003e nums[hight]) swap(nums,low,hight); if (nums[mid] \u003e nums[hight]) swap(nums,mid,hight); if (nums[mid] \u003e nums[low]) swap(nums,mid,low); int pivot = nums[low]; int start = low; while (low \u003c hight) { while (low \u003c hight \u0026\u0026 nums[hight] \u003e= pivot) hight--; while (low \u003c hight \u0026\u0026 nums[low] \u003c= pivot) low++; if (low \u003e= hight) break; swap(nums, low, hight); } swap(nums,start,low); return low; } public void insertSort (int[] nums, int low, int hight) { for (int i = low + 1; i \u003c= hight; i++) { int temp = nums[i]; int j; for (j = i - 1; j \u003e= 0; j--) { if (temp \u003c nums[j]) { nums[j+1] = nums[j]; continue; } break; } nums[j+1] = temp; } } public void swap (int[] nums, int i, int j) { int temp = nums[i]; nums[i] = nums[j]; nums[j] = temp; } } ","date":"2022-02-20","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E6%80%BB%E7%BB%93/:6:2","tags":["数据结构与算法"],"title":"快速排序总结","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E6%80%BB%E7%BB%93/"},{"categories":["技术笔记"],"content":"针对重复元素多的情况：三向切分（三路快排） 将相同元素放到一起呢，大大减小递归调用时的区间大小。 class Solution { private static final int INSERTION_SORT_MAX_LENGTH = 7; public int[] sortArray(int[] nums) { quickSort(nums,0,nums.length-1); return nums; } public void quickSort(int nums[], int low, int hight) { //插入排序 if (hight - low \u003c= INSERTION_SORT_MAX_LENGTH) { insertSort(nums,low,hight); return; } //三数取中 int mid = low + ((hight-low) \u003e\u003e 1); if (nums[low] \u003e nums[hight]) swap(nums,low,hight); if (nums[mid] \u003e nums[hight]) swap(nums,mid,hight); if (nums[mid] \u003e nums[low]) swap(nums,mid,low); //三向切分 int left = low, i = low + 1, right = hight; int pvoit = nums[low]; while (i \u003c= right) { if (pvoit \u003c nums[i]) { swap(nums,i,right); right--; } else if (pvoit == nums[i]) { i++; } else { swap(nums,left,i); left++; i++; } } quickSort(nums,low,left-1); quickSort(nums,right+1,hight); } public void insertSort (int[] nums, int low, int hight) { for (int i = low+1; i \u003c= hight; ++i) { int temp = nums[i]; int j; for (j = i-1; j \u003e= 0; --j) { if (temp \u003c nums[j]) { nums[j+1] = nums[j]; continue; } break; } nums[j+1] = temp; } } public void swap (int[] nums, int i, int j) { int temp = nums[i]; nums[i] = nums[j]; nums[j] = temp; } } 利用探路指针也就是 i，遇到比 pivot 大的元素，则和 right 指针进行交换，交换后 right 指向的元素肯定比 pivot 大，则 right–，但是，此时我们的 nums[i] 指向的元素并不知道情况，所以我们的 i 指针先不动，继续判断。 如果此时 nums[i] \u003c pivot 则与 left 指针交换，注意此时我们的 left 指向的值肯定是等于 povit的，所以交换后我们要 left++,i++, nums[i] == pivot 时，仅需要 i++ 即可，继续判断下一个元素。我们也可以借助这个思想来解决经典的荷兰国旗问题。 ","date":"2022-02-20","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E6%80%BB%E7%BB%93/:6:3","tags":["数据结构与算法"],"title":"快速排序总结","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E6%80%BB%E7%BB%93/"},{"categories":["技术笔记"],"content":"双轴快排 JDK里的Arrays.sort()主要使用。 双轴就是选取两个主元素理想将区间划为3部分，这样不仅每次能够确定元素个数增多为2个，划分的区间由原来的两个变成三个，最坏的情况就是左右同大小并且都是最大或者最小，但这样的概率相比一个最大或者最小还是低很多，所以双轴快排的优化力度还是挺大的。 public class 双轴快排 { public static void main(String[] args) { int a[]= {7,3,5,4,8,5,6,55,4,333,44,7,885,23,6,44}; dualPivotQuickSort(a,0,a.length-1); } private static void dualPivotQuickSort(int[] arr, int start, int end) { if(start\u003eend)return;//参数不对直接返回 if(arr[start]\u003earr[end]) swap(arr, start, end); int pivot1=arr[start],pivot2=arr[end];//储存最左侧和最右侧的值 //(start，left]:左侧小于等于pivot1 [right,end)大于pivot2 int left=start,right=end,k=left+1; while (k\u003cright) { //和左侧交换 if(arr[k]\u003c=pivot1) { //需要交换 swap(arr, ++left, k++); } else if (arr[k]\u003c=pivot2) {//在中间的情况 k++; } else { while (arr[right]\u003e=pivot2) {//如果全部小于直接跳出外层循环 if(right--==k) break ; } if(k\u003e=right)break ; swap(arr, k, right); } } swap(arr, start, left); swap(arr, end, right); dualPivotQuickSort(arr, start, left-1); dualPivotQuickSort(arr, left+1, right-1); dualPivotQuickSort(arr, right+1, end); } static void swap(int arr[],int i,int j) { int team=arr[i]; arr[i]=arr[j]; arr[j]=team; } } ","date":"2022-02-20","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E6%80%BB%E7%BB%93/:6:4","tags":["数据结构与算法"],"title":"快速排序总结","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E6%80%BB%E7%BB%93/"},{"categories":["技术笔记"],"content":"关于实现稳定的快排 可以在partition函数中保持了原序列中所有元素的相对顺序，只把pivot放到了它的正确位置。具体方法是三遍扫描原序列： 第一遍先把小于pivot的元素按先后顺序放到tmp里，然后把pivot放到它的正确位置tmp[k]； 第二遍把大于pivot的元素按先后顺序追加在tmp里，这样除了pivot以前的其他元素，都保持了和原序列中一样的顺序； 第三遍把tmp赋值回原数组A。 虽然这种快排的时间复杂度还是$O(nlogn)$，但在partition方法中扫描了3次数组，并且借用了辅助函数，因此不再是in-place排序算法，所以排序时会比常规快排和归并排序更慢，没什么必要。 ","date":"2022-02-20","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E6%80%BB%E7%BB%93/:6:5","tags":["数据结构与算法"],"title":"快速排序总结","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E6%80%BB%E7%BB%93/"},{"categories":["生活"],"content":"促音（そくおん sokuon），是在日语中用来表示停顿的符号，写法为っ、片假名ッ。促音“っ”是“つ”的缩小版本，但2个假名的关系只是外型相似，在发音上是完全没有关系的。促音“っ”本身没有发音，但当生字中含有促音时，促音却会占一拍，例如“さき（先）”是有2个音节共2拍，输入了促音后变成“さっき（刚才）”，音节不变同样是2节，但就会变成3拍。 ","date":"2022-02-18","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E6%97%A5%E8%AF%AD-%E4%BF%83%E9%9F%B3/:0:0","tags":["日语"],"title":"日语-促音","uri":"/posts/%E7%94%9F%E6%B4%BB/%E6%97%A5%E8%AF%AD-%E4%BF%83%E9%9F%B3/"},{"categories":["生活"],"content":"发音 促音っ只出现在か行、さ行、た行、ぱ(半浊音)行前面。 在促音っ后面连接か行（か、き、く、け、こ）的时候，以 k 的发音方法顿挫一拍（只做口型不出声）。 いっかい「ikkai」一层 がっき「gakki」乐器 はっけん「hakken」发现　いっこ「ikko」一个 在促音っ后面连接ぱ行（ぱ、ぴ、ぷ、ぺ、ぽ）的时候，以 p 的发音方法顿挫一拍。 いっぱい「ippai」满满的　いっぴき「ippiki」一匹 きっぷ「kippu」票　しっぽ「shippo」尾巴 在促音っ后面连接さ行（さ、し、す、せ、そ）或た行（た、ち、つ、て、と）的时候，以 s 或 t 的发音方法顿挫一拍。 いっさい「issai」1岁　ざっし「zasshi」杂志 けっせき「kesseki」缺席 さっそく「sassoku」立刻　きって「kitte」邮票　おっと「otto」丈夫 ","date":"2022-02-18","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E6%97%A5%E8%AF%AD-%E4%BF%83%E9%9F%B3/:1:0","tags":["日语"],"title":"日语-促音","uri":"/posts/%E7%94%9F%E6%B4%BB/%E6%97%A5%E8%AF%AD-%E4%BF%83%E9%9F%B3/"},{"categories":["生活"],"content":"输入法输入 在电脑打字时，若要单独输入促音“っ”，可输入xtu，ltu，ltsu。 和其它假名一同输入：重复下一个假名的子音。例如打“sa”输入“さ”，与及打“ki”输入“き”，会出现“さき”，如要打“さっき”，则只需在打完“sa”后，连续打“k”2次，变成“kki”，电脑就会自动在“き”前插入一个促音。 ","date":"2022-02-18","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E6%97%A5%E8%AF%AD-%E4%BF%83%E9%9F%B3/:2:0","tags":["日语"],"title":"日语-促音","uri":"/posts/%E7%94%9F%E6%B4%BB/%E6%97%A5%E8%AF%AD-%E4%BF%83%E9%9F%B3/"},{"categories":["技术笔记"],"content":"IP 网络层（IP）的主要作用是：实现主机与主机之间的通信，点到点（end to end）的通信。 数据链路层（MAC）的作用是实现直连的两个设备之间通信，网络层（IP）则负责在没有直连的两个网络之间通信。 源IP地址和目标IP地址在传输过程中是不变的，源MAC地址和目标MAC一直在变化。 IP地址并不是根据主机数量来分配的，而是根据网卡。像服务器、路由器等设备都是有2个以上的网卡，就会有2个以上的IP地址。 ","date":"2022-01-11","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/ip%E5%B1%82%E6%A6%82%E8%BF%B0/:0:0","tags":["计算机网络"],"title":"IP层概述","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/ip%E5%B1%82%E6%A6%82%E8%BF%B0/"},{"categories":["技术笔记"],"content":"IP地址的分类 ","date":"2022-01-11","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/ip%E5%B1%82%E6%A6%82%E8%BF%B0/:1:0","tags":["计算机网络"],"title":"IP层概述","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/ip%E5%B1%82%E6%A6%82%E8%BF%B0/"},{"categories":["技术笔记"],"content":"分类地址 最开始是分类地址，分类A、B、C、D、E五类。 A、B、C类，分为网络号加主机号。 D类为组播（多播）地址。用于将包发送给塔顶组内的所有主机。由于广播无法穿透路由，若想给其他网段发送同样的包，就可以使用穿透路由的组播。 E类为备用。 主机号全为1指定某个网络下的所有主机，用于广播。 主机号全为0指定某个网络。 广播地址分为： 本地广播：在本网络内的广播 直接广播：在不同网络之间的广播 分类地址的优点：简单明了、选路简单。 分类地址的缺点：同一网络下没有地址层次，不够灵活。不能很好的与需求匹配。 ","date":"2022-01-11","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/ip%E5%B1%82%E6%A6%82%E8%BF%B0/:1:1","tags":["计算机网络"],"title":"IP层概述","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/ip%E5%B1%82%E6%A6%82%E8%BF%B0/"},{"categories":["技术笔记"],"content":"CIDR无分类地址 CIDR无分类地址可以解决分类地址的问题。 CIDR无分类地址将32比特的IP地址分为两部分，网络号+主机号。 表示形式a.b.c.d/x，/x表示前面x位是网络号。 还有另一种划分网络号和主机号的方式，使用子网掩码。子网掩码还有一个作用，就是划分子网。将主机号分为：子网网络地址+子网主机地址。 为什么要分离网络号和主机号？ 因为两台计算机要通讯，首先要判断是否处于同一个广播域内，即网络号是否相同。如果相同，可以直接把数据报发送到目标主机。 IP地址的网络地址是用于进行路由控制的。 路由控制表记中记录着网络地址与下一步应该发送至路由器的地址。主机和路由器都有各自的路由控制表。 如果路由控制表中有多条相同的网络地址记录，选择相同位数最多的网络地址，即最长匹配。 计算机使用一个特殊的IP地址 127.0.0.1作为环回地址。与该地址具有相同意义的主机名是localhost。使用这个IP或主机名时，数据包不会流向网络。 经过分片后的IP数据报在被重组时，只能由目标主机进行，路由器是不会进行重组的。 在分片传输中，一旦某个分片丢失，则会造成整个IP数据报作为，所以TCP引入了MSS也就是在TCP进行分片不由IP分片。而对于UDP我们尽量不要发送一个大于MTU的数据报文。 ","date":"2022-01-11","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/ip%E5%B1%82%E6%A6%82%E8%BF%B0/:1:2","tags":["计算机网络"],"title":"IP层概述","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/ip%E5%B1%82%E6%A6%82%E8%BF%B0/"},{"categories":["技术笔记"],"content":"IPv6 IPv4是32位的。 IPv6是128位的。以每16位一组，每组用冒号:隔开。常用16进制表示。 IPv4和IPv6不能相互兼容。 IPv6优点： 可自动配置，几时没有DHCP服务器也可以实现自动分配IP。 首部采用固定值40字节，去掉了校验和，简化了首部结构。 安全性提升。有对应伪造IP地址的网络安全功能以及防止线路窃听的功能。 ","date":"2022-01-11","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/ip%E5%B1%82%E6%A6%82%E8%BF%B0/:2:0","tags":["计算机网络"],"title":"IP层概述","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/ip%E5%B1%82%E6%A6%82%E8%BF%B0/"},{"categories":["技术笔记"],"content":"DNS DNS域名解析，将域名转化为IP地址。 在域名中，越靠右的表示层级越高。 域名层级： 根DNS服务器 顶级域DNS服务器（com） 权威DNS服务器（server.com） 域名解析工作流程： 流浪器首先看自己的缓存里有没有，没有就向操作系统的缓存要，还有没就检查本地域名解析文件hosts，还没有就想DNS服务器进行查询。 客户端发送一个DNS请求，先发给本地DNS服务器（客户端的TCP/IP设置中填写的DNS服务器地址）。 本地域名服务器收到客户端请求后，如果缓存中有，就直接返回IP。如有没，本地DNS会向根域名服务器询问。 根会告知客户端是属于哪个顶级域名服务器。 本地DNS收到顶级域名服务器地址后，向其发起请求。 顶级域名服务器会告知属于哪个权威DNS服务器。 本地DNS向权威DNS服务器询问，得到IP地址。 本地DNS将IP地址返回给客户端。 ","date":"2022-01-11","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/ip%E5%B1%82%E6%A6%82%E8%BF%B0/:3:0","tags":["计算机网络"],"title":"IP层概述","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/ip%E5%B1%82%E6%A6%82%E8%BF%B0/"},{"categories":["技术笔记"],"content":"ARP 由IP地址得到MAC地址。 借助ARP请求（发送广播询问）与ARP响应确定MAC地址。 ","date":"2022-01-11","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/ip%E5%B1%82%E6%A6%82%E8%BF%B0/:4:0","tags":["计算机网络"],"title":"IP层概述","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/ip%E5%B1%82%E6%A6%82%E8%BF%B0/"},{"categories":["技术笔记"],"content":"RARP 由MAC地址得到IP地址。 ","date":"2022-01-11","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/ip%E5%B1%82%E6%A6%82%E8%BF%B0/:5:0","tags":["计算机网络"],"title":"IP层概述","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/ip%E5%B1%82%E6%A6%82%E8%BF%B0/"},{"categories":["技术笔记"],"content":"DHCP 动态获取IP地址，省去了配IP的繁琐过程。 DHCP的交互中，全程都是使用UDP广播通信。 ","date":"2022-01-11","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/ip%E5%B1%82%E6%A6%82%E8%BF%B0/:6:0","tags":["计算机网络"],"title":"IP层概述","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/ip%E5%B1%82%E6%A6%82%E8%BF%B0/"},{"categories":["技术笔记"],"content":"NAT 为了缓解IPv4地址空间不足的情况。通过NAT网络地址转换，将公网IP和私网IP进行转换。 由于大多数网络应用都是使用TCP或UDP传输，因此可以IP地址+端口号一起进行转换，这种转换技术叫网络地址与端口转换NAPT。 使用IPv6的话就不用使用NAT了。 NAT穿透技术：客户端主动从NAT设备获取公有IP地址，然后自己建立端口映射条目，然后用这个条目对外通信，就不需要NAT设备来进行转换了。 ","date":"2022-01-11","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/ip%E5%B1%82%E6%A6%82%E8%BF%B0/:7:0","tags":["计算机网络"],"title":"IP层概述","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/ip%E5%B1%82%E6%A6%82%E8%BF%B0/"},{"categories":["技术笔记"],"content":"ICMP ICMP Internet Control Message Protocal，互联网控制报文协议。 ICMP报文是封装在IP包里，工作在网络层。 ICMP分为两类： 查询报文类型：用于诊断的查询信息。eg：ping。 差错报文类型：通知出错原因的错误信息。eg：tracerouter。 ","date":"2022-01-11","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/ip%E5%B1%82%E6%A6%82%E8%BF%B0/:8:0","tags":["计算机网络"],"title":"IP层概述","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/ip%E5%B1%82%E6%A6%82%E8%BF%B0/"},{"categories":["技术笔记"],"content":"IGMP IGMP是因特网组管理协议，工作在主机（组播成员）和最后一跳路由之间。 ","date":"2022-01-11","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/ip%E5%B1%82%E6%A6%82%E8%BF%B0/:9:0","tags":["计算机网络"],"title":"IP层概述","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/ip%E5%B1%82%E6%A6%82%E8%BF%B0/"},{"categories":["技术笔记"],"content":"TCP三次握手 三次握手建立连接。 一开始客户端和服务端都处于CLOSED状态，服务端主动监听某个端口，处于LISTEN状态。 第一次握手，客户端随机初始化序列号，然后将 SYN标志位置1，发送SYN报文。之后客户端处于 SYN-SENT状态。 第二次握手，服务端收到 SYN 报文，初始化自己的序列号，然后将确认应答号设置为收到的序列号+1，将SYN 和 ACK标志位置位1，发送给客户端。之后服务端处于 SYN-RCVD 状态。 第三次握手，客户端向服务端发送应答报文，将 ACK标志位设置为1，确认应答号设置为收到的序列号+1。之后客户端处于 ESTABLISHED 状态。 服务端收到应答报文后，也进入 ESTABLISHED 状态。 其中，只有第三次握手是可以携带数据的，前两次不行。 ","date":"2022-01-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/tcp%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/:1:0","tags":["计算机网络"],"title":"TCP三次握手\u0026四次挥手","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/tcp%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/"},{"categories":["技术笔记"],"content":"Linux如何看连接状态 netstat -napt ","date":"2022-01-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/tcp%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/:1:1","tags":["计算机网络"],"title":"TCP三次握手\u0026四次挥手","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/tcp%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/"},{"categories":["技术笔记"],"content":"为什么是3次，不是2次、4次 为什么三次握⼿才可以初始化Socket、序列号和窗⼝⼤⼩并建⽴ TCP 连接。 原因在于： 三次握手可以防止旧的重复连接被初始化造成混乱（主要原因） 当网络阻塞时，如果客户端连续发送了多次SYN建立连接的报文，当一个旧的SYN报文比最新的SYN报文早到了服务端，那此时服务端就会回一个 SYN+ACK 报文给客户端。客户端可以根据自身的上下文，判断你这是一个历史连接（序列号过期或超时），那么客户端就会发送 RST 报文给服务端，中止这一次连接。 如果是两次握手连接，就不能判断当前连接是否是历史连接（是不是自己需要的），三次握手则可以再客户端（发送方）准备发送第三次报文时，去进行判断（发送ACK 或 RST） 三次握手可以同步双方的初始化序列 TCP协议通信的双方，都必须要维护一个序列号，序列号是可靠传输的关键因素，作用在于： 接收方可以去除重复的数据。 接收方可以根据数据包的序列号按序接收。 可以标识发送出去的数据包中，哪些是已经被对方收到的。 发送一个SYN报文，需要回一个ACK应答报文。四次握手服务端ACK报文和SYN报文可以合并成一步，故三次握手就够了。 三次握手可以避免资源浪费。 如果只有两次握手，当客户端SYN请求连接网络阻塞时，客户端没有收到 ACK报文，就会重新发送SYN，但服务端并不清楚客户端是否接受到ACK，所以每收到一个SYN就只能先主动建立一个连接，会导致建立了多个冗余的无效连接，造成资源浪费。 总结： TCP建立连接时，通过三次握手能防止历史连接的建立，能减少不必要的资源开销，能保证双方同步初始化序列号。 序列号能保证数据包不重复、不丢失和按序传输。 两次握手：无法阻止历史连接的建立，会造成双方资源的浪费，无法可靠的同步双方序列号。 四次握手：三次握手就可以建立可靠的连接，因此不需要更多的通信次数。 ","date":"2022-01-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/tcp%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/:1:2","tags":["计算机网络"],"title":"TCP三次握手\u0026四次挥手","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/tcp%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/"},{"categories":["技术笔记"],"content":"为什么初始序列号是不同的？ 如果一个已经失效的连接被重用了，但就连接的历史报文还残留在网络中，如果序列号相同，就无法分辨是不是历史报文，如果历史报文被新连接接受了，会产生数据混乱。 为了安全性，防止黑客伪造相同的序列号的TCP报文被对方接收。 ","date":"2022-01-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/tcp%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/:1:3","tags":["计算机网络"],"title":"TCP三次握手\u0026四次挥手","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/tcp%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/"},{"categories":["技术笔记"],"content":"既然IP层会分片，为什么TCP层还需要MSS？ ","date":"2022-01-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/tcp%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/:1:4","tags":["计算机网络"],"title":"TCP三次握手\u0026四次挥手","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/tcp%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/"},{"categories":["技术笔记"],"content":"什么SYN攻击，如何避免？ SYN攻击是指伪造不同IP地址的SYN报文，当服务端接受到一个SYN报文时，会发送ACK+SYN报文，进入SYN_RCVD状态，然而得不到未知IP主机的ACK，会把服务端SYN接受队列（未连接队列）占满。 （应用程序处理过慢的话，则会导致Accept队列被占满） 正常流程： 当服务端接收到客户端的 SYN 报⽂时，会将其加⼊到内核的「 SYN 队列」； 接着发送 SYN + ACK 给客户端，等待客户端回应 ACK 报⽂； 服务端接收到 ACK 报⽂后，从「 SYN 队列」移除放⼊到「 Accept 队列」； 应⽤通过调⽤ accpet() socket 接⼝，从「 Accept 队列」取出连接。 避免方法： 修改linux内核参数，控制队列大小和队列满时应做什么操作。 tcp_syncookies方式。但SYN队列满时，后序SYN包不进入队列，直接计算出一个SYN cookie返回客户端。 ","date":"2022-01-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/tcp%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/:1:5","tags":["计算机网络"],"title":"TCP三次握手\u0026四次挥手","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/tcp%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/"},{"categories":["技术笔记"],"content":"TCP四次挥手 客户端准备关闭连接，发送一个TCP首部 FIN 标记为为1的报文，即 FIN 报文，之后客户端进入 FIN_WAIT_1 状态。 服务端收到报文后，向客户端发送 ACK 应答报文，之后服务端进入 CLOSED_WAIT 状态。 客户端收到 ACK 报文，之后进入 FIN_WAIT_2 状态。 服务端处理完数据后，向客户端发送 FIN 报文，之后服务端进入 LAST_ACK 状态。 客户端收到 FIN报文后，回一个 ACK 报文，之后客户端进入 TIME_WAIT 状态。 服务端收到ACK报文后，就进入了 CLOSED状态，服务端已经完成连接的关闭。 客户端在经过 2MSL 时间后，进入 CLOSED 状态，客户端也完成连接的关闭。 每个方向都需要一个 FIN 和一个 ACK，因此称为四次挥手。 主动关闭连接的，才有 TIME_WAIT状态。 ","date":"2022-01-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/tcp%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/:2:0","tags":["计算机网络"],"title":"TCP三次握手\u0026四次挥手","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/tcp%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/"},{"categories":["技术笔记"],"content":"为什么是四次挥手？ 关闭连接时，客户端发送FIN报文，仅表示客户端不再发送数据了，但还可以接受数据。 服务端收到 FIN，先回一个ACK，但服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送FIN给客户端，表示开始关闭。 ","date":"2022-01-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/tcp%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/:2:1","tags":["计算机网络"],"title":"TCP三次握手\u0026四次挥手","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/tcp%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/"},{"categories":["技术笔记"],"content":"为什么要TIME_WAIT要等到2MSL？ MSL（Maximum Segment Lifetime），即报文最大生存时间，是任何报文在网络上存在的最长时间，超过这个时间的报文将被丢弃。 IP头有一个 TTL字段，表示IP数据报可以经过的最大路有数，每经过一个处理它的路由此值就减1，当此值为0时数据被丢弃，同时发送ICMP报文通知源主机。 TIME_WAIT等待2倍的MSL，是因为网络中可能存在来自发送方的数据包，当这些数据包被接收后又会收到响应，2MSL可以保证两个方向上的所有数据包都被处理或被丢弃。 比如被动关闭方没有收到断开连接的最后的ACK报文，就会触发超时重发FIN报文，另一方接收到FIN后，会重发ACK给被动关闭方，一来一回正好2MSL。 Linux里2MSL默认是60秒。 ","date":"2022-01-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/tcp%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/:2:2","tags":["计算机网络"],"title":"TCP三次握手\u0026四次挥手","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/tcp%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/"},{"categories":["技术笔记"],"content":"TIME_WAIT状态的过多有什么危害？ 占用内存资源 占用端口资源，一个TCP连接至少消耗一个本地端口。一般可以开启的端口为 32768~61000. ","date":"2022-01-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/tcp%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/:2:3","tags":["计算机网络"],"title":"TCP三次握手\u0026四次挥手","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/tcp%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/"},{"categories":["技术笔记"],"content":"如何优化TIME_WAIT？ 打开 net.ipv4.tcp_tw_reuse 和 net.ipv4.tcp_timestamps 选项； 可以复⽤处于 TIME_WAIT 的 socket 为新的连接所⽤。 ","date":"2022-01-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/tcp%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/:2:4","tags":["计算机网络"],"title":"TCP三次握手\u0026四次挥手","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/tcp%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/"},{"categories":["技术笔记"],"content":"已经建立了连接，但客户端突然故障了怎么办？ TCP 有⼀个机制是保活机制。原理如下： 定义⼀个时间段，在这个时间段内，如果没有任何连接相关的活动， TCP 保活机制会开始作⽤，每隔⼀个时间间 隔，发送⼀个探测报⽂，该探测报⽂包含的数据⾮常少，如果连续⼏个探测报⽂都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应⽤程序。 net.ipv4.tcp_keepalive_time=7200 //表示保活时间是 7200 秒（2⼩时），也就 2 ⼩时内如果没有任何连接相关的活 动，则会启动保活机制 net.ipv4.tcp_keepalive_intvl=75 //表示每次检测间隔 75 秒 net.ipv4.tcp_keepalive_probes=9 //表示检测 9 次⽆响应，认为对⽅是不可达的，从⽽中断本次的连接。 ","date":"2022-01-09","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/tcp%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/:2:5","tags":["计算机网络"],"title":"TCP三次握手\u0026四次挥手","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/tcp%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/"},{"categories":["技术笔记"],"content":"http各版本结构 ","date":"2022-01-05","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/http%E7%89%88%E6%9C%AC%E6%BC%94%E8%BF%9B/:1:0","tags":["计算机网络"],"title":"HTTP版本演进","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/http%E7%89%88%E6%9C%AC%E6%BC%94%E8%BF%9B/"},{"categories":["技术笔记"],"content":"http/1.1 ","date":"2022-01-05","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/http%E7%89%88%E6%9C%AC%E6%BC%94%E8%BF%9B/:2:0","tags":["计算机网络"],"title":"HTTP版本演进","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/http%E7%89%88%E6%9C%AC%E6%BC%94%E8%BF%9B/"},{"categories":["技术笔记"],"content":"http/1.1的优点 简单 灵活易扩展 应用广泛和跨平台 ","date":"2022-01-05","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/http%E7%89%88%E6%9C%AC%E6%BC%94%E8%BF%9B/:2:1","tags":["计算机网络"],"title":"HTTP版本演进","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/http%E7%89%88%E6%9C%AC%E6%BC%94%E8%BF%9B/"},{"categories":["技术笔记"],"content":"http/1.1缺点 无状态【双刃剑】。简单解决方案：cookie 明文传输【双刃剑】 不安全 通信使用明文，内容可能会被窃听【窃听】 不验证通信方的身份，可能遭遇伪装【冒充】 无法证明报文的完整性，可能已遭篡改【篡改】 ","date":"2022-01-05","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/http%E7%89%88%E6%9C%AC%E6%BC%94%E8%BF%9B/:2:2","tags":["计算机网络"],"title":"HTTP版本演进","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/http%E7%89%88%E6%9C%AC%E6%BC%94%E8%BF%9B/"},{"categories":["技术笔记"],"content":"对比http/1.0 和 http/1.1 http/1.1 相对 http/1.0 的改进： 使用TCP长连接的方式改善了 http/1.0 短连接造成的性能开销。http1.0对每个请求都要新建TCP连接。 支持管道（pipeline）网络传输，允许浏览器同时发送多个请求，但服务器还是要按顺序返回。可减少整体的响应时间。 但http/1.1还有的性能瓶颈有： 请求/响应头部（Header）未经压缩就发送，首部信息越多延迟越大，只能压缩 Body 的部分。 发送冗长的首部。每次相互发送相同的首部造成的浪费较多。 服务器是按请求顺序响应的，如果服务器响应慢，会导致客户端一直请求不到数据，即队头阻塞。 有没请求优先级控制。 请求只能从客户端开始，服务器只能被动响应。 ","date":"2022-01-05","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/http%E7%89%88%E6%9C%AC%E6%BC%94%E8%BF%9B/:2:3","tags":["计算机网络"],"title":"HTTP版本演进","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/http%E7%89%88%E6%9C%AC%E6%BC%94%E8%BF%9B/"},{"categories":["技术笔记"],"content":"https ","date":"2022-01-05","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/http%E7%89%88%E6%9C%AC%E6%BC%94%E8%BF%9B/:3:0","tags":["计算机网络"],"title":"HTTP版本演进","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/http%E7%89%88%E6%9C%AC%E6%BC%94%E8%BF%9B/"},{"categories":["技术笔记"],"content":"https解决的http问题 窃听风险：信息加密，混合加密 在通信建立前采用非对称加密的方式交换【会话密钥】。 在通信过程中全部使用对称加密的方式使用【会话密钥】加密明文数据（明文加摘要）。 篡改风险：校验机制，通过摘要算法保证完整性 冒充风险：身份证书，将公钥放入到数字证书中。 客户端要先向服务端索要公钥，然后用公钥加密信息，如何保证公钥不被篡改？借助第三方权威机构CA（数字证书认证机构），将服务器公钥放在数字证书中，只要证书是可信的，公钥就是可信的。 通过在http与tcp层之间加入了 SSL/TLS 协议实现。 SSL和TLS 二者实际上是一个东西，是同一东西不同阶段的名字。 SSL（Secure Sockets Layer）中文套接字，上世纪90年代出现的。 由于SSL应用广泛，便把SSL标准化，标准化之后的名称为TLS（Transport Layer Security）传输层安全协议。 很多文章习惯把二者并列写为SSL/TLS。 ","date":"2022-01-05","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/http%E7%89%88%E6%9C%AC%E6%BC%94%E8%BF%9B/:3:1","tags":["计算机网络"],"title":"HTTP版本演进","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/http%E7%89%88%E6%9C%AC%E6%BC%94%E8%BF%9B/"},{"categories":["技术笔记"],"content":"http 和 https传输过程的差异 建立连接时：https比http多了TLS握手过程。 传输内容时：https会对数据进行对称加密。 ","date":"2022-01-05","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/http%E7%89%88%E6%9C%AC%E6%BC%94%E8%BF%9B/:3:2","tags":["计算机网络"],"title":"HTTP版本演进","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/http%E7%89%88%E6%9C%AC%E6%BC%94%E8%BF%9B/"},{"categories":["技术笔记"],"content":"https是如何建立连接的？ SSL/TLS 协议基本流程： 客户端向浏览器索要并验证服务器的公钥。 通过非对称加密传递【会话密钥】 双方采用【会话密钥】进行加密通信。 前两步就是 SSL/TLS 的建立工程，也就是握手阶段。 TLS1.2需要4次握手，需要两个RTT往返时延。 TLS1.3只需要3次握手，只需要1个RTT往返时延。 ","date":"2022-01-05","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/http%E7%89%88%E6%9C%AC%E6%BC%94%E8%BF%9B/:3:3","tags":["计算机网络"],"title":"HTTP版本演进","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/http%E7%89%88%E6%9C%AC%E6%BC%94%E8%BF%9B/"},{"categories":["技术笔记"],"content":"http/2 的优化 http/2 协议是基于https的，所以安全性也是有保障的。 http/2 改进点： 头部压缩 http/2会压缩头（Header）。如果你同时发出多个请求，他们的头是一样的或是相似的，协议就会帮你消除重复的部分。 采用了 HPACK 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送相同的字段，发送索引号，提高速度。 二进制格式报文：header 和 body 都是二进制，并且统称为帧 数据流 Http/2的数据包不是按顺序发送的，同一个连接里面连续的数据包，可能属于不同的响应。因此，必须要对数据包进行标记，指出它属于哪个响应。 每个请求或响应的所有数据包，称为一个数据流（Stream）。每个数据流都标记着一个独一无二的编号，其中规定客户端发出的数据流编号为奇数，服务器发出的数据流编号为偶数。 客户端还可以指定数据流的优先级。优先级高的请求，服务器优先响应。 多路复用 http/2 可以在一个连接中并发多个请求或响应，而不用按照顺序一一对应。移除了http/1.1中的串行请求，不会出现队头阻塞的问题，降低了延迟，提高了连接的利用率。 服务器推送（Server Push/Cache Push）：服务器可以主动向客户端发送消息。如：在浏览器刚请求html时，就提前把可能会用到的js、css等静态文件主动发送给客户端，减少延时的等待。 ","date":"2022-01-05","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/http%E7%89%88%E6%9C%AC%E6%BC%94%E8%BF%9B/:4:0","tags":["计算机网络"],"title":"HTTP版本演进","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/http%E7%89%88%E6%9C%AC%E6%BC%94%E8%BF%9B/"},{"categories":["技术笔记"],"content":"http/3 的优化 http/2的主要问题在于，多个http请求复用一个tcp连接，下层的tcp协议不知道有多少个http请求。一旦发生了丢包，就会触发tcp的重传机制，那么在同一个tcp连接下的http请求就都必须重新等待这个丢的包被重传回来。 http/3 把下层的tcp协议改成了udp。 udp是不管顺序，不管丢包的。所以不会出现队头阻塞和一个丢包全部重传的问题。 udp是不可靠传输，但基于udp的QUIC协议可以实现类似tcp的可靠传输。 TLS升级成了最新的1.3版本 头部压缩算法升级成了 QPack ","date":"2022-01-05","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/http%E7%89%88%E6%9C%AC%E6%BC%94%E8%BF%9B/:5:0","tags":["计算机网络"],"title":"HTTP版本演进","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/http%E7%89%88%E6%9C%AC%E6%BC%94%E8%BF%9B/"},{"categories":["技术笔记"],"content":"QUIC QUIC通过自己的一套机制保证可靠传输。当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响。 https要建立一个连接，要花费6次交互，TCP的3次握手+TLS1.3的三次握手。QUIC直接把TCP和TLS1.3的6次交互合并成了3次，减少了交互次数。 QUIC是一个建立在UDP之上的 伪TCP + TLS + HTTP/2 的多路复用协议。 由于QUIC是新协议，对于很多网络设备，不知道什么是QUIC，只会当做UDP，会导致新的问题出现，所以HTTP/3的普及进度是否缓慢。 ","date":"2022-01-05","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/http%E7%89%88%E6%9C%AC%E6%BC%94%E8%BF%9B/:5:1","tags":["计算机网络"],"title":"HTTP版本演进","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/http%E7%89%88%E6%9C%AC%E6%BC%94%E8%BF%9B/"},{"categories":["技术笔记"],"content":"垃圾回收算法 标记-清除 Mark-Sweep 标记-复制：常用于新生代 标记-整理 Mark-Compact 分代回收：只是根据对象存活周期的不同将内存分为几块。一般将 java 堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。 ","date":"2022-01-04","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/:1:0","tags":["JVM"],"title":"JVM垃圾回收","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"},{"categories":["技术笔记"],"content":"并行和并发 并行（Parallel） ：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行，可能会交替执行），用户程序在继续运行，而垃圾收集器运行在另一个 CPU 上。 ","date":"2022-01-04","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/:2:0","tags":["JVM"],"title":"JVM垃圾回收","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"},{"categories":["技术笔记"],"content":"垃圾回收器图解 Serial 是单线程的收集器 ParNew 收集器实质上是Serial收集器的多线程并行版本。除了同时使用多条线程进行垃圾收集之外， 其余的行为包括Serial收集器可用的所有控制参数（例如： -XX： SurvivorRatio、 -XX：PretenureSizeThreshold、 -XX： HandlePromotionFailure等） 、 收集算法、 Stop The World、 对象分配规则、 回收策略等都与Serial收集器完全一致， 在实现上这两种收集器也共用了相当多的代码。 ParNew收集器除了支持多线程并行收集之外， 其他与Serial收集器相比并没有太多创新之处。 ","date":"2022-01-04","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/:3:0","tags":["JVM"],"title":"JVM垃圾回收","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"},{"categories":["技术笔记"],"content":"垃圾回收器分类 经典垃圾回收器 新生代 Serial：新生代采用标记-复制算法，老年代采用标记-整理算法。 ParNew：serial的多线程版 Parallel Scavenge：新生代采用标记-复制算法，老年代采用标记-整理算法。 Parallel Scavenge 收集器关注点是吞吐量（高效率的利用 CPU）。CMS 等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是 CPU 中用于运行用户代码的时间与 CPU 总消耗时间的比值。 Parallel Scavenge 收集器提供了很多参数供用户找到最合适的停顿时间或最大吞吐量，如果对于收集器运作不太了解，手工优化存在困难的时候，使用 Parallel Scavenge 收集器配合自适应调节策略，把内存管理优化交给虚拟机去完成也是一个不错的选择。 ParNew和Parallel Scavenge的异同：两者都是复制算法，都是并行处理，但是不同的是，paralel scavenge 可以设置最大gc停顿时间（-XX:MaxGCPauseMills）以及gc时间占比(-XX:GCTimeRatio) 老年代： Serial Old Parallel Old：多线程+标记整理 CMS：Concurrent Mark Sweep，采用标记-清除算法。目标最短回收停顿时间。 G1：面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足 GC 停顿时间要求的同时,还具备高吞吐量性能特征.（低停顿+高吞吐）。G1 从整体来看是基于“标记-整理”算法实现的收集器；从局部上来看是基于“标记-复制”算法实现的。 G1 收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的 Region(这也就是它的名字 Garbage-First 的由来) 。 低延迟垃圾回收器 ZGC：基于Region 内存布局，不设分代，使用了读屏障、染色指针和内存多重映射等技术实现可并发的标记-整理算法，以低延迟为首要目标。 Shenandoah CMS缺点： 对 CPU 资源敏感； 无法处理浮动垃圾； 它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。 Shenandoah与G1的3个明显不同： 支持并发的整理算法（最重要）。G1的回收阶段是可以多线程并行的，但不能与用户线程并发。 目前默认不使用分代回收 摒弃G1中耗费大量内存和计算资源去维护的记忆集，使用“连接矩阵”的全局数据结构来记录跨Region的引用关系。 默认搭配： JDK8 默认使用的是 Parallel Scavenge + Parallel Old。但一般不用这个。常用ParNew+CMS吧（因为是唯一搭配呀） JDK9~16 默认G1 在JVM中是+XX配置实现的搭配组合： -XX:+UseSerialGC，虚拟机运行在Client模式下的默认值，Serial+Serial Old。 -XX:+UseParNewGC，ParNew+Serial Old，在JDK1.8被废弃，在JDK1.7还可以使用。 -XX:+UseConcMarkSweepGC，ParNew+CMS+Serial Old。 -XX:+UseParallelGC，虚拟机运行在Server模式下的默认值，Parallel Scavenge+Serial Old(PS Mark Sweep)。 -XX:+UseParallelOldGC，Parallel Scavenge+Parallel Old。 -XX:+UseG1GC，G1+G1。 堆内存常见分配策略： 对象优先分配在eden区 大对象直接分配到老年代。大对象就是需要大量连续内存空间的对象（比如：字符串、数组）。 长期存活的对象进入老年代 空间分配担保：目的是确保Minor GC之前老年代有足够空间容纳新生代所有对象 JDK 6 Update 24 之前，在发生 Minor GC 之前，虚拟机必须先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果这个条件成立，那这一次 Minor GC 可以确保是安全的。如果不成立，则虚拟机会先查看 -XX:HandlePromotionFailure 参数的设置值是否允许担保失败(Handle Promotion Failure);如果允许，那会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试进行一次 Minor GC，尽管这次 Minor GC 是有风险的;如果小于，或者 -XX: HandlePromotionFailure 设置不允许冒险，那这时就要改为进行一次 Full GC。 JDK 6 Update 24之后的规则变为只要老年代的连续空间大于新生代对象总大小或者历次晋升的平均大小，就会进行 Minor GC，否则将进行 Full GC。 动态对象年龄判定：Hotspot 遍历所有对象时，按照年龄从小到大对其所占用的大小进行累积，当累积的某个年龄大小超过了 survivor 区的 50% 时（默认值是 50%，可以通过 -XX:TargetSurvivorRatio=percent 来设置 ），取这个年龄和 MaxTenuringThreshold（默认15岁） 中更小的一个值，作为新的晋升年龄阈值”。 GC分类 Partial GC: Minor GC/Young GC Major GC/Old GC Mixed GC：对整个新生代和老年代进行垃圾回收 Full GC：收集整个Java堆和方法区 ","date":"2022-01-04","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/:4:0","tags":["JVM"],"title":"JVM垃圾回收","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"},{"categories":["技术笔记"],"content":"如何判断一个对象已经无效？ 引用计数法 实现简单，效率高，但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它很难解决对象之间相互循环引用的问题。 可达性分析法 通过一系列的称为 “GC Roots” 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的。 可作为GC Roots的对象： 虚拟机栈（栈帧中的本地变量表）中引用的对象 本地方法栈（Native方法）中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 所有被同步锁持有的对象 ","date":"2022-01-04","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/:5:0","tags":["JVM"],"title":"JVM垃圾回收","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"},{"categories":["技术笔记"],"content":"引用 JDK1.2 之前，Java 中引用的定义很传统：如果 reference 类型的数据存储的数值代表的是另一块内存的起始地址，就称这块内存代表一个引用。 JDK1.2 以后，Java 对引用的概念进行了扩充，将引用分为强引用、软引用、弱引用、虚引用四种（引用强度逐渐减弱） 强引用（StrongReference） 以前我们使用的大部分引用实际上都是强引用，这是使用最普遍的引用。如果一个对象具有强引用，那就类似于必不可少的生活用品，垃圾回收器绝不会回收它。当内存空间不足，Java 虚拟机宁愿抛出 OutOfMemoryError 错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足问题。 软引用（SoftReference） 如果一个对象只具有软引用，那就类似于可有可无的生活用品。**如果内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存。**只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。 软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收，JAVA 虚拟机就会把这个软引用加入到与之关联的引用队列中。 弱引用（WeakReference） 如果一个对象只具有弱引用，那就类似于可有可无的生活用品。弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。 弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java 虚拟机就会把这个弱引用加入到与之关联的引用队列中。 虚引用（PhantomReference） “虚引用\"顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收。 虚引用主要用来跟踪对象被垃圾回收的活动。 虚引用与软引用和弱引用的一个区别在于： 虚引用必须和引用队列（ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。程序如果发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。 特别注意，在程序设计中一般很少使用弱引用与虚引用，使用软引用的情况较多，这是因为软引用可以加速 JVM 对垃圾内存的回收速度，可以维护系统的运行安全，防止内存溢出（OutOfMemory）等问题的产生。 你会使用软引用和弱引用吗？软引用和弱引用的例子不错。 ","date":"2022-01-04","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/:6:0","tags":["JVM"],"title":"JVM垃圾回收","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"},{"categories":["技术笔记"],"content":"常量池的位置 JDK1.7 之前运行时常量池逻辑包含字符串常量池存放在方法区, 此时 hotspot 虚拟机对方法区的实现为永久代。 JDK1.7 字符串常量池被从方法区拿到了堆中, 这里没有提到运行时常量池,也就是说字符串常量池被单独拿到堆,运行时常量池剩下的东西还在方法区, 也就是 hotspot 中的永久代 。 JDK1.8 hotspot 移除了永久代用元空间(Metaspace)取而代之, 这时候字符串常量池还在堆, 运行时常量池还在方法区, 只不过方法区的实现从永久代变成了元空间(Metaspace) 假如在字符串常量池中存在字符串 “abc”，如果当前没有任何 String 对象引用该字符串常量的话，就说明常量 “abc” 就是废弃常量，如果这时发生内存回收的话而且有必要的话，“abc” 就会被系统清理出常量池了。 ","date":"2022-01-04","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/:7:0","tags":["JVM"],"title":"JVM垃圾回收","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"},{"categories":["技术笔记"],"content":"如何判断一个类是无用的类 方法区主要回收的是无用的类，那么如何判断一个类是无用的类的呢？ 判定一个常量是否是“废弃常量”比较简单，而要判定一个类是否是“无用的类”的条件则相对苛刻许多。类需要同时满足下面 3 个条件才能算是 “无用的类” ： 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。 加载该类的 ClassLoader 已经被回收。 该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 虚拟机可以对满足上述 3 个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样不使用了就会必然被回收。 ","date":"2022-01-04","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/:8:0","tags":["JVM"],"title":"JVM垃圾回收","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"},{"categories":["技术笔记"],"content":"运行时数据区 《Java虚拟机规范》 ：“概念模型”这个词会经常被提及， 它代表了所有虚拟机的统一外观， 但各款具体的Java虚拟机并不 一定要完全照着概念模型的定义来进行设计， 可能会通过一些更高效率的等价方式去实现它。 ","date":"2021-12-23","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/java%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/:0:0","tags":["JVM"],"title":"Java运行时数据区","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/java%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/"},{"categories":["技术笔记"],"content":"程序计数器 当前线程所执行的字节码的行号。字节码解释器就是通过改变这个计数器的值来选取下一条需要执行的字节码指令。 程序计数器主要有两个作用： 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。 注意：程序计数器是唯一一个不会出现 OutOfMemoryError 的内存区域，它的生命周期随着线程的创建而创建，随着线程的结束而死亡。 ","date":"2021-12-23","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/java%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/:1:0","tags":["JVM"],"title":"Java运行时数据区","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/java%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/"},{"categories":["技术笔记"],"content":"Java虚拟机栈 描述的是Java方法执行的线程内存模型，每个方法被执行时，Java虚拟机都会同步创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态连接、方法出口等信息。每个方法从被调用到执行完毕的过程，就对应这一个栈帧在虚拟机栈的入栈和出栈过程。 局部变量表主要存放了编译期可知的各种数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference 类型，它不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）。 Java 虚拟机栈会出现两种错误：StackOverFlowError 和 OutOfMemoryError。 StackOverFlowError： 若 Java 虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 StackOverFlowError 错误。 OutOfMemoryError： Java 虚拟机栈的内存大小可以动态扩展， 如果虚拟机在动态扩展栈时无法申请到足够的内存空间，则抛出OutOfMemoryError异常。 HotSpot虚拟机的栈容量是不可以动态扩展的， 以前的Classic虚拟机倒是可以。 所以在HotSpot虚拟机上是不会由于虚拟机栈无法扩展而导致OutOfMemoryError异常——只要线程申请栈空间成功了就不会有OOM， 但是如果申请时就失败， 仍然是会出现OOM异常的。 ","date":"2021-12-23","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/java%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/:2:0","tags":["JVM"],"title":"Java运行时数据区","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/java%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/"},{"categories":["技术笔记"],"content":"本地方法栈 本地方法栈（Native Method Stacks） 与虚拟机栈所发挥的作用是非常相似的， 其区别只是虚拟机栈为虚拟机执行Java方法（也就是字节码） 服务， 而本地方法栈则是为虚拟机使用到的本地（Native）方法服务。 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。 ","date":"2021-12-23","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/java%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/:3:0","tags":["JVM"],"title":"Java运行时数据区","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/java%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/"},{"categories":["技术笔记"],"content":"堆 Java 虚拟机所管理的内存中最大的一块，Java 堆是所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。 Java 世界中“几乎”所有的对象都在堆中分配，但是，随着 JIT 编译器的发展与逃逸分析技术逐渐成熟，栈上分配、标量替换优化技术将会导致一些微妙的变化，所有的对象都分配到堆上也渐渐变得不那么“绝对”了。从 JDK 1.7 开始已经默认开启逃逸分析，如果某些方法中的对象引用没有被返回或者未被外面使用（也就是未逃逸出去），那么对象可以直接在栈上分配内存。 Java 堆是垃圾收集器管理的主要区域，因此也被称作GC 堆（Garbage Collected Heap）。从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以 Java 堆还可以细分为：新生代和老年代；再细致一点有：Eden 空间、From Survivor、To Survivor 空间等。进一步划分的目的是更好地回收内存，或者更快地分配内存。 从回收内存的角度看， 由于现代垃圾收集器大部分都是基于分代收集理论设计的， 所以Java堆中经常会出现“新生代”“老年代”“永久代”“Eden空间”“From Survivor空间”“To Survivor空间”等名词， 这些区域划分仅仅是一部分垃圾收集器的共同特性或者说设计风格而已， 而非某个Java虚拟机具体实现的固有内存布局， 更不是《Java虚拟机规范》 里对Java堆的进一步细致划分。 不少资料上经常写着类似于“Java虚拟机的堆内存分为新生代、 老年代、 永久代、 Eden、 Survivor……”这样的内容。 在十年之前（以G1收集器的出现为分界） ， 作为业界绝对主流的HotSpot虚拟机， 它内部的垃圾收集器全部都基于“经典分代”[3]来设计， 需要新生代、 老年代收集器搭配才能工作， 但现在不可同日而语，也出现了不采用分代设计的垃圾回收器。 在 JDK 7 版本及 JDK 7 版本之前，堆内存被通常分为下面三部分： 新生代内存(Young Generation) 老生代(Old Generation) 永生代(Permanent Generation) JDK 8 版本之后方法区（HotSpot 的永久代）被彻底移除了（JDK1.7 就已经开始了），取而代之是元空间，元空间使用的是直接内存。 上图所示的 Eden 区、两个 Survivor 区都属于新生代（为了区分，这两个 Survivor 区域按照顺序被命名为 from 和 to），中间一层属于老年代。 大部分情况，对象都会首先在 Eden 区域分配，在一次新生代垃圾回收后，如果对象还存活，则会进入 s0 或者 s1，并且对象的年龄还会加 1(Eden 区-\u003eSurvivor 区后对象的初始年龄变为 1)，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。 Hotspot 遍历所有对象时，按照年龄从小到大对其所占用的大小进行累积，当累积的某个年龄大小超过了 survivor 区的一半时，取这个年龄和 MaxTenuringThreshold 中更小的一个值，作为新的晋升年龄阈值。 堆这里最容易出现的就是 OutOfMemoryError 错误，并且出现这种错误之后的表现形式还会有几种，比如： java.lang.OutOfMemoryError: GC Overhead Limit Exceeded ： 当 JVM 花太多时间执行垃圾回收并且只能回收很少的堆空间时，就会发生此错误。 java.lang.OutOfMemoryError: Java heap space :假如在创建新的对象时, 堆内存中的空间不足以存放新创建的对象, 就会引发此错误。(和配置的最大堆内存有关，且受制于物理内存大小。最大堆内存可通过-Xmx参数配置，-Xms设置初始堆内存，若没有特别配置，将会使用默认值，详见：Default Java 8 max heap size (opens new window)) ","date":"2021-12-23","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/java%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/:4:0","tags":["JVM"],"title":"Java运行时数据区","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/java%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/"},{"categories":["技术笔记"],"content":"方法区 方法区与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然 Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做 Non-Heap（非堆），目的应该是与 Java 堆区分开来。 说到方法区， 不得不提一下“永久代”这个概念， 尤其是在JDK 8以前， 许多Java程序员都习惯在HotSpot虚拟机上开发、 部署程序， 很多人都更愿意把方法区称呼为“永久代”（Permanent Generation） ， 或将两者混为一谈。 本质上这两者并不是等价的， 因为仅仅是当时的HotSpot虚拟机设计团队选择把收集器的分代设计扩展至方法区， 或者说使用永久代来实现方法区而已， 这样使得HotSpot的垃圾收集器能够像管理Java堆一样管理这部分内存， 省去专门为方法区编写内存管理代码的工作。 但是对于其他虚拟机实现， 譬如BEA JRockit、 IBM J9等来说， 是不存在永久代的概念的。 原则上如何实现方法区属于虚拟机实现细节， 不受《Java虚拟机规范》 管束， 并不要求统一。 但现在回头来看， 当年使用永久代来实现方法区的决定并不是一个好主意， 这种设计导致了Java应用更容易遇到内存溢出的问题（永久代有-XX： MaxPermSize的上限， 即使不设置也有默认大小， 而J9和JRockit只要没有触碰到进程可用内存的上限， 例如32位系统中的4GB限制， 就不会出问题） ， 而且有极少数方法（例如String::intern()） 会因永久代的原因而导致不同虚拟机下有不同的表现。 当Oracle收购BEA获得了JRockit的所有权后， 准备把JRockit中的优秀功能， 譬如Java Mission Control管理工具， 移植到HotSpot虚拟机时， 但因为两者对方法区实现的差异而面临诸多困难。 考虑到HotSpot未来的发展， 在JDK 6的时候HotSpot开发团队就有放弃永久代， 逐步改为采用本地内存（Native Memory） 来实现方法区的计划了[1]， 到了JDK 7的HotSpot， 已经把原本放在永久代的字符串常量池、 静态变量等移出， 而到了JDK 8， 终于完全废弃了永久代的概念， 改用与JRockit、 J9一样在本地内存中实现的元空间（Metaspace） 来代替， 把JDK 7中永久代还剩余的内容（主要是类型信息） 全部移到元空间中。 //JDK 1.8 之前永久代还没被彻底移除的时候通常通过下面这些参数来调节方法区大小 -XX:PermSize=N //方法区 (永久代) 初始大小 -XX:MaxPermSize=N //方法区 (永久代) 最大大小,超过这个值将会抛出 OutOfMemoryError 异常:java.lang.OutOfMemoryError: PermGen JDK 1.8 的时候，方法区（HotSpot 的永久代）被彻底移除了（JDK1.7 就已经开始了），取而代之是元空间，元空间使用的是直接内存。 //一些常用参数： -XX:MetaspaceSize=N //设置 Metaspace 的初始（和最小大小） -XX:MaxMetaspaceSize=N //设置 Metaspace 的最大大小 与永久代很大的不同就是，如果不指定大小的话，随着更多类的创建，虚拟机会耗尽所有可用的系统内存。 运行时常量池是方法区的一部分。Class 文件中除了有类的版本、字段、方法、接口等描述信息外，还有常量池表（用于存放编译期生成的各种字面量和符号引用）。既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 错误。 JDK1.7 之前运行时常量池逻辑包含字符串常量池存放在方法区, 此时 hotspot 虚拟机对方法区的实现为永久代。 JDK1.7字符串常量池被从方法区拿到了堆中, 这里没有提到运行时常量池,也就是说字符串常量池被单独拿到堆,运行时常量池剩下的东西还在方法区, 也就是 hotspot 中的永久代。 JDK1.8 hotspot 移除了永久代用元空间(Metaspace)取而代之, 这时候字符串常量池还在堆, 运行时常量池还在方法区, 只不过方法区的实现从永久代变成了元空间(Metaspace)。 ","date":"2021-12-23","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/java%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/:5:0","tags":["JVM"],"title":"Java运行时数据区","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/java%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/"},{"categories":["技术笔记"],"content":"直接内存 直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用。而且也可能导致 OutOfMemoryError 错误出现。 JDK1.4 中新加入的 NIO(New Input/Output) 类，引入了一种基于通道（Channel）与缓存区（Buffer）的 I/O 方式，它可以直接使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样就能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆之间来回复制数据。 本机直接内存的分配不会受到 Java 堆的限制，但是，既然是内存就会受到本机总内存大小以及处理器寻址空间的限制。 ","date":"2021-12-23","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/java%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/:6:0","tags":["JVM"],"title":"Java运行时数据区","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/java%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/"},{"categories":["技术笔记"],"content":"Future Future 模式是多线程开发中非常常见的一种设计模式，它的核心思想是异步调用。 当我们需要调用一个函数方法时，如果这个函数执行的很慢，那么我们就要进行等待。但有时候，我们可能并不急于获取结果。因此，我们可以让被调用者立即返回，让它在后台慢慢处理这个请求。对于调用者来说，则可以先处理一些其他任务，在真正需要数据的场合再去尝试获取需要的数据。 对 Future 模式来说，虽然它无法立即给你需要的数据，但它会给你一个契约，将来你可以凭借这个契约去重新获取你需要的信息。 这里我们主要谈论 JDK 中的 Future 模式，即 java.util.concurrent 包下的 Future 接口。 RunnableFutre 接口：继承了 Future 和 Runnable 两个接口。其中run() 方法用于构造真实的数据。 FutureTask 类：一个具体的实现类。WaitNode 是其内部类。 ","date":"2021-12-16","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/future-completablefuture/:0:0","tags":["Java并发"],"title":"Future \u0026 CompletableFuture","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/future-completablefuture/"},{"categories":["技术笔记"],"content":"常见操作 ExecutorService executor = Executors.newFixedThreadPool(4); // 定义任务: Callable\u003cString\u003e task = new Task(); // 提交任务并获得Future: Future\u003cString\u003e future = executor.submit(task); // 从Future获取异步执行返回的结果: String result = future.get(); // 可能阻塞 流程： 当我们提交一个Callable任务后（Runnable 任务没有返回值），我们会同时获得一个Future对象。 然后，我们在主线程某个时刻调用Future对象的get()方法，就可以获得异步执行的结果。 在调用get()时，如果异步任务已经完成，我们就直接获得结果。 如果异步任务还没有完成，那么get()会阻塞，直到任务完成后才返回结果。 ","date":"2021-12-16","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/future-completablefuture/:1:0","tags":["Java并发"],"title":"Future \u0026 CompletableFuture","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/future-completablefuture/"},{"categories":["技术笔记"],"content":"Future 接口方法 一个Future\u003cV\u003e接口表示一个未来可能会返回的结果，它定义的方法有： get()：获取结果（可能会等待） get(long timeout, TimeUnit unit)：获取结果，但只等待指定的时间； cancel(boolean mayInterruptIfRunning)：取消当前任务； isDone()：判断任务是否已完成。 CompletableFuture CompletableFuture 是 Java8 新增的工具类，是增强的 Future。 CompletableFuture 它实现了 Future 接口，还实现了 CompletionStage 接口。 CompletableFuture 除了提供了更为好用和强大的 Future 特性之外，还提供了函数式编程的能力。 public class CompletableFuture\u003cT\u003e implements Future\u003cT\u003e, CompletionStage\u003cT\u003e { } CompletionStage 接口也是 Java8 新增的。而这个接口里有多达40种方法，是为了函数式编程中的流式调用准备的。 通过这个接口，我们可以在一个执行结果上进行多次流式调用。 stage.thenApply(x -\u003e square(x)).thenAccept(x -\u003e System.out.print(x)).thenRun(() -\u003e System.out.println) 其功能： 完成了就通知 异步执行任务 流式调用 异常处理 组合多个CompletableFuture ","date":"2021-12-16","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/future-completablefuture/:2:0","tags":["Java并发"],"title":"Future \u0026 CompletableFuture","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/future-completablefuture/"},{"categories":["技术笔记"],"content":"常见操作 ","date":"2021-12-16","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/future-completablefuture/:3:0","tags":["Java并发"],"title":"Future \u0026 CompletableFuture","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/future-completablefuture/"},{"categories":["技术笔记"],"content":"创建CompletableFuture 常见的创建 CompletableFuture 对象的方法如下： 通过 new 关键字。 基于 CompletableFuture 自带的静态工厂方法：runAsync() 、supplyAsync() 。 CompletableFuture\u003cRpcResponse\u003cObject\u003e\u003e resultFuture = new CompletableFuture\u003c\u003e(); static \u003cU\u003e CompletableFuture\u003cU\u003e supplyAsync(Supplier\u003cU\u003e supplier); // 使用自定义线程池(推荐) static \u003cU\u003e CompletableFuture\u003cU\u003e supplyAsync(Supplier\u003cU\u003e supplier, Executor executor); static CompletableFuture\u003cVoid\u003e runAsync(Runnable runnable); // 使用自定义线程池(推荐) static CompletableFuture\u003cVoid\u003e runAsync(Runnable runnable, Executor executor); ","date":"2021-12-16","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/future-completablefuture/:3:1","tags":["Java并发"],"title":"Future \u0026 CompletableFuture","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/future-completablefuture/"},{"categories":["技术笔记"],"content":"处理异步结算的结果 当我们获取到异步计算的结果之后，还可以对其进行进一步的处理，比较常用的方法有下面几个： thenApply() thenAccept() thenRun() whenComplete() ","date":"2021-12-16","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/future-completablefuture/:3:2","tags":["Java并发"],"title":"Future \u0026 CompletableFuture","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/future-completablefuture/"},{"categories":["技术笔记"],"content":"异常处理 handle() exceptionally() completeExceptionally() ","date":"2021-12-16","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/future-completablefuture/:3:3","tags":["Java并发"],"title":"Future \u0026 CompletableFuture","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/future-completablefuture/"},{"categories":["技术笔记"],"content":"组合CompletableFuture thenCompose() thenCombine() thenCompose() 和 thenCombine() 有什么区别呢？ thenCompose() 可以两个 CompletableFuture 对象，并将前一个任务的返回结果作为下一个任务的参数，它们之间存在着先后顺序。 thenCombine() 会在两个任务都执行完成后，把两个任务的结果合并。两个任务是并行执行的，它们之间并没有先后依赖顺序。 ","date":"2021-12-16","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/future-completablefuture/:3:4","tags":["Java并发"],"title":"Future \u0026 CompletableFuture","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/future-completablefuture/"},{"categories":["技术笔记"],"content":"并行运行多个CompletableFuture allOf() anyOf() allOf() 方法会等到所有的 CompletableFuture 都运行完成之后再返回 anyOf() 方法不会等待所有的 CompletableFuture 都运行完成之后再返回，只要有一个执行完成即可！ 参考 [1] 《实战Java高并发程序设计》 [2] 廖雪峰-使用Future [3] JavaGuide-CompletableFuture入门 ","date":"2021-12-16","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/future-completablefuture/:3:5","tags":["Java并发"],"title":"Future \u0026 CompletableFuture","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/future-completablefuture/"},{"categories":["技术笔记"],"content":"本文主要目的是理清 Java 的偏向锁、轻量级锁、自选锁、锁消除等概念。 JDK 6，虚拟机团队锁进行了多种优化。在JVM层面实现加锁逻辑，不用依赖底层操作系统，避免了切换的消耗。主要有： 适应性自旋 Adaptive Spinning 锁消除 Lock Elimination 锁膨胀 Lock Coarsening 轻量级锁 Lightweight Locking 偏向锁 Biased Locking 锁升级过程 偏向锁： 在锁对象的对象头中记录当前获取到该锁的线程ID，该线程下次如果还来获取该锁就可以直接获取到。 轻量级锁： 由偏向锁升级而来，当一个线程获取到锁后，此时这把锁是偏向锁。如果这时有第二个线程来竞争锁，偏向锁就会升级为轻量级锁。之所以叫轻量级锁，是为了和重量级锁区分开，轻量级锁底层是通过自旋实现的，不会阻塞线程。 自旋： 自选锁就是线程在获取锁的过程中，不会去阻塞线程，也就无所谓的唤醒线程，阻塞和唤醒这两个步骤都需要操作系统去执行，因此耗时，自旋锁是线程通过CAS获取预期的一个标记，如果没有获取到，就继续循环获取。如果获取到了则表示获得了该锁，这个过程线程一直在运行中，相对而言没有使用太多的操作系统资源，比较轻量。 重量级锁： 如果自旋次数过多仍然没有获取到锁，则会升级为重量级锁，重量级锁会导致线程阻塞。 当JVM认为只有某个线程才会执行同步代码，即没有竞争时会使用偏向锁。在Mark Word 直接记录线程ID，当线程来执行代码，对比线程ID是否相等，相等则当前线程直接获得到锁，执行同步代码。如果不相等，CAS尝试修改当前线程ID，如果修改成功，还是能得到锁，执行同步代码，如果CAS失败，说明有竞争环境，此时偏向锁升级为轻量级锁。 在轻量级锁的状态下，当前线程会在栈帧下创建一个锁记录Lock Record，Lock Record会把Mark Word的信息拷贝进去，而且有个owner指针指向加锁对象。线程执行同步代码时，则用CAS尝试将Mark Word 指向到栈帧的Lock Record，如果CAS修改成功，则获得到轻量级锁。如果修改失败，则自旋重试，自旋一定次数失败后，则升级为重量级锁。 重量级锁用到monitor对象，依赖操作系统的mutex指令，需要用户态和内核态切换，消耗性能。 即： 只有一个线程进入临界区，偏向锁 多个线程交替进入临界区，轻量级锁 多线程同时进入临界区，重量级锁 锁状态 假定情况 竞争处理策略 偏向锁 假定获取锁的一直都是同一个线程 升级为轻量锁 轻量级锁 假定锁被占用时不会有其他线程获取 自旋等待，超时升级 重量级锁 最坏情况，经常发生竞争 直接将要获取锁的线程挂起 偏向锁 偏向锁的相关信息是保存在Java对象的对象头中的。 在HotSpot虚拟机中，Java对象在内存中存储的布局分为3块区域：对象头、实例数据和对齐填充。 对象头包含：包含对象的HashCode、分代年龄、锁标志位、线程持有的锁、偏向线程ID等，这部分数据的长度在32位和64位的虚拟机中分别为32bit和64bit，官方称为Mark Word。 偏向锁的目的是消除数据在无竞争情况下的同步原语。如果说轻量级锁是在无竞争的情况下使用CAS操作去消除同步使用的互斥量，那偏向锁就是在无竞争情况下把整个同步都消除掉，连CAS操作都不做。 这个锁会偏向于第一个获得它的线程，如果在接下来的执行过程中，该锁一直没有被其他的线程获取，则持有偏向锁的线程将永远不需要再进行同步。 偏向锁默认是开启的。当锁对象第一次被线程获取时，虚拟机会把对象头中的标志位设置为“01”、把偏向模式设置为1，表示进入偏向模式。同时使用CAS操作把获取到这个锁的线程ID记录在对象的Mark Word中。果CAS操作成功， 持有偏向锁的线程以后每次进入这个锁相关的同步块时， 虚拟机都可以不再进行任何同步操作（例如加锁、 解锁及对Mark Word的更新操作等）。 一旦出现另外一个线程去尝试获取这个锁的情况， 偏向模式就马上宣告结束。 根据锁对象目前是否处于被锁定的状态决定是否撤销偏向（偏向模式设置为“0”） ， 撤销后标志位恢复到未锁定（标志位为“01”） 或轻量级锁定（标志位为“00”） 的状态， 后续的同步操作就按照上面介绍的轻量级锁那样去执行。 如果程序中大多数的锁都总是被多个不同的线程访问，那么偏向模式就是多余的。有时使用参数 -XX:-UseBisedLocking=false来禁止偏向锁优化反而可以提升性能。 （JDK 15 废弃偏向锁） 轻量级锁 轻量级锁并不是来替代重量级锁的，它的设计初衷是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量的性能消耗。 在代码即将进入同步块时，如果此同步对象没有被锁定（锁标志位为“01”状态），虚拟机首先将在当前线程的栈帧中简历一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝。 然后虚拟机将使用 CAS操作尝试把对象的Mark Word更新为指向Lock Record 的指针。 如果更新动作成功了，代表该线程拥有了这个对象的锁，并且对象Mark Word的锁标志位（Mark Word的最后两个比特）将变为“00”，表示此对象正处于轻量级锁定状态。 如果更新操作失败了，意味着有线程与当前线程竞争该对象的锁。虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是，说明当前线程已经拥有了这个对象的锁，直接进入同步块。否则说明这个锁对象给其他线程抢占了，此时轻量级锁升级为重量级锁，锁标志位状态变为“10”。 轻量级锁能提升程序同步性能的依据是“对于绝大部分的锁，在整个同步周期内都是不存在竞争的”。如果没有竞争，轻量级锁便通过CAS操作成功避免了使用互斥量的开销。但如果确实存在锁竞争，除了互斥量本身的开销外，还额外发生了CAS的开销。因此在有竞争的情况下，轻量级锁反而会比传统的重量级锁更慢。 自旋锁与自适应自旋 引入自旋锁是为了节省线程挂起和恢复的开销。 互斥同步对性能最大的影响是阻塞的实现， 挂起线程和恢复线程的操作都需要转入内核态中完成， 这些操作给Java虚拟机的并发性能带来了很大的压力。 同时， 我们注意到在许多应用上， 共享数据的锁定状态只会持续很短的一段时间， 为了这段时间去挂起和恢复线程并不值得。如果物理机器有一个以上的处理器或者处理器核心， 能让两个或以上的线程同时并行执行， 我们 就可以让后面请求锁的那个线程“稍等一会”， 但不放弃处理器的执行时间， 看看持有锁的线程是否很快就会释放锁。 为了让线程等待， 我们只须让线程执行一个忙循环（自旋） ， 这项技术就是所谓的自旋锁。 自旋锁在1.4.2中就引进了，不过默认是关闭的。JDK 6开始改为默认开启。默认自旋10次。 JDK 6 对自旋锁的优化，引入了自适应的自旋。自适应自旋意味着自旋次数不再是固定的了，由前一次在同一个锁上的自旋时间以及锁的拥有者的状态决定。 如果同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，进而允许自旋等待持续更长的时间。如果对于某个锁，自旋很少成功获得过锁，那以后要获取这个锁将可能直接省略自旋过程。 如果前面线程成功获取锁并且正常运行，那么本次获取锁的可能性很大，所以自旋的次数相对多一些；如果前面线程很少成功获取锁，那么本次获取锁的概率也很小，就可能不执行自旋了。 锁粗化 如果在一段代码中同一线程反复获取、释放同一个对象的锁，将会产生不必要的性能开销，所以要把获取锁的范围扩大，对同一个对象的锁操作只进行一次，在头部获取锁，在尾部释放锁。 如果虚拟机检测到有一串零碎的操作都对同一个对象加锁，就会把加锁同步的范围粗化到整个操作序列的外部。 锁消除 锁消除是指JIT（Just in time 即时编译器）在运行时分析到使用了锁的同步代码在实际运行中不可能存在竞争的情况，对锁进行消除。 锁消除的主要判断依据来源于逃逸分析的数据支持。 如果判断到一段代码，在堆上的所有数据都不会逃逸出去被其他线程访问到，那就可以把他们当做栈上数据对待，认为他们是线程私有的，同步加锁自然就不用再进行了。 参考 https://segmentfault.com/a/1190000021220448 https://www.jianshu.com/p/937a876372ff https://mp.weixin.qq.com/s/YilCUO-uUliXE4Bg6e_8Vg https://segmentfault.com/a/1190000040447521 https://juejin.cn/post/6844903550586191885#heading-0 https://juejin.cn/post/6844903647713689607 《深入理解Java虚拟机》 ","date":"2021-12-06","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/jvm%E9%94%81%E4%BC%98%E5%8C%96/:0:0","tags":["Java并发"],"title":"JVM锁优化","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/jvm%E9%94%81%E4%BC%98%E5%8C%96/"},{"categories":["科研"],"content":"Self-Attention ","date":"2021-10-12","objectID":"/posts/%E7%A7%91%E7%A0%94/self-attention%E6%A6%82%E8%BF%B0/:0:0","tags":["attention"],"title":"Self-Attention概述","uri":"/posts/%E7%A7%91%E7%A0%94/self-attention%E6%A6%82%E8%BF%B0/"},{"categories":["科研"],"content":"什么是self-attention？ self-attention会考虑所有的input，去输出output，考虑了全局的资讯。输入几个input就输出几个output。 fully-connected network，专注于处理某一个位置的咨询。 往往交替使用self-attention和fully-connected ","date":"2021-10-12","objectID":"/posts/%E7%A7%91%E7%A0%94/self-attention%E6%A6%82%E8%BF%B0/:1:0","tags":["attention"],"title":"Self-Attention概述","uri":"/posts/%E7%A7%91%E7%A0%94/self-attention%E6%A6%82%E8%BF%B0/"},{"categories":["科研"],"content":"self-attention的运作 宏观上其每一个b都是考虑了所有的a以后产生的。 关键在于如何考虑a的所有咨询。self-attention通过一个数值α来表示每一个向量跟当前input的关联程度。 attention模组就是拿两个向量作为输入，然后输出α。计算α一般有两种做法： dot product（常用）：输入的两个向量分别乘上两个不同的矩阵，左边这个向量乘上$W^q$这个矩阵得到矩阵$q$,右边这个向量乘上$W^k$这个矩阵得到矩阵$k$。再把q和k做dot product得到α。 additive：同样这两个向量通过$W^q$ $W^k$,得到$q$跟$k$,然后把它这个串起来,然后丢到一个Activation Function，然后再通过一个转换得到α。 这里的activation function可以用别的，ReLU、softmax都可以尝试。 接着从$α'$中抽取出整个输入里重要的咨询。 首先把$a^1$到$a^4$这边每一个向量,乘上$W^v $得到新的向量,这边分别就是用$v^1 v^2 v^3 v^4$来表示 接下来把这边的$v^1$到$v^4$,每一个向量都去乘上Attention的分数,都去乘上$α'$ 然后再把它加起来,得到$b^1$ $$ b^1=\\sum_i\\alpha'_{1,i}v^i $$ 如果某一个向量它得到的分数越高,比如说如果$a^1$跟$a^2$的关联性很强,这个$α'$得到的值很大,那在做Weighted Sum以后,得到的$b^1$的值,就可能会比较接近$v^2$。 所以谁的Attention的分数最大,谁的$v$就会显现出你抽出来的结果。 vector 得到 $b^1$,跟从这一排 vector 得到 $b^2$,它的操作是一模一样的。 $b^1$ 到 $b^4$,它们并不需要依序產生,它们是一次同时被计算出来的，可以并行化计算。 ","date":"2021-10-12","objectID":"/posts/%E7%A7%91%E7%A0%94/self-attention%E6%A6%82%E8%BF%B0/:2:0","tags":["attention"],"title":"Self-Attention概述","uri":"/posts/%E7%A7%91%E7%A0%94/self-attention%E6%A6%82%E8%BF%B0/"},{"categories":["科研"],"content":"从矩阵的角度看 I 是 Self-attention 的 input,Self-attention 的 input 是一排的vector,这排 vector 拼起来当作矩阵的 column,就是 I 这个 input 分别乘上三个矩阵,$W^q$ $W^k$ 跟$ W^v$,得到 Q K V 这三个矩阵,接下来 Q 乘上 K 的 transpose,得到 A 这个矩阵,A 的矩阵你可能会做一些处理,得到 $A'$,那有时候我们会把这个 $A'$,叫做 ==Attention Matrix==，生成Q矩阵就是为了得到Attention的score 然后接下来你把 $A'$ 再乘上 V,就得到 O,O 就是 Self-attention 这个 layer 的输出,生成V是为了计算最后的b，也就是矩阵O $W^k$ 跟$ W^v$ 而已,只有$W^q$ $W^k$ 跟$ W^v$是未知的**,是需要通过的训练资料训练出来的。从 I 到 O 就是做了 Self-attention。 Attention机制的本质思想：通过Query和Keys计算对应的value的权重，再对value进行加权求和，得到最终的Attention数值。 ","date":"2021-10-12","objectID":"/posts/%E7%A7%91%E7%A0%94/self-attention%E6%A6%82%E8%BF%B0/:3:0","tags":["attention"],"title":"Self-Attention概述","uri":"/posts/%E7%A7%91%E7%A0%94/self-attention%E6%A6%82%E8%BF%B0/"},{"categories":["科研"],"content":"Multi-head Self-attention Self-attention 有一个进阶的版本,叫Multi-head Self-attention,今天应用得非常地广泛。 需要用多少head，又是一个hyperparameter。 什么是head？为什么我们要用到多头呢？ 在做 Self-attention 的时候,我们就是用 q 去找相关的 k,但是相关这件事情有很多种不同的形式,有很多种不同的定义,所以也许我们不能只有一个 q,我们应该要有多个 q,不同的 q 负责不同种类的相关性。 先把 a 乘上一个矩阵得到 q 再把 q 乘上另外两个矩阵,分别得到 $q^1$ 跟 $q^2$,用两个上标,i 代表的是位置,然后这个 1 跟 2 代表是,这个位置的第几个 q,所以这边有 $q^{i,1}$ 跟 $q^{i,2}$,代表说我们有两个 head 这个问题,裡面有两种不同的相关性,是我们需要产生两种不同的 head,来找两种不同的相关性。 既然 q 有两个,那 k 也就要有两个,那 v 也就要有两个,从 q 得到 $q^1 q^2$,从 k 得到 $k^1 k^2$,从 v 得到 $v^1 v^2$,那其实就是把 q 把 k 把 v,分别乘上两个矩阵,得到这个不同的 head。 然后分别计算$b^{i,1}$、$b^{i,2}$，步骤是一样的。 最后把 $b^{i,1}$ 跟 $b^{i,2}$,把它接起来,然后再通过一个 transform，也就是再乘上一个矩阵,然后得到 bi,然后再送到下一层去,那这个就是 Multi-head attention。 ","date":"2021-10-12","objectID":"/posts/%E7%A7%91%E7%A0%94/self-attention%E6%A6%82%E8%BF%B0/:4:0","tags":["attention"],"title":"Self-Attention概述","uri":"/posts/%E7%A7%91%E7%A0%94/self-attention%E6%A6%82%E8%BF%B0/"},{"categories":["科研"],"content":"Positional Encoding 对self-attention来说，位置 1 跟位置 2 跟位置 3 跟位置 4,完全没有任何差别,这四个位置的操作其实是一模一样,对它来说 q1 到跟 q4 的距离,并没有特别远,1 跟 4 的距离并没有特别远,2 跟 3 的距离也没有特别近。self-attention没有记录位置的资讯。而有时候位置的资源很重要。 positional encoding技术就是将位置的资讯加上。 关于这个vector是如何产生的，仍是个尚待研究的问题，有以下思路： 通过一个sin function产生，当做网络的参数的一部分，也是学习出来的。（最早的positionnal encoding） 用RNN产生出来。 ","date":"2021-10-12","objectID":"/posts/%E7%A7%91%E7%A0%94/self-attention%E6%A6%82%E8%BF%B0/:5:0","tags":["attention"],"title":"Self-Attention概述","uri":"/posts/%E7%A7%91%E7%A0%94/self-attention%E6%A6%82%E8%BF%B0/"},{"categories":["科研"],"content":"应用 语音。Truncated Self-attention，只看一小个范围。 图像。直接把图片当成一个vector set。 ","date":"2021-10-12","objectID":"/posts/%E7%A7%91%E7%A0%94/self-attention%E6%A6%82%E8%BF%B0/:6:0","tags":["attention"],"title":"Self-Attention概述","uri":"/posts/%E7%A7%91%E7%A0%94/self-attention%E6%A6%82%E8%BF%B0/"},{"categories":["科研"],"content":"Self-attention vs CNN 用 Self-attention 来处理一张图片,代表说,假设这个是你要考虑的 pixel,那它產生 query,其他 pixel 產生 key。做 inner product 的时候,你考虑的不是一个小的receptive field的信息,而是整张影像的资讯。 做 CNN 的时候,,会画出一个 receptive field,每一个 filter,每一个 neural,只考虑 receptive field 范围裡面的资讯。 所以如果我们比较 CNN 跟 Self-attention 的话,CNN 可以看作是一种简化版的 Self-attention，因為在做CNN的时候,我们只考虑 receptive field 裡面的资讯,而在做 Self-attention 的时候,我们是考虑整张图片的资讯,所以 CNN,是简化版的 Self-attention 或者是你可以反过来说,Self-attention 是一个复杂化的 CNN 在 CNN 裡面,我们要划定 receptive field,每一个 neural,只考虑 receptive field 裡面的资讯,而 receptive field 的范围跟大小,是人决定的。 而对 Self-attention 而言,我们用 attention,去找出相关的 pixel,就好像是 receptive field 是自动被学出的,network 自己决定说,receptive field 的形状长什麼样子,network 自己决定说,以这个 pixel 為中心,哪些 pixel 是我们真正需要考虑的,那些 pixel 是相关的。所以 receptive field 的范围,不再是人工划定,而是让机器自己学出来。 ","date":"2021-10-12","objectID":"/posts/%E7%A7%91%E7%A0%94/self-attention%E6%A6%82%E8%BF%B0/:7:0","tags":["attention"],"title":"Self-Attention概述","uri":"/posts/%E7%A7%91%E7%A0%94/self-attention%E6%A6%82%E8%BF%B0/"},{"categories":["科研"],"content":"Self-attention vs RNN RNN的角色,很大一部分都可以用 Self-attention 来取代。很多的应用都往往把 RNN 的架构,逐渐改成 Self-attention 的架构 RNN跟 Self-attention 做的事情其实也非常像,它们的 input 都是一个 vector sequence。 Self-attention的每一个 vector,它都考虑了整个 input 的 sequence,而 RNN 每一个 vector,只考虑了左边已经输入的 vector,它没有考虑右边的 vector。 但是 RNN 其实也可以是双向的,所以如果你 RNN 用双向的 RNN 的话,其实这边的每一个 hidden 的 output,每一个 memory 的 output,其实也可以看作是考虑了整个 input 的 sequence。 ","date":"2021-10-12","objectID":"/posts/%E7%A7%91%E7%A0%94/self-attention%E6%A6%82%E8%BF%B0/:8:0","tags":["attention"],"title":"Self-Attention概述","uri":"/posts/%E7%A7%91%E7%A0%94/self-attention%E6%A6%82%E8%BF%B0/"},{"categories":["科研"],"content":"self-attention与一般的attention有哪些不同呢？ 从seq2seq所常用的attention来说： 从组织形式上考虑的话，attention可以分为两种：vanilla attention以及self attention。attention的概念最开始是由google进行形式化的提出，以Q、K、V作为重要组件，通过对三种分量的加权求和得到attention向量。 而vanilla attention和self attention的区别在于：query来自于解码层，key和value来自于编码层时叫vanilla attention，即最基本的attention。query，key和value都来自编码层的叫self attention。（nlp中的Attention注意力机制+Transformer详解-人工智能） 广义上说的transformer就是指self-attention。self-attention变形一般都叫xxxformer了。 Self-attention 它最大的问题就是,它的运算量非常地大,所以怎么减少 Self-attention 的运算量,是一个未来的重点。 各种xxformer往往速度比Transformer快，但performance会变差。 ","date":"2021-10-12","objectID":"/posts/%E7%A7%91%E7%A0%94/self-attention%E6%A6%82%E8%BF%B0/:9:0","tags":["attention"],"title":"Self-Attention概述","uri":"/posts/%E7%A7%91%E7%A0%94/self-attention%E6%A6%82%E8%BF%B0/"},{"categories":["科研"],"content":"Seq2seq 编码器—解码器（encoder-decoder）或者seq2seq模型，这两个模型本质上都用到了两个循环神经网络，分别叫做编码器和解码器。编码器用来分析输入序列，解码器用来生成输出序列。 编码器的作用是把一个不定长的输入序列变换成一个定长的背景变量c，并在该背景变量中编码输入序列信息。常用的编码器是循环神经网络。 编码器-解码器（seq2seq）可以输入并输出不定长的序列。 编码器—解码器可使用两个循环神经网络，但后来使用注意力机制效果更好。 seq2seq model的应用: 语音识别 机器翻译 语音翻译 语音合成 Text-to-Speech（TTS）Synthesis 聊天机器人 chatbot QA。许多NLP的问题，往往可以看成是QA的问题，如sentiment analysis，而QA的问题，可以用seq2seq model来解。 句法解析 Syntactic Parsing multi-label classification Seq2seq for Object Detection Transformer transformer就是一个seq2seq model。现在讲到seq2seq’s model的时候,第一个想到的，可能都是transformer。 ","date":"2021-10-10","objectID":"/posts/%E7%A7%91%E7%A0%94/transformer%E6%A6%82%E8%BF%B0/:0:0","tags":["Transfomer"],"title":"Transformer概述","uri":"/posts/%E7%A7%91%E7%A0%94/transformer%E6%A6%82%E8%BF%B0/"},{"categories":["科研"],"content":"Encoder seq2seq model Encoder 要做的事情,就是给一排向量，输出另外一排向量 给一排向量、输出一排向量这件事情,很多模型都可以做到,可能第一个想到的是,我们刚刚讲完的self-attention,其实不只self-attention,RNN CNN 其实也都能够做到,input一排向量,output另外一个同样长度的向量 在transformer裡面,transformer的Encoder,用的就是self-attention。 现在的Encoder裡面,会分成很多很多的block。 每一个block都是输入一排向量,输出一排向量,你输入一排向量 第一个block,第一个block输出另外一排向量,再输给另外一个block,到最后一个block,会输出最终的vector sequence,每一个block 其实,并不是neural network的一层 每一个block裡面做的事情,是好几个layer在做的事情,在transformer的Encoder裡面,每一个block做的事情,大概是这样子的 先做一个self-attention,input一排vector以后,做self-attention,考虑整个sequence的资讯，Output另外一排vector. 接下来这一排vector,会再丢到fully connected的feed forward network裡面,再output另外一排vector,这一排vector就是block的输出 ","date":"2021-10-10","objectID":"/posts/%E7%A7%91%E7%A0%94/transformer%E6%A6%82%E8%BF%B0/:1:0","tags":["Transfomer"],"title":"Transformer概述","uri":"/posts/%E7%A7%91%E7%A0%94/transformer%E6%A6%82%E8%BF%B0/"},{"categories":["科研"],"content":"residual connection 在之前self-attention的时候,我们输入一排vector,就输出一排vector,这边的每一个vector,它是考虑了所有的input以后,所得到的结果。 在transformer裡面,它加入了一个设计,不只是输出这个vector,我们还要把这个vector加上它的input,得到output。这样的架构叫residual connection ","date":"2021-10-10","objectID":"/posts/%E7%A7%91%E7%A0%94/transformer%E6%A6%82%E8%BF%B0/:1:1","tags":["Transfomer"],"title":"Transformer概述","uri":"/posts/%E7%A7%91%E7%A0%94/transformer%E6%A6%82%E8%BF%B0/"},{"categories":["科研"],"content":"layer normalization 得到residual的结果以后,再做normalization,这边用的不是batch normalization,这边用的叫做layer normalization。 layer normalization做的事情,比bacth normalization更简单一点 输入一个向量 输出另外一个向量,不需要考虑batch,它会把输入的这个向量,计算它的mean跟standard deviation 但是要注意一下,batch normalization是对不同example,不同feature的同一个dimension,去计算mean跟standard deviation 但layer normalization,它是对同一个feature,同一个example裡面,不同的dimension,去计算mean跟standard deviation 计算出mean,跟standard deviation以后,就可以做一个normalize,我们把input 这个vector裡面每一个,dimension减掉mean,再除以standard deviation以后得到x',就是layer normalization的输出 $$ x'_i=\\frac{x_i-m}{\\sigma} $$ 得到layer normalization的输出以后,它的这个输出 才是FC network的输入 而FC network这边,也有residual的架构,所以 我们会把FC network的input,跟它的output加起来 做一下residual,得到新的输出 这个FC network做完residual以后,还不是结束 你要把residual的结果,再做一次layer normalization,得到的输出,才是residual network裡面,一个block的输出。 步骤： 首先 做self-attention,其实在input的地方,还有加上positional encoding,加上positional的information。 Multi-Head Attention,这个就是self-attention的block。 Add\u0026norm,就是residual加layer normalization,我们刚才有说self-attention,有加上residual的connection,加下来还要过layer normalization,图上的Add\u0026norm,就是residual加layer norm的意思 接下来,要过feed forward network fc的feed forward network以后再做一次Add\u0026norm,再做一次residual加layer norm,才是一个block的输出, 然后这个block会重复n次。 ","date":"2021-10-10","objectID":"/posts/%E7%A7%91%E7%A0%94/transformer%E6%A6%82%E8%BF%B0/:1:2","tags":["Transfomer"],"title":"Transformer概述","uri":"/posts/%E7%A7%91%E7%A0%94/transformer%E6%A6%82%E8%BF%B0/"},{"categories":["科研"],"content":"Decoder Decoder其实有两种： Autoregressive（AT） Non-autoregressive (NAT) ","date":"2021-10-10","objectID":"/posts/%E7%A7%91%E7%A0%94/transformer%E6%A6%82%E8%BF%B0/:2:0","tags":["Transfomer"],"title":"Transformer概述","uri":"/posts/%E7%A7%91%E7%A0%94/transformer%E6%A6%82%E8%BF%B0/"},{"categories":["科研"],"content":"Autoregressive AT的Decoder会将上一个时间点自己的输出当做接下来的输入。 对比encoder和decoder，decoder中使用的self-attention，是masked self-attention。他的不同之处在于，masked的只考虑它左边的东西，不考虑它右边的东西。这才符合decoder的运作。 为了让Decoder决定输出的sequence的长度，还需要准备一个特殊的符号，用来表示终止。当他产生出来的向量是这个符号时，这个decoder产生sequence的过程就结束了。 ","date":"2021-10-10","objectID":"/posts/%E7%A7%91%E7%A0%94/transformer%E6%A6%82%E8%BF%B0/:2:1","tags":["Transfomer"],"title":"Transformer概述","uri":"/posts/%E7%A7%91%E7%A0%94/transformer%E6%A6%82%E8%BF%B0/"},{"categories":["科研"],"content":"Non-Autoregressive NAT和AT的不同点在于，NAT的Decoder吃一整排BEGIN的Token，然后产生一排的Token就结束了。 至于输出的长度为多少，没有办法很直接的知道,以下有几个做法： 另外learn一个 Classifier,这个 Classifier ,它吃 Encoder 的 Input,然后输出是一个数字,这个数字代表 Decoder 应该要输出的长度。 另一种可能做法就是,给它一堆 BEGIN 的 Token,假设输出的句子的长度,绝对不会超过 300 个字,给它 300 个 BEGIN,然后就会输出 300 个字，再看什麼地方输出 END,输出 END 右边的,就当做它没有输出。 ","date":"2021-10-10","objectID":"/posts/%E7%A7%91%E7%A0%94/transformer%E6%A6%82%E8%BF%B0/:2:2","tags":["Transfomer"],"title":"Transformer概述","uri":"/posts/%E7%A7%91%E7%A0%94/transformer%E6%A6%82%E8%BF%B0/"},{"categories":["科研"],"content":"NAT VS AT NAT的好处： 并行化。使用AT，是一个个产生的，假设要输出100个字的句子，就要做100次的decode。 能控制输出的长度。 NAT的劣势： 性能往往不如AT ","date":"2021-10-10","objectID":"/posts/%E7%A7%91%E7%A0%94/transformer%E6%A6%82%E8%BF%B0/:2:3","tags":["Transfomer"],"title":"Transformer概述","uri":"/posts/%E7%A7%91%E7%A0%94/transformer%E6%A6%82%E8%BF%B0/"},{"categories":["科研"],"content":"Encoder-Decoder encoder和decoder之间是如何传递的？ Cross-Attention： decoder 对输入做masked self-attention，产生一个q。 将q与encoder这边产生的k1、k2、k3计算attention的分数 再把得到的结果的weighted sum相加得到v v当做接下来decoder的fully connected network的input 参考 Vaswani, Ashish, et al. “Attention is all you need.” Advances in neural information processing systems 30 (2017). HUNG-YI LEE (李宏毅) “MACHINE LEARNING 2021 SPRING” ","date":"2021-10-10","objectID":"/posts/%E7%A7%91%E7%A0%94/transformer%E6%A6%82%E8%BF%B0/:3:0","tags":["Transfomer"],"title":"Transformer概述","uri":"/posts/%E7%A7%91%E7%A0%94/transformer%E6%A6%82%E8%BF%B0/"},{"categories":["科研"],"content":"LeNet LeNet( (conv): Sequential( (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1)) (1): Sigmoid() (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)) (4): Sigmoid() (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) ) (fc): Sequential( (0): Linear(in_features=256, out_features=120, bias=True) (1): Sigmoid() (2): Linear(in_features=120, out_features=84, bias=True) (3): Sigmoid() (4): Linear(in_features=84, out_features=10, bias=True) ) ) ","date":"2021-09-24","objectID":"/posts/%E7%A7%91%E7%A0%94/%E7%BB%8F%E5%85%B8cnn%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94/:1:0","tags":["CNN"],"title":"经典CNN模型对比","uri":"/posts/%E7%A7%91%E7%A0%94/%E7%BB%8F%E5%85%B8cnn%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94/"},{"categories":["科研"],"content":"AlexNet AlexNet( (conv): Sequential( (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4)) (1): ReLU() (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False) (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)) (4): ReLU() (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False) (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (7): ReLU() (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (9): ReLU() (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (11): ReLU() (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False) ) (fc): Sequential( (0): Linear(in_features=6400, out_features=4096, bias=True) (1): ReLU() (2): Dropout(p=0.5) (3): Linear(in_features=4096, out_features=4096, bias=True) (4): ReLU() (5): Dropout(p=0.5) (6): Linear(in_features=4096, out_features=10, bias=True) ) ) AlexNet与LeNet的区别： 第一，与相对较小的LeNet相比，AlexNet包含8层变换，其中有5层卷积和2层全连接隐藏层，以及1个全连接输出层。下面我们来详细描述这些层的设计。 AlexNet第一层中的卷积窗口形状是11*11。因为ImageNet中绝大多数图像的高和宽均比MNIST图像的高和宽大10倍以上，ImageNet图像的物体占用更多的像素，所以需要更大的卷积窗口来捕获物体。第二层中的卷积窗口形状减小到5×5，之后全采用3×3。此外，第一、第二和第五个卷积层之后都使用了窗口形状为3×3、步幅为2的最大池化层。而且，AlexNet使用的卷积通道数也大于LeNet中的卷积通道数数十倍。 紧接着最后一个卷积层的是两个输出个数为4096的全连接层。这两个巨大的全连接层带来将近1 GB的模型参数。由于早期显存的限制，最早的AlexNet使用双数据流的设计使一个GPU只需要处理一半模型。幸运的是，显存在过去几年得到了长足的发展，因此通常我们不再需要这样的特别设计了。 第二，AlexNet将sigmoid激活函数改成了更加简单的ReLU激活函数。一方面，ReLU激活函数的计算更简单，例如它并没有sigmoid激活函数中的求幂运算。另一方面，ReLU激活函数在不同的参数初始化方法下使模型更容易训练。这是由于当sigmoid激活函数输出极接近0或1时，这些区域的梯度几乎为0，从而造成反向传播无法继续更新部分模型参数；而ReLU激活函数在正区间的梯度恒为1。因此，若模型参数初始化不当，sigmoid函数可能在正区间得到几乎为0的梯度，从而令模型无法得到有效训练。 第三，AlexNet通过丢弃法dropout（参见3.13节）来控制全连接层的模型复杂度。而LeNet并没有使用丢弃法。 第四，AlexNet引入了大量的图像增广，如翻转、裁剪和颜色变化，从而进一步扩大数据集来缓解过拟合。我们将在后面的9.1节（图像增广）详细介绍这种方法。 在LeNet的基础上增加了3个卷积层（更深了），并对卷积窗口、输出通道数和构造顺序做了大量调整。 ","date":"2021-09-24","objectID":"/posts/%E7%A7%91%E7%A0%94/%E7%BB%8F%E5%85%B8cnn%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94/:2:0","tags":["CNN"],"title":"经典CNN模型对比","uri":"/posts/%E7%A7%91%E7%A0%94/%E7%BB%8F%E5%85%B8cnn%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94/"},{"categories":["科研"],"content":"VGG 由Visual Geometry Group实验室提出。VGG提出可以通过使用简单的基础块来构造深度模型的思路。 VGG块的组成规律是：连续使用数个相同的填充为1、窗口形状为3×3的卷积层后接上一个步幅为2、窗口形状为2×2的最大池化层。卷积层保持输入的高和宽不变，而池化层则对其减半。我们使用vgg_block函数来实现这个基础的VGG块，它可以指定卷积层的数量和输入输出通道数。 def vgg_block(num_convs, in_channels, out_channels): blk = [] for i in range(num_convs): if i == 0: blk.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)) else: blk.append(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)) blk.append(nn.ReLU()) blk.append(nn.MaxPool2d(kernel_size=2, stride=2)) # 这里会使宽高减半 return nn.Sequential(*blk) ","date":"2021-09-24","objectID":"/posts/%E7%A7%91%E7%A0%94/%E7%BB%8F%E5%85%B8cnn%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94/:3:0","tags":["CNN"],"title":"经典CNN模型对比","uri":"/posts/%E7%A7%91%E7%A0%94/%E7%BB%8F%E5%85%B8cnn%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94/"},{"categories":["科研"],"content":"NiN LeNet、AlexNet和VGG在设计上的共同之处是：先以由卷积层构成的模块充分抽取空间特征，再以由全连接层构成的模块来输出分类结果。其中，AlexNet和VGG对LeNet的改进主要在于如何对这两个模块加宽（增加通道数）和加深。NiN则提出了另外一个思路，即串联多个由卷积层和“全连接”层构成的小网络来构建一个深层网络。 NiN块是NiN中的基础块。它由一个卷积层加两个充当全连接层的1×1卷积层串联而成。其中第一个卷积层的超参数可以自行设置，而第二和第三个卷积层的超参数一般是固定的。 def nin_block(in_channels, out_channels, kernel_size, stride, padding): blk = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding), nn.ReLU(), nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU(), nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU()) return blk NiN是在AlexNet问世不久后提出的。它们的卷积层设定有类似之处。NiN使用卷积窗口形状分别为11×11、5×5和3×3的卷积层，相应的输出通道数也与AlexNet中的一致。每个NiN块后接一个步幅为2、窗口形状为3×3的最大池化层。 除使用NiN块以外，NiN还有一个设计与AlexNet显著不同：NiN去掉了AlexNet最后的3个全连接层，取而代之地，NiN使用了输出通道数等于标签类别数的NiN块，然后使用全局平均池化层对每个通道中所有元素求平均并直接用于分类。这里的全局平均池化层即窗口形状等于输入空间维形状的平均池化层。NiN的这个设计的好处是可以显著减小模型参数尺寸，从而缓解过拟合。然而，该设计有时会造成获得有效模型的训练时间的增加。 NiN重复使用由卷积层和代替全连接层的1×1卷积层构成的NiN块来构建深层网络。 NiN去除了容易造成过拟合的全连接输出层，而是将其替换成输出通道数等于标签类别数的NiN块和全局平均池化层。 NiN的以上设计思想影响了后面一系列卷积神经网络的设计。 ","date":"2021-09-24","objectID":"/posts/%E7%A7%91%E7%A0%94/%E7%BB%8F%E5%85%B8cnn%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94/:4:0","tags":["CNN"],"title":"经典CNN模型对比","uri":"/posts/%E7%A7%91%E7%A0%94/%E7%BB%8F%E5%85%B8cnn%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94/"},{"categories":["科研"],"content":"GoogLeNet Inception块中可以自定义的超参数是每个层的输出通道数，我们以此来控制模型复杂度。 Inception块相当于一个有4条线路的子网络。它通过不同窗口形状的卷积层和最大池化层来并行抽取信息，并使用1×1卷积层减少通道数从而降低模型复杂度。 GoogLeNet将多个设计精细的Inception块和其他层串联起来。其中Inception块的通道数分配之比是在ImageNet数据集上通过大量的实验得来的。 GoogLeNet和它的后继者们一度是ImageNet上最高效的模型之一：在类似的测试精度下，它们的计算复杂度往往更低。 ","date":"2021-09-24","objectID":"/posts/%E7%A7%91%E7%A0%94/%E7%BB%8F%E5%85%B8cnn%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94/:5:0","tags":["CNN"],"title":"经典CNN模型对比","uri":"/posts/%E7%A7%91%E7%A0%94/%E7%BB%8F%E5%85%B8cnn%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94/"},{"categories":["科研"],"content":"ResNet 残差网络 残差块： ResNet沿用了VGG全3×3卷积层的设计。残差块里首先有2个有相同输出通道数的3×3卷积层。每个卷积层后接一个批量归一化层和ReLU激活函数。然后我们将输入跳过这两个卷积运算后直接加在最后的ReLU激活函数前。这样的设计要求两个卷积层的输出与输入形状一样，从而可以相加。如果想改变通道数，就需要引入一个额外的1×1卷积层来将输入变换成需要的形状后再做相加运算。 ResNet模型 ResNet的前两层跟之前介绍的GoogLeNet中的一样：在输出通道数为64、步幅为2的7×7卷积层后接步幅为2的3×3的最大池化层。不同之处在于ResNet每个卷积层后增加的批量归一化层。 接着我们为ResNet加入所有残差块。这里每个模块使用两个残差块。 （GoogLeNet在后面接了4个由Inception块组成的模块。ResNet则使用4个由残差块组成的模块，每个模块使用若干个同样输出通道数的残差块。第一个模块的通道数同输入通道数一致。由于之前已经使用了步幅为2的最大池化层，所以无须减小高和宽。之后的每个模块在第一个残差块里将上一个模块的通道数翻倍，并将高和宽减半。） 最后，与GoogLeNet一样，加入全局平均池化层后接上全连接层输出。 (这里每个模块里有4个卷积层（不计算1×1卷积层），加上最开始的卷积层和最后的全连接层，共计18层。这个模型通常也被称为ResNet-18。通过配置不同的通道数和模块里的残差块数可以得到不同的ResNet模型，例如更深的含152层的ResNet-152。虽然ResNet的主体架构跟GoogLeNet的类似，但ResNet结构更简单，修改也更方便。这些因素都导致了ResNet迅速被广泛使用。) 残差块通过跨层的数据通道从而能够训练出有效的深度神经网络。 ResNet深刻影响了后来的深度神经网络的设计。 ","date":"2021-09-24","objectID":"/posts/%E7%A7%91%E7%A0%94/%E7%BB%8F%E5%85%B8cnn%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94/:6:0","tags":["CNN"],"title":"经典CNN模型对比","uri":"/posts/%E7%A7%91%E7%A0%94/%E7%BB%8F%E5%85%B8cnn%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94/"},{"categories":["科研"],"content":"DenseNet 稠密连接网络 ResNet中的跨层连接设计引申出了数个后续工作。其中一个就是DenseNet 稠密连接网络。 图5.10中将部分前后相邻的运算抽象为模块A和模块B。与ResNet的主要区别在于，DenseNet里模块B的输出不是像ResNet那样和模块A的输出相加，而是在通道维上连结。这样模块A的输出可以直接传入模块B后面的层。在这个设计里，模块A直接跟模块B后面的所有层连接在了一起。这也是它被称为“稠密连接”的原因。 DenseNet的主要构建模块是稠密块（dense block）和过渡层（transition layer）。前者定义了输入和输出是如何连结的，后者则用来控制通道数，使之不过大。 稠密块 def conv_block(in_channels, out_channels): blk = nn.Sequential(nn.BatchNorm2d(in_channels), nn.ReLU(), nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)) return blk 稠密块由多个conv_block组成，每块使用相同的输出通道数。但在前向计算时，我们将每块的输入和输出在通道维上连结。 class DenseBlock(nn.Module): def __init__(self, num_convs, in_channels, out_channels): super(DenseBlock, self).__init__() net = [] for i in range(num_convs): in_c = in_channels + i * out_channels net.append(conv_block(in_c, out_channels)) self.net = nn.ModuleList(net) self.out_channels = in_channels + num_convs * out_channels # 计算输出通道数 def forward(self, X): for blk in self.net: Y = blk(X) X = torch.cat((X, Y), dim=1) # 在通道维上将输入和输出连结 return X 过渡层 由于每个稠密块都会带来通道数的增加，使用过多则会带来过于复杂的模型。过渡层用来控制模型复杂度。它通过1×1卷积层来减小通道数，并使用步幅为2的平均池化层减半高和宽，从而进一步降低模型复杂度。 def transition_block(in_channels, out_channels): blk = nn.Sequential( nn.BatchNorm2d(in_channels), nn.ReLU(), nn.Conv2d(in_channels, out_channels, kernel_size=1), nn.AvgPool2d(kernel_size=2, stride=2)) return blk DenseNet模型 DenseNet首先使用同ResNet一样的单卷积层和最大池化层。 类似于ResNet接下来使用的4个残差块，DenseNet使用的是4个稠密块。同ResNet一样，我们可以设置每个稠密块使用多少个卷积层。这里我们设成4。稠密块里的卷积层通道数（即增长率）设为32，所以每个稠密块将增加128个通道。 ResNet里通过步幅为2的残差块在每个模块之间减小高和宽。这里我们则使用过渡层来减半高和宽，并减半通道数。 同ResNet一样，最后接上全局池化层和全连接层来输出。 net = nn.Sequential( nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2, padding=1)) num_channels, growth_rate = 64, 32 # num_channels为当前的通道数 num_convs_in_dense_blocks = [4, 4, 4, 4] for i, num_convs in enumerate(num_convs_in_dense_blocks): DB = DenseBlock(num_convs, num_channels, growth_rate) net.add_module(\"DenseBlosk_%d\" % i, DB) # 上一个稠密块的输出通道数 num_channels = DB.out_channels # 在稠密块之间加入通道数减半的过渡层 if i != len(num_convs_in_dense_blocks) - 1: net.add_module(\"transition_block_%d\" % i, transition_block(num_channels, num_channels // 2)) num_channels = num_channels // 2 net.add_module(\"BN\", nn.BatchNorm2d(num_channels)) net.add_module(\"relu\", nn.ReLU()) net.add_module(\"global_avg_pool\", d2l.GlobalAvgPool2d()) # GlobalAvgPool2d的输出: (Batch, num_channels, 1, 1) net.add_module(\"fc\", nn.Sequential(d2l.FlattenLayer(), nn.Linear(num_channels, 10))) 在跨层连接上，不同于ResNet中将输入与输出相加，DenseNet在通道维上连结输入与输出。 DenseNet的主要构建模块是稠密块和过渡层。 batch normalization 批量归一化（batch normalization）层，它能让较深的神经网络的训练变得更加容易。 数据标准化处理：处理后的任意一个特征在数据集中所有样本上的均值为0、标准差为1。标准化处理输入数据使各个特征的分布相近：这往往更容易训练出有效的模型。通常来说，数据标准化预处理对于浅层模型就足够有效了。随着模型训练的进行，当每层中参数更新时，靠近输出层的输出较难出现剧烈变化。 但对深层神经网络来说，即使输入数据已做标准化，训练中模型参数的更新依然很容易造成靠近输出层输出的剧烈变化。这种计算数值的不稳定性通常令我们难以训练出有效的深度模型。 批量归一化的提出正是为了应对深度模型训练的挑战。在模型训练时，批量归一化利用小批量上的均值和标准差，不断调整神经网络中间输出，从而使整个神经网络在各层的中间输出的数值更稳定。 ","date":"2021-09-24","objectID":"/posts/%E7%A7%91%E7%A0%94/%E7%BB%8F%E5%85%B8cnn%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94/:7:0","tags":["CNN"],"title":"经典CNN模型对比","uri":"/posts/%E7%A7%91%E7%A0%94/%E7%BB%8F%E5%85%B8cnn%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94/"},{"categories":["科研"],"content":"全连接层的批量归一化 通常，我们将批量归一化层置于全连接层中的仿射变换和激活函数之间。 ","date":"2021-09-24","objectID":"/posts/%E7%A7%91%E7%A0%94/%E7%BB%8F%E5%85%B8cnn%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94/:8:0","tags":["CNN"],"title":"经典CNN模型对比","uri":"/posts/%E7%A7%91%E7%A0%94/%E7%BB%8F%E5%85%B8cnn%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94/"},{"categories":["科研"],"content":"卷积层的批量归一化 对卷积层来说，批量归一化发生在卷积计算之后、应用激活函数之前。 如果卷积计算输出多个通道，我们需要对这些通道的输出分别做批量归一化，且每个通道都拥有独立的拉伸和偏移参数，并均为标量。 与我们刚刚自己定义的BatchNorm类相比，Pytorch中nn模块定义的BatchNorm1d和BatchNorm2d类使用起来更加简单，二者分别用于全连接层和卷积层，都需要指定输入的num_features参数值。num_features参数对于全连接层来说应为输出个数，对于卷积层来说则为输出通道数。 在模型训练时，批量归一化利用小批量上的均值和标准差，不断调整神经网络的中间输出，从而使整个神经网络在各层的中间输出的数值更稳定。 对全连接层和卷积层做批量归一化的方法稍有不同。 批量归一化层和丢弃层一样，在训练模式和预测模式的计算结果是不一样的。 PyTorch提供了BatchNorm类方便使用。 ","date":"2021-09-24","objectID":"/posts/%E7%A7%91%E7%A0%94/%E7%BB%8F%E5%85%B8cnn%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94/:9:0","tags":["CNN"],"title":"经典CNN模型对比","uri":"/posts/%E7%A7%91%E7%A0%94/%E7%BB%8F%E5%85%B8cnn%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94/"},{"categories":["技术笔记"],"content":"监控系统的作用 实时采集监控数据 实时反馈监控状态 预知故障和告警 辅助定位故障 辅助性能调优 辅助容量规划 辅助自动化运维 ","date":"2021-07-25","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E9%80%89%E5%9E%8B%E8%B0%83%E7%A0%94/:1:0","tags":["监控"],"title":"监控系统选型调研","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E9%80%89%E5%9E%8B%E8%B0%83%E7%A0%94/"},{"categories":["技术笔记"],"content":"如何使用监控系统 了解监控对象的工作原理 比如想对JVM进行监控，就必须清楚JVM的堆内存结构和垃圾回收机制。 确定监控对象的指标 比如想对某个接口进行监控，可以采用请求量、耗时、超时量、异常量等指标来衡量。 定义合理的报警阈值和等级 建立完善的故障处理流程 ","date":"2021-07-25","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E9%80%89%E5%9E%8B%E8%B0%83%E7%A0%94/:2:0","tags":["监控"],"title":"监控系统选型调研","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E9%80%89%E5%9E%8B%E8%B0%83%E7%A0%94/"},{"categories":["技术笔记"],"content":"监控对象和指标 硬件监控 电源、CPU、机器温度、风扇、物理磁盘、raid、内存、网卡 服务器基础监控 CPU：单个CPU以及整体的使用情况 内存：已用内存、可用内存 磁盘：磁盘使用率、磁盘读写的吞吐量 网络：出口流量、入口流量、TCP连接状态 数据库监控 数据库连接数 QPS、TPS 并行处理的会话数 缓存命中率 主从时延 锁状态 慢查询 中间件监控 Nginx：活跃连接数、等待、连接数、丢弃连接数、请求量、耗时、5XX错误率 Tomcat：最大线程数、当前线程数、请求量、耗时、错误量、堆内存使用情况、GC次数和耗时 缓存：成功连接数、阻塞连接数、已使用内存、内存碎片率、请求量、耗时、缓存命中率 消息队列：连接数、队列数、生成速率、消费速率、消息堆积量 应用监控 HTTP接口：URL存活、请求量、耗时、异常量 RPC接口：请求量、耗时、超时量、拒绝量 JVM：GC次数、GC耗时、各个内存区域的大小、当前线程数、死锁线程数 线程池：活跃线程数、任务队列大小、任务执行耗时、拒绝任务数 连接池：总连接数、活跃连接数 日志监控：访问日志、错误日志 业务指标：如PV、订单量 ","date":"2021-07-25","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E9%80%89%E5%9E%8B%E8%B0%83%E7%A0%94/:3:0","tags":["监控"],"title":"监控系统选型调研","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E9%80%89%E5%9E%8B%E8%B0%83%E7%A0%94/"},{"categories":["技术笔记"],"content":"主流监控系统 老牌监控系统： Zabbix Nagios Cacti Ganglia Garafana 新一代监控系统： Open-Falcon（自动采集，只要安装了falcon-agent的机器，就会自动开始采集各项指标，主动上报，不需要用户在server做任何配置） Prometheus（采用pull模式） ","date":"2021-07-25","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E9%80%89%E5%9E%8B%E8%B0%83%E7%A0%94/:4:0","tags":["监控"],"title":"监控系统选型调研","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E9%80%89%E5%9E%8B%E8%B0%83%E7%A0%94/"},{"categories":["技术笔记"],"content":"Spring Boot Admin 可以监控spring-boot项目的基本信息比如：Spring容器管理的所有的bean、详细的Health信息、内存信息、JVM信息、垃圾回收信息、各种配置信息（比如数据源、缓存列表和命中率）等，Threads 线程管理，Environment 管理等。 支持多种告警方式接入，如企业微信、钉钉、邮件、短信。 可满足spring boot项目轻量级的使用。 在SBA中，Server作为注册中心，监控所有客户端当前的状态，服务端和客户端之间通过/health接口进行通信，依次来对客户端进行监听。服务端通过定时轮询客户端的/health接口来对客户端进行心态检测。 客户端通过 Actuator 获取信息。 ","date":"2021-07-25","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E9%80%89%E5%9E%8B%E8%B0%83%E7%A0%94/:5:0","tags":["监控"],"title":"监控系统选型调研","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E9%80%89%E5%9E%8B%E8%B0%83%E7%A0%94/"},{"categories":["技术笔记"],"content":"选型建议 首先要明确需求：要监控的对象有哪些，机器数量和监控指标有多少，需要具备什么样的功能。 不要想一开始就all in one，从成本考虑，初期直接使用开源的方案即可，解决从无到有。 Zabbix在服务器监控方面占绝对优势，但对应用层监控并不擅长。这点Open-Falcon和Prometheus做的比较好。 新一代监控系统的明显优势：灵活的数据模型，更成熟的时序数据库，强大的告警功能。如果没有对老牌监控系统的技术积累的话，建议直接使用Open-Falcon或Prometheus。 Open-Falcon的核心优势在于数据分片功能，能支撑更多的机器和监控项；Prometheus则是容器监控方面的标配，有Google和k8s加持。 Zabbix、Open-Falcon和Prometheus都支持和Grafana做快速集成，想要美观且强大的可视化体验，可以和Grafana进行组合。 轻量级使用，可使用SBA，并可对其扩展。 Prometheus 也可以选择买阿里云的产品。。。 ","date":"2021-07-25","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E9%80%89%E5%9E%8B%E8%B0%83%E7%A0%94/:6:0","tags":["监控"],"title":"监控系统选型调研","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E9%80%89%E5%9E%8B%E8%B0%83%E7%A0%94/"},{"categories":["技术笔记"],"content":"参考 https://www.daimajiaoliu.com/daima/7b7376aeb0be805 https://cloud.tencent.com/developer/article/1704555 https://xie.infoq.cn/article/e1d2ad0d57d9fc6b2bb8fd6a5 https://github.com/codecentric/spring-boot-admin ","date":"2021-07-25","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E9%80%89%E5%9E%8B%E8%B0%83%E7%A0%94/:7:0","tags":["监控"],"title":"监控系统选型调研","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E9%80%89%E5%9E%8B%E8%B0%83%E7%A0%94/"},{"categories":["好文转载"],"content":"随着计算机行业的飞速发展，摩尔定律逐渐失效，多核CPU成为主流。使用多线程并行计算逐渐成为开发人员提升服务器性能的基本武器。J.U.C提供的线程池：ThreadPoolExecutor类，帮助开发人员管理线程并方便地执行并行任务。了解并合理使用线程池，是一个开发人员必修的基本功。 本文开篇简述线程池概念和用途，接着结合线程池的源码，帮助读者领略线程池的设计思路，最后回归实践，通过案例讲述使用线程池遇到的问题，并给出了一种动态化线程池解决方案。 ","date":"2021-07-14","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%9C%A8%E7%BE%8E%E5%9B%A2%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/:0:0","tags":["线程池"],"title":"Java线程池实现原理及其在美团业务中的实践","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%9C%A8%E7%BE%8E%E5%9B%A2%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/"},{"categories":["好文转载"],"content":"一、写在前面 ","date":"2021-07-14","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%9C%A8%E7%BE%8E%E5%9B%A2%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/:1:0","tags":["线程池"],"title":"Java线程池实现原理及其在美团业务中的实践","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%9C%A8%E7%BE%8E%E5%9B%A2%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/"},{"categories":["好文转载"],"content":"1.1 线程池是什么 线程池（Thread Pool）是一种基于池化思想管理线程的工具，经常出现在多线程服务器中，如MySQL。 线程过多会带来额外的开销，其中包括创建销毁线程的开销、调度线程的开销等等，同时也降低了计算机的整体性能。线程池维护多个线程，等待监督管理者分配可并发执行的任务。这种做法，一方面避免了处理任务时创建销毁线程开销的代价，另一方面避免了线程数量膨胀导致的过分调度问题，保证了对内核的充分利用。 而本文描述线程池是JDK中提供的ThreadPoolExecutor类。 当然，使用线程池可以带来一系列好处： 降低资源消耗：通过池化技术重复利用已创建的线程，降低线程创建和销毁造成的损耗。 提高响应速度：任务到达时，无需等待线程创建即可立即执行。 提高线程的可管理性：线程是稀缺资源，如果无限制创建，不仅会消耗系统资源，还会因为线程的不合理分布导致资源调度失衡，降低系统的稳定性。使用线程池可以进行统一的分配、调优和监控。 提供更多更强大的功能：线程池具备可拓展性，允许开发人员向其中增加更多的功能。比如延时定时线程池ScheduledThreadPoolExecutor，就允许任务延期执行或定期执行。 ","date":"2021-07-14","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%9C%A8%E7%BE%8E%E5%9B%A2%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/:1:1","tags":["线程池"],"title":"Java线程池实现原理及其在美团业务中的实践","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%9C%A8%E7%BE%8E%E5%9B%A2%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/"},{"categories":["好文转载"],"content":"1.2 线程池解决的问题是什么 线程池解决的核心问题就是资源管理问题。在并发环境下，系统不能够确定在任意时刻中，有多少任务需要执行，有多少资源需要投入。这种不确定性将带来以下若干问题： 频繁申请/销毁资源和调度资源，将带来额外的消耗，可能会非常巨大。 对资源无限申请缺少抑制手段，易引发系统资源耗尽的风险。 系统无法合理管理内部的资源分布，会降低系统的稳定性。 为解决资源分配这个问题，线程池采用了“池化”（Pooling）思想。池化，顾名思义，是为了最大化收益并最小化风险，而将资源统一在一起管理的一种思想。 Pooling is the grouping together of resources (assets, equipment, personnel, effort, etc.) for the purposes of maximizing advantage or minimizing risk to the users. The term is used in finance, computing and equipment management.——wikipedia “池化”思想不仅仅能应用在计算机领域，在金融、设备、人员管理、工作管理等领域也有相关的应用。 在计算机领域中的表现为：统一管理IT资源，包括服务器、存储、和网络资源等等。通过共享资源，使用户在低投入中获益。除去线程池，还有其他比较典型的几种使用策略包括： 内存池(Memory Pooling)：预先申请内存，提升申请内存速度，减少内存碎片。 连接池(Connection Pooling)：预先申请数据库连接，提升申请连接的速度，降低系统的开销。 实例池(Object Pooling)：循环使用对象，减少资源在初始化和释放时的昂贵损耗。 在了解完“是什么”和“为什么”之后，下面我们来一起深入一下线程池的内部实现原理。 ","date":"2021-07-14","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%9C%A8%E7%BE%8E%E5%9B%A2%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/:1:2","tags":["线程池"],"title":"Java线程池实现原理及其在美团业务中的实践","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%9C%A8%E7%BE%8E%E5%9B%A2%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/"},{"categories":["好文转载"],"content":"二、线程池核心设计与实现 在前文中，我们了解到：线程池是一种通过“池化”思想，帮助我们管理线程而获取并发性的工具，在Java中的体现是ThreadPoolExecutor类。那么它的的详细设计与实现是什么样的呢？我们会在本章进行详细介绍。 ","date":"2021-07-14","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%9C%A8%E7%BE%8E%E5%9B%A2%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/:2:0","tags":["线程池"],"title":"Java线程池实现原理及其在美团业务中的实践","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%9C%A8%E7%BE%8E%E5%9B%A2%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/"},{"categories":["好文转载"],"content":"2.1 总体设计 Java中的线程池核心实现类是ThreadPoolExecutor，本章基于JDK 1.8的源码来分析Java线程池的核心设计与实现。我们首先来看一下ThreadPoolExecutor的UML类图，了解下ThreadPoolExecutor的继承关系。 图1 ThreadPoolExecutor UML类图 ThreadPoolExecutor实现的顶层接口是Executor，顶层接口Executor提供了一种思想：将任务提交和任务执行进行解耦。用户无需关注如何创建线程，如何调度线程来执行任务，用户只需提供Runnable对象，将任务的运行逻辑提交到执行器(Executor)中，由Executor框架完成线程的调配和任务的执行部分。ExecutorService接口增加了一些能力：（1）扩充执行任务的能力，补充可以为一个或一批异步任务生成Future的方法；（2）提供了管控线程池的方法，比如停止线程池的运行。AbstractExecutorService则是上层的抽象类，将执行任务的流程串联了起来，保证下层的实现只需关注一个执行任务的方法即可。最下层的实现类ThreadPoolExecutor实现最复杂的运行部分，ThreadPoolExecutor将会一方面维护自身的生命周期，另一方面同时管理线程和任务，使两者良好的结合从而执行并行任务。 ThreadPoolExecutor是如何运行，如何同时维护线程和执行任务的呢？其运行机制如下图所示： 图2 ThreadPoolExecutor运行流程 线程池在内部实际上构建了一个生产者消费者模型，将线程和任务两者解耦，并不直接关联，从而良好的缓冲任务，复用线程。线程池的运行主要分成两部分：任务管理、线程管理。任务管理部分充当生产者的角色，当任务提交后，线程池会判断该任务后续的流转：（1）直接申请线程执行该任务；（2）缓冲到队列中等待线程执行；（3）拒绝该任务。线程管理部分是消费者，它们被统一维护在线程池内，根据任务请求进行线程的分配，当线程执行完任务后则会继续获取新的任务去执行，最终当线程获取不到任务的时候，线程就会被回收。 接下来，我们会按照以下三个部分去详细讲解线程池运行机制： 线程池如何维护自身状态。 线程池如何管理任务。 线程池如何管理线程。 ","date":"2021-07-14","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%9C%A8%E7%BE%8E%E5%9B%A2%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/:2:1","tags":["线程池"],"title":"Java线程池实现原理及其在美团业务中的实践","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%9C%A8%E7%BE%8E%E5%9B%A2%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/"},{"categories":["好文转载"],"content":"2.2 生命周期管理 线程池运行的状态，并不是用户显式设置的，而是伴随着线程池的运行，由内部来维护。线程池内部使用一个变量维护两个值：运行状态(runState)和线程数量 (workerCount)。在具体实现中，线程池将运行状态(runState)、线程数量 (workerCount)两个关键参数的维护放在了一起，如下代码所示： private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); ctl这个AtomicInteger类型，是对线程池的运行状态和线程池中有效线程的数量进行控制的一个字段， 它同时包含两部分的信息：线程池的运行状态 (runState) 和线程池内有效线程的数量 (workerCount)，高3位保存runState，低29位保存workerCount，两个变量之间互不干扰。用一个变量去存储两个值，可避免在做相关决策时，出现不一致的情况，不必为了维护两者的一致，而占用锁资源。通过阅读线程池源代码也可以发现，经常出现要同时判断线程池运行状态和线程数量的情况。线程池也提供了若干方法去供用户获得线程池当前的运行状态、线程个数。这里都使用的是位运算的方式，相比于基本运算，速度也会快很多。 关于内部封装的获取生命周期状态、获取线程池线程数量的计算方法如以下代码所示： private static int runStateOf(int c) { return c \u0026 ~CAPACITY; } //计算当前运行状态 private static int workerCountOf(int c) { return c \u0026 CAPACITY; } //计算当前线程数量 private static int ctlOf(int rs, int wc) { return rs | wc; } //通过状态和线程数生成ctl ThreadPoolExecutor的运行状态有5种，分别为： 其生命周期转换如下入所示： 图3 线程池生命周期 ","date":"2021-07-14","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%9C%A8%E7%BE%8E%E5%9B%A2%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/:2:2","tags":["线程池"],"title":"Java线程池实现原理及其在美团业务中的实践","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%9C%A8%E7%BE%8E%E5%9B%A2%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/"},{"categories":["好文转载"],"content":"2.3 任务执行机制 2.3.1 任务调度 任务调度是线程池的主要入口，当用户提交了一个任务，接下来这个任务将如何执行都是由这个阶段决定的。了解这部分就相当于了解了线程池的核心运行机制。 首先，所有任务的调度都是由execute方法完成的，这部分完成的工作是：检查现在线程池的运行状态、运行线程数、运行策略，决定接下来执行的流程，是直接申请线程执行，或是缓冲到队列中执行，亦或是直接拒绝该任务。其执行过程如下： 首先检测线程池运行状态，如果不是RUNNING，则直接拒绝，线程池要保证在RUNNING的状态下执行任务。 如果workerCount \u003c corePoolSize，则创建并启动一个线程来执行新提交的任务。 如果workerCount \u003e= corePoolSize，且线程池内的阻塞队列未满，则将任务添加到该阻塞队列中。 如果workerCount \u003e= corePoolSize \u0026\u0026 workerCount \u003c maximumPoolSize，且线程池内的阻塞队列已满，则创建并启动一个线程来执行新提交的任务。 如果workerCount \u003e= maximumPoolSize，并且线程池内的阻塞队列已满, 则根据拒绝策略来处理该任务, 默认的处理方式是直接抛异常。 其执行流程如下图所示： 图4 任务调度流程 2.3.2 任务缓冲 任务缓冲模块是线程池能够管理任务的核心部分。线程池的本质是对任务和线程的管理，而做到这一点最关键的思想就是将任务和线程两者解耦，不让两者直接关联，才可以做后续的分配工作。线程池中是以生产者消费者模式，通过一个阻塞队列来实现的。阻塞队列缓存任务，工作线程从阻塞队列中获取任务。 阻塞队列(BlockingQueue)是一个支持两个附加操作的队列。这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。 下图中展示了线程1往阻塞队列中添加元素，而线程2从阻塞队列中移除元素： 图5 阻塞队列 使用不同的队列可以实现不一样的任务存取策略。在这里，我们可以再介绍下阻塞队列的成员： 2.3.3 任务申请 由上文的任务分配部分可知，任务的执行有两种可能：一种是任务直接由新创建的线程执行。另一种是线程从任务队列中获取任务然后执行，执行完任务的空闲线程会再次去从队列中申请任务再去执行。第一种情况仅出现在线程初始创建的时候，第二种是线程获取任务绝大多数的情况。 线程需要从任务缓存模块中不断地取任务执行，帮助线程从阻塞队列中获取任务，实现线程管理模块和任务管理模块之间的通信。这部分策略由getTask方法实现，其执行流程如下图所示： 图6 获取任务流程图 getTask这部分进行了多次判断，为的是控制线程的数量，使其符合线程池的状态。如果线程池现在不应该持有那么多线程，则会返回null值。工作线程Worker会不断接收新任务去执行，而当工作线程Worker接收不到任务的时候，就会开始被回收。 2.3.4 任务拒绝 任务拒绝模块是线程池的保护部分，线程池有一个最大的容量，当线程池的任务缓存队列已满，并且线程池中的线程数目达到maximumPoolSize时，就需要拒绝掉该任务，采取任务拒绝策略，保护线程池。 拒绝策略是一个接口，其设计如下： public interface RejectedExecutionHandler { void rejectedExecution(Runnable r, ThreadPoolExecutor executor); } 用户可以通过实现这个接口去定制拒绝策略，也可以选择JDK提供的四种已有拒绝策略，其特点如下： 2.4 Worker线程管理 2.4.1 Worker线程 线程池为了掌握线程的状态并维护线程的生命周期，设计了线程池内的工作线程Worker。我们来看一下它的部分代码： private final class Worker extends AbstractQueuedSynchronizer implements Runnable{ final Thread thread;//Worker持有的线程 Runnable firstTask;//初始化的任务，可以为null } Worker这个工作线程，实现了Runnable接口，并持有一个线程thread，一个初始化的任务firstTask。thread是在调用构造方法时通过ThreadFactory来创建的线程，可以用来执行任务；firstTask用它来保存传入的第一个任务，这个任务可以有也可以为null。如果这个值是非空的，那么线程就会在启动初期立即执行这个任务，也就对应核心线程创建时的情况；如果这个值是null，那么就需要创建一个线程去执行任务列表（workQueue）中的任务，也就是非核心线程的创建。 Worker执行任务的模型如下图所示： 图7 Worker执行任务 线程池需要管理线程的生命周期，需要在线程长时间不运行的时候进行回收。线程池使用一张Hash表去持有线程的引用，这样可以通过添加引用、移除引用这样的操作来控制线程的生命周期。这个时候重要的就是如何判断线程是否在运行。 Worker是通过继承AQS，使用AQS来实现独占锁这个功能。没有使用可重入锁ReentrantLock，而是使用AQS，为的就是实现不可重入的特性去反应线程现在的执行状态。 1.lock方法一旦获取了独占锁，表示当前线程正在执行任务中。 2.如果正在执行任务，则不应该中断线程。 3.如果该线程现在不是独占锁的状态，也就是空闲的状态，说明它没有在处理任务，这时可以对该线程进行中断。 4.线程池在执行shutdown方法或tryTerminate方法时会调用interruptIdleWorkers方法来中断空闲的线程，interruptIdleWorkers方法会使用tryLock方法来判断线程池中的线程是否是空闲状态；如果线程是空闲状态则可以安全回收。 在线程回收过程中就使用到了这种特性，回收过程如下图所示： 图8 线程池回收过程 2.4.2 Worker线程增加 增加线程是通过线程池中的addWorker方法，该方法的功能就是增加一个线程，该方法不考虑线程池是在哪个阶段增加的该线程，这个分配线程的策略是在上个步骤完成的，该步骤仅仅完成增加线程，并使它运行，最后返回是否成功这个结果。addWorker方法有两个参数：firstTask、core。firstTask参数用于指定新增的线程执行的第一个任务，该参数可以为空；core参数为true表示在新增线程时会判断当前活动线程数是否少于corePoolSize，false表示新增线程前需要判断当前活动线程数是否少于maximumPoolSize，其执行流程如下图所示： 图9 申请线程执行流程图 2.4.3 Worker线程回收 线程池中线程的销毁依赖JVM自动的回收，线程池做的工作是根据当前线程池的状态维护一定数量的线程引用，防止这部分线程被JVM回收，当线程池决定哪些线程需要回收时，只需要将其引用消除即可。Worker被创建出来后，就会不断地进行轮询，然后获取任务去执行，核心线程可以无限等待获取任务，非核心线程要限时获取任务。当Worker无法获取到任务，也就是获取的任务为空时，循环会结束，Worker会主动消除自身在线程池内的引用。 try { while (task != null || (task = getTask()) != null) { //执行任务 } } finally { processWorkerExit(w, completedAbruptly);//获取不到任务时，主动回收自己 } 线程回收的工作是在processWorkerExit方法完成的。 图10 线程销毁流程 事实上，在这个方法中，将线程引用移出线程池就已经结束了线程销毁的部分。但由于引起线程销毁的可能性有很多，线程池还要判断是什么引发了这次销毁，是否要改变线程池的现阶段状态，是否要根据新状态，重新分配线程。 2.4.4 Worker线程执行任务 在Worker类中的run方法调用了runWorker方法来执行任务，runWorker方法的执行过程如下： 1.while循环不断地通过getTask()方法获取任务。 2.getTask()方法从阻塞队列中取任务。 3.如果线程池正在停止，那么要保证当前线程是中断状态，否则要保证当前线程不是中断状态。 4.执行任务。 5.如果getTask结果为null则跳出循环，执行processWorkerExit()方法，销毁线程。 执行流程如下图所示： 图11 执行任务流程 ","date":"2021-07-14","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%9C%A8%E7%BE%8E%E5%9B%A2%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/:2:3","tags":["线程池"],"title":"Java线程池实现原理及其在美团业务中的实践","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%9C%A8%E7%BE%8E%E5%9B%A2%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/"},{"categories":["好文转载"],"content":"三、线程池在业务中的实践 ","date":"2021-07-14","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%9C%A8%E7%BE%8E%E5%9B%A2%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/:3:0","tags":["线程池"],"title":"Java线程池实现原理及其在美团业务中的实践","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%9C%A8%E7%BE%8E%E5%9B%A2%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/"},{"categories":["好文转载"],"content":"3.1 业务背景 在当今的互联网业界，为了最大程度利用CPU的多核性能，并行运算的能力是不可或缺的。通过线程池管理线程获取并发性是一个非常基础的操作，让我们来看两个典型的使用线程池获取并发性的场景。 场景1：快速响应用户请求 描述：用户发起的实时请求，服务追求响应时间。比如说用户要查看一个商品的信息，那么我们需要将商品维度的一系列信息如商品的价格、优惠、库存、图片等等聚合起来，展示给用户。 分析：从用户体验角度看，这个结果响应的越快越好，如果一个页面半天都刷不出，用户可能就放弃查看这个商品了。而面向用户的功能聚合通常非常复杂，伴随着调用与调用之间的级联、多级级联等情况，业务开发同学往往会选择使用线程池这种简单的方式，将调用封装成任务并行的执行，缩短总体响应时间。另外，使用线程池也是有考量的，这种场景最重要的就是获取最大的响应速度去满足用户，所以应该不设置队列去缓冲并发任务，调高corePoolSize和maxPoolSize去尽可能创造多的线程快速执行任务。 图12 并行执行任务提升任务响应速度 场景2：快速处理批量任务 描述：离线的大量计算任务，需要快速执行。比如说，统计某个报表，需要计算出全国各个门店中有哪些商品有某种属性，用于后续营销策略的分析，那么我们需要查询全国所有门店中的所有商品，并且记录具有某属性的商品，然后快速生成报表。 分析：这种场景需要执行大量的任务，我们也会希望任务执行的越快越好。这种情况下，也应该使用多线程策略，并行计算。但与响应速度优先的场景区别在于，这类场景任务量巨大，并不需要瞬时的完成，而是关注如何使用有限的资源，尽可能在单位时间内处理更多的任务，也就是吞吐量优先的问题。所以应该设置队列去缓冲并发任务，调整合适的corePoolSize去设置处理任务的线程数。在这里，设置的线程数过多可能还会引发线程上下文切换频繁的问题，也会降低处理任务的速度，降低吞吐量。 图13 并行执行任务提升批量任务执行速度 ","date":"2021-07-14","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%9C%A8%E7%BE%8E%E5%9B%A2%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/:3:1","tags":["线程池"],"title":"Java线程池实现原理及其在美团业务中的实践","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%9C%A8%E7%BE%8E%E5%9B%A2%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/"},{"categories":["好文转载"],"content":"3.2 实际问题及方案思考 线程池使用面临的核心的问题在于：线程池的参数并不好配置。一方面线程池的运行机制不是很好理解，配置合理需要强依赖开发人员的个人经验和知识；另一方面，线程池执行的情况和任务类型相关性较大，IO密集型和CPU密集型的任务运行起来的情况差异非常大，这导致业界并没有一些成熟的经验策略帮助开发人员参考。 关于线程池配置不合理引发的故障，公司内部有较多记录，下面举一些例子： Case1：2018年XX页面展示接口大量调用降级： 事故描述：XX页面展示接口产生大量调用降级，数量级在几十到上百。 事故原因：该服务展示接口内部逻辑使用线程池做并行计算，由于没有预估好调用的流量，导致最大核心数设置偏小，大量抛出RejectedExecutionException，触发接口降级条件，示意图如下： 图14 线程数核心设置过小引发RejectExecutionException Case2：2018年XX业务服务不可用S2级故障 事故描述：XX业务提供的服务执行时间过长，作为上游服务整体超时，大量下游服务调用失败。 事故原因：该服务处理请求内部逻辑使用线程池做资源隔离，由于队列设置过长，最大线程数设置失效，导致请求数量增加时，大量任务堆积在队列中，任务执行时间过长，最终导致下游服务的大量调用超时失败。示意图如下： 图15 线程池队列长度设置过长、corePoolSize设置过小导致任务执行速度低 业务中要使用线程池，而使用不当又会导致故障，那么我们怎样才能更好地使用线程池呢？针对这个问题，我们下面延展几个方向： 1. 能否不用线程池? 回到最初的问题，业务使用线程池是为了获取并发性，对于获取并发性，是否可以有什么其他的方案呢替代？我们尝试进行了一些其他方案的调研： 综合考虑，这些新的方案都能在某种情况下提升并行任务的性能，然而本次重点解决的问题是如何更简易、更安全地获得的并发性。另外，Actor模型的应用实际上甚少，只在Scala中使用广泛，协程框架在Java中维护的也不成熟。这三者现阶段都不是足够的易用，也并不能解决业务上现阶段的问题。 2. 追求参数设置合理性？ 有没有一种计算公式，能够让开发同学很简易地计算出某种场景中的线程池应该是什么参数呢？ 带着这样的疑问，我们调研了业界的一些线程池参数配置方案： 调研了以上业界方案后，我们并没有得出通用的线程池计算方式。并发任务的执行情况和任务类型相关，IO密集型和CPU密集型的任务运行起来的情况差异非常大，但这种占比是较难合理预估的，这导致很难有一个简单有效的通用公式帮我们直接计算出结果。 3. 线程池参数动态化？ 尽管经过谨慎的评估，仍然不能够保证一次计算出来合适的参数，那么我们是否可以将修改线程池参数的成本降下来，这样至少可以发生故障的时候可以快速调整从而缩短故障恢复的时间呢？基于这个思考，我们是否可以将线程池的参数从代码中迁移到分布式配置中心上，实现线程池参数可动态配置和即时生效，线程池参数动态化前后的参数修改流程对比如下： 图16 动态修改线程池参数新旧流程对比 基于以上三个方向对比，我们可以看出参数动态化方向简单有效。 ","date":"2021-07-14","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%9C%A8%E7%BE%8E%E5%9B%A2%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/:3:2","tags":["线程池"],"title":"Java线程池实现原理及其在美团业务中的实践","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%9C%A8%E7%BE%8E%E5%9B%A2%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/"},{"categories":["好文转载"],"content":"3.3 动态化线程池 3.3.1 整体设计 动态化线程池的核心设计包括以下三个方面： 简化线程池配置：线程池构造参数有8个，但是最核心的是3个：corePoolSize、maximumPoolSize，workQueue，它们最大程度地决定了线程池的任务分配和线程分配策略。考虑到在实际应用中我们获取并发性的场景主要是两种：（1）并行执行子任务，提高响应速度。这种情况下，应该使用同步队列，没有什么任务应该被缓存下来，而是应该立即执行。（2）并行执行大批次任务，提升吞吐量。这种情况下，应该使用有界队列，使用队列去缓冲大批量的任务，队列容量必须声明，防止任务无限制堆积。所以线程池只需要提供这三个关键参数的配置，并且提供两种队列的选择，就可以满足绝大多数的业务需求，Less is More。 参数可动态修改：为了解决参数不好配，修改参数成本高等问题。在Java线程池留有高扩展性的基础上，封装线程池，允许线程池监听同步外部的消息，根据消息进行修改配置。将线程池的配置放置在平台侧，允许开发同学简单的查看、修改线程池配置。 增加线程池监控：对某事物缺乏状态的观测，就对其改进无从下手。在线程池执行任务的生命周期添加监控能力，帮助开发同学了解线程池状态。 图17 动态化线程池整体设计 3.3.2 功能架构 动态化线程池提供如下功能： 动态调参：支持线程池参数动态调整、界面化操作；包括修改线程池核心大小、最大核心大小、队列长度等；参数修改后及时生效。 任务监控：支持应用粒度、线程池粒度、任务粒度的Transaction监控；可以看到线程池的任务执行情况、最大任务执行时间、平均任务执行时间、95/99线等。 负载告警：线程池队列任务积压到一定值的时候会通过大象（美团内部通讯工具）告知应用开发负责人；当线程池负载数达到一定阈值的时候会通过大象告知应用开发负责人。 操作监控：创建/修改和删除线程池都会通知到应用的开发负责人。 操作日志：可以查看线程池参数的修改记录，谁在什么时候修改了线程池参数、修改前的参数值是什么。 权限校验：只有应用开发负责人才能够修改应用的线程池参数。 图18 动态化线程池功能架构 参数动态化 JDK原生线程池ThreadPoolExecutor提供了如下几个public的setter方法，如下图所示： 图19 JDK 线程池参数设置接口 JDK允许线程池使用方通过ThreadPoolExecutor的实例来动态设置线程池的核心策略，以setCorePoolSize为方法例，在运行期线程池使用方调用此方法设置corePoolSize之后，线程池会直接覆盖原来的corePoolSize值，并且基于当前值和原始值的比较结果采取不同的处理策略。对于当前值小于当前工作线程数的情况，说明有多余的worker线程，此时会向当前idle的worker线程发起中断请求以实现回收，多余的worker在下次idel的时候也会被回收；对于当前值大于原始值且当前队列中有待执行任务，则线程池会创建新的worker线程来执行队列任务，setCorePoolSize具体流程如下： 图20 setCorePoolSize方法执行流程 线程池内部会处理好当前状态做到平滑修改，其他几个方法限于篇幅，这里不一一介绍。重点是基于这几个public方法，我们只需要维护ThreadPoolExecutor的实例，并且在需要修改的时候拿到实例修改其参数即可。基于以上的思路，我们实现了线程池参数的动态化、线程池参数在管理平台可配置可修改，其效果图如下图所示： 图21 可动态修改线程池参数 用户可以在管理平台上通过线程池的名字找到指定的线程池，然后对其参数进行修改，保存后会实时生效。目前支持的动态参数包括核心数、最大值、队列长度等。除此之外，在界面中，我们还能看到用户可以配置是否开启告警、队列等待任务告警阈值、活跃度告警等等。关于监控和告警，我们下面一节会对齐进行介绍。 线程池监控 除了参数动态化之外，为了更好地使用线程池，我们需要对线程池的运行状况有感知，比如当前线程池的负载是怎么样的？分配的资源够不够用？任务的执行情况是怎么样的？是长任务还是短任务？基于对这些问题的思考，动态化线程池提供了多个维度的监控和告警能力，包括：线程池活跃度、任务的执行Transaction（频率、耗时）、Reject异常、线程池内部统计信息等等，既能帮助用户从多个维度分析线程池的使用情况，又能在出现问题第一时间通知到用户，从而避免故障或加速故障恢复。 1. 负载监控和告警 线程池负载关注的核心问题是：基于当前线程池参数分配的资源够不够。对于这个问题，我们可以从事前和事中两个角度来看。事前，线程池定义了“活跃度”这个概念，来让用户在发生Reject异常之前能够感知线程池负载问题，线程池活跃度计算公式为：线程池活跃度 = activeCount/maximumPoolSize。这个公式代表当活跃线程数趋向于maximumPoolSize的时候，代表线程负载趋高。事中，也可以从两方面来看线程池的过载判定条件，一个是发生了Reject异常，一个是队列中有等待任务（支持定制阈值）。以上两种情况发生了都会触发告警，告警信息会通过大象推送给服务所关联的负责人。 图22 大象告警通知 2. 任务级精细化监控 在传统的线程池应用场景中，线程池中的任务执行情况对于用户来说是透明的。比如在一个具体的业务场景中，业务开发申请了一个线程池同时用于执行两种任务，一个是发消息任务、一个是发短信任务，这两类任务实际执行的频率和时长对于用户来说没有一个直观的感受，很可能这两类任务不适合共享一个线程池，但是由于用户无法感知，因此也无从优化。动态化线程池内部实现了任务级别的埋点，且允许为不同的业务任务指定具有业务含义的名称，线程池内部基于这个名称做Transaction打点，基于这个功能，用户可以看到线程池内部任务级别的执行情况，且区分业务，任务监控示意图如下图所示： 图23 线程池任务执行监控 3. 运行时状态实时查看 用户基于JDK原生线程池ThreadPoolExecutor提供的几个public的getter方法，可以读取到当前线程池的运行状态以及参数，如下图所示： 图24 线程池实时运行情况 动态化线程池基于这几个接口封装了运行时状态实时查看的功能，用户基于这个功能可以了解线程池的实时状态，比如当前有多少个工作线程，执行了多少个任务，队列中等待的任务数等等。效果如下图所示： 图25 线程池实时运行情况 ","date":"2021-07-14","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%9C%A8%E7%BE%8E%E5%9B%A2%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/:3:3","tags":["线程池"],"title":"Java线程池实现原理及其在美团业务中的实践","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%9C%A8%E7%BE%8E%E5%9B%A2%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/"},{"categories":["好文转载"],"content":"3.4 实践总结 面对业务中使用线程池遇到的实际问题，我们曾回到支持并发性问题本身来思考有没有取代线程池的方案，也曾尝试着去追求线程池参数设置的合理性，但面对业界方案具体落地的复杂性、可维护性以及真实运行环境的不确定性，我们在前两个方向上可谓“举步维艰”。最终，我们回到线程池参数动态化方向上探索，得出一个且可以解决业务问题的方案，虽然本质上还是没有逃离使用线程池的范畴，但是在成本和收益之间，算是取得了一个很好的平衡。成本在于实现动态化以及监控成本不高，收益在于：在不颠覆原有线程池使用方式的基础之上，从降低线程池参数修改的成本以及多维度监控这两个方面降低了故障发生的概率。希望本文提供的动态化线程池思路能对大家有帮助。 ","date":"2021-07-14","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%9C%A8%E7%BE%8E%E5%9B%A2%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/:3:4","tags":["线程池"],"title":"Java线程池实现原理及其在美团业务中的实践","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%9C%A8%E7%BE%8E%E5%9B%A2%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/"},{"categories":["好文转载"],"content":"四、参考资料 [1] JDK 1.8源码 [2] 维基百科-线程池 [3] 更好的使用Java线程池 [4] 维基百科Pooling(Resource Management) [5] 深入理解Java线程池：ThreadPoolExecutor [6]《Java并发编程实践》 原文地址：https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html ","date":"2021-07-14","objectID":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%9C%A8%E7%BE%8E%E5%9B%A2%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/:4:0","tags":["线程池"],"title":"Java线程池实现原理及其在美团业务中的实践","uri":"/posts/%E5%A5%BD%E6%96%87%E8%BD%AC%E8%BD%BD/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%9C%A8%E7%BE%8E%E5%9B%A2%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/"},{"categories":["技术笔记"],"content":"什么是分布式锁？ 分布式锁顾名思义就是用在分布式系统中，用于控制分布式系统之间同步访问共享资源。 核心操作：加锁、解锁、防止锁超时。 分布式锁的几种实现 Memcached 分布式锁：Memecached add命令是原子性的。 Zookeeper 分布式锁：利用Zookeeper 的顺序临时节点，且临时节点连接中断会自动删除，来实现分布式锁。同时还提供watch机制，可以实现加锁失败就阻塞住，直到获取到锁为止。 Chubby：Google实现的粗粒度分布式锁服务。 Redis 分布式锁：下文详细讨论。 Redis分布式锁的实现 ","date":"2021-07-03","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0/:0:0","tags":["Redis"],"title":"Redis分布式锁实现","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0/"},{"categories":["技术笔记"],"content":"SETNX指令 SETNX指令只在key不存在的情况下，将key设置为value值，若key存在，则不做任何操作。 key是锁的唯一标识，可以按业务需求锁定的资源命名。 SETNX lock_key lock_value do something DEL lock_key 这一方式的问题在于：锁超时问题。如果获得锁的进程在业务处理过程中出现了异常，将导致DEL指令无法执行，锁无法释放，该资源将会被一直锁住。 ","date":"2021-07-03","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0/:1:0","tags":["Redis"],"title":"Redis分布式锁实现","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0/"},{"categories":["技术笔记"],"content":"SETNX指令 + EXPIRE指令 因此很容易想到，给key设置一个过期时间。由于SETNX不支持设置过期时间，所以需要额外的EXPIRE指令 SETNX lock_key lock_value EXPIRE lock_key 10 do something DEL lock_key 这一方式的问题在于：SETNX 和 EXPIRE 这两个操作是非原子性的， 如果进程在执行 SETNX 和 EXPIRE 之间发生异常，同样会出现上述问题。 ","date":"2021-07-03","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0/:2:0","tags":["Redis"],"title":"Redis分布式锁实现","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0/"},{"categories":["技术笔记"],"content":"SET扩展指令 为了解决 SETNX 和 EXPIRE 两个操作非原子性的问题，可以使用 Redis 的 SET 指令的扩展参数，使得 SETNX 和 EXPIRE 这两个操作可以原子执行。 SET lock_key lock_value NX EX 10 do something DEL lock_key 这一方式的问题在于：锁可能在业务处理结束前提前释放。从而也可能导致锁被误删。 为了避免上述情况，建议不要在执行时间过长的场景中使用 Redis 分布式锁，同时一个比较安全的做法是在执行 DEL 释放锁之前对锁进行判断，验证当前锁的持有者是否是自己。 具体实现就是在加锁时将 value 设置为一个唯一的随机数（或者线程 ID ），释放锁时先判断随机数是否一致，然后再执行释放操作，确保不会错误地释放其它线程持有的锁，除非是锁过期了被服务器自动释放。 SET lock_key random_value nx ex 10 do something if random_value == lock_key.value DEL lock_key ","date":"2021-07-03","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0/:3:0","tags":["Redis"],"title":"Redis分布式锁实现","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0/"},{"categories":["技术笔记"],"content":"SET扩展指令 + Lua 但判断 value 和删除 key 是两个独立的操作，并不是原子性的，所以这个地方需要使用 Lua 脚本进行处理。 if redis.call(\"get\", KEYS[1]) == ARGV[1] then return redis.call(\"del\", KEYS[1]) else return 0 end Redis使用Lua脚本时为什么能保证原子性? Redis使用同一个的Lua解释器，来运行所有的命令。Redis保证以一种原子性的方式来执行脚本。在执行脚本时，不会执行其他脚本或Redis命令。这个语义类似于MULTI（开启事务）/EXEC（触发事务，一并执行事务中的所有命令）。从所有其他客户端的角度来看，脚本的效果要么仍然不可见，要么已经完成。 但这并不是一个完美的方案，只是相对完全一点，因为它并没有完全解决执行超时锁被提前释放的问题。 ","date":"2021-07-03","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0/:4:0","tags":["Redis"],"title":"Redis分布式锁实现","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0/"},{"categories":["技术笔记"],"content":"Redisson 原理：可以利用锁的可重入特性，让获得锁的线程开启一个定时器的守护线程，每 expireTime/3 执行一次，去检查该线程的锁是否存在，如果存在则对锁的过期时间重新设置为 expireTime，即利用守护线程对锁进行“续命”，防止锁由于过期提前释放。 ","date":"2021-07-03","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0/:5:0","tags":["Redis"],"title":"Redis分布式锁实现","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0/"},{"categories":["技术笔记"],"content":"基于Redis多机实现的Redlock 以上几种基于 Redis 单机实现的分布式锁其实都存在一个问题，就是加锁时只作用在一个 Redis 节点上，即使 Redis 通过 Sentinel 保证了高可用，但由于 Redis 的复制是异步的，Master 节点获取到锁后在未完成数据同步的情况下发生故障转移，此时其他客户端上的线程依然可以获取到锁，因此会丧失锁的安全性。 在 Redis 的分布式环境中，Redis 的作者 antirez 提供了 RedLock 的算法来实现一个分布式锁，该算法大概是这样的： 假设有 N（N\u003e=5）个 Redis 节点，这些节点完全互相独立，不存在主从复制或者其他集群协调机制，确保在这 N 个节点上使用与在 Redis 单实例下相同的方法获取和释放锁。 获取锁的过程，客户端应执行如下操作： 获取当前 Unix 时间，以毫秒为单位。 按顺序依次尝试从 5 个实例使用相同的 key 和具有唯一性的 value（例如 UUID）获取锁。当向 Redis 请求获取锁时，客户端应该设置一个网络连接和响应超时时间，这个超时时间应该小于锁的失效时间。例如锁自动失效时间为 10 秒，则超时时间应该在 5-50 毫秒之间。这样可以避免服务器端 Redis 已经挂掉的情况下，客户端还在一直等待响应结果。如果服务器端没有在规定时间内响应，客户端应该尽快尝试去另外一个 Redis 实例请求获取锁。 客户端使用当前时间减去开始获取锁时间（步骤 1 记录的时间）就得到获取锁使用的时间。当且仅当从大多数（N/2+1，这里是 3 个节点）的 Redis 节点都取到锁，并且使用的时间小于锁失效时间时，锁才算获取成功。 如果取到了锁，key 的真正有效时间等于有效时间减去获取锁所使用的时间（步骤 3 计算的结果）。 如果因为某些原因，获取锁失败（没有在至少 N/2+1 个 Redis 实例取到锁或者取锁时间已经超过了有效时间），客户端应该在所有的 Redis 实例上进行解锁（使用 Redis Lua 脚本）。 参考 https://www.infoq.cn/article/dvaaj71f4fbqsxmgvdce https://juejin.cn/post/6844903830442737671#heading-14 ","date":"2021-07-03","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0/:6:0","tags":["Redis"],"title":"Redis分布式锁实现","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0/"},{"categories":["技术笔记"],"content":"本文旨在提供一个快速上手Flume的教程，内容上麻雀虽小但五脏俱全. 什么是Flume Flume is a distributed, reliable, and available service for efficiently collecting, aggregating, and moving large amounts of log data. Flume 是一种分布式、可靠且可用的服务，用于高效地收集、聚合和移动大量日志数据。由此可见，flume的应用场景是处理大量的日志数据。 其中框框部分就是Flume。 由Source、Channel、Sink三个核心组件组成。整体构成一个Agent。 名词解释： Source：是负责接受数据到Agent的组件。 Channel：位于Source和Sink之间的缓冲区。 Sink：负责将事件从从Channel写入到其他地方。可以是另一个Agent也可以是存储系统。 Event：Flume以事件的形式传递数据。 一个例子 ","date":"2021-06-01","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/flume%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/:0:0","tags":["Flume"],"title":"Flume快速上手","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/flume%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/"},{"categories":["技术笔记"],"content":"安装（针对Linux） 官网下载 apache-flume-1.7.0-bin.tar.gz 解压 tar -zxf apache-flume-1.7.0-bin.tar.gz ","date":"2021-06-01","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/flume%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/:1:0","tags":["Flume"],"title":"Flume快速上手","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/flume%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/"},{"categories":["技术笔记"],"content":"使用 主要是配置一个flume的配置文件，这里起名example.conf，规定以如下形式： # Name the components on this agent a1.sources = r1 //定义了一个agent a1，r1为a1的source a1.sinks = k1 //k1为a1的sink a1.channels = c1 //c1为a1的channel # Describe/configure the source a1.sources.r1.type = netcat #source r1的类型为netcat a1.sources.r1.bind = localhost #source r1绑定的地址 a1.sources.r1.port = 44444 #source r1绑定的端口 # Describe the sink a1.sinks.k1.type = logger #sink k1的类型 # Use a channel which buffers events in memory a1.channels.c1.type = memory #channel c1的类型 a1.channels.c1.capacity = 1000 #channel c1的容量 a1.channels.c1.transactionCapacity = 100 #channel c1的事务容量 # Bind the source and sink to the channel a1.sources.r1.channels = c1 #source r1和channel c1绑定 a1.sinks.k1.channel = c1 #sink k1和channel c1绑定 启动命令： bin/flume-ng agent --conf conf --conf-file example.conf --name a1 -Dflume.root.logger=INFO,console 组件种类 以下列举的是常用的组件类型，有用到其他的类型可以通过官网直接直接搜索类型查看详情 ","date":"2021-06-01","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/flume%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/:2:0","tags":["Flume"],"title":"Flume快速上手","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/flume%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/"},{"categories":["技术笔记"],"content":"source avro：用于接收从另一个flume（agent）中收到的数据 exec：用于接收从命令中获取的数据，如结合命令tail -f使用 netcat：用于接收端口传来的数据 spooling directory：用于接收文件变动的数据 ","date":"2021-06-01","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/flume%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/:3:0","tags":["Flume"],"title":"Flume快速上手","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/flume%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/"},{"categories":["技术笔记"],"content":"channel memory channel 内存，速度快，但宕机时有数据丢失的风险 file channel 速度比较慢，但安全 kafka channel ","date":"2021-06-01","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/flume%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/:4:0","tags":["Flume"],"title":"Flume快速上手","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/flume%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/"},{"categories":["技术笔记"],"content":"sink avro 输出到另一个flume（agent） hdfs 输出到hdfs logger 日志形式输出 file 文件形式落地 To be continue… 参考 Flume官网用户使用手册 ","date":"2021-06-01","objectID":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/flume%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/:5:0","tags":["Flume"],"title":"Flume快速上手","uri":"/posts/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/flume%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/"},{"categories":null,"content":"关于原形和ます形：https://zhidao.baidu.com/question/449869534 总体的变化规则：把原形的【う段】变成【い段+ます】。 动词原形又称辞书形，以う段假名作为词尾的动词。う、く（ぐ）、す、つ、ぬ、ぶ、む、る 所以，初学日语，背诵50音图时，竖着按段背诵很重要。 用途： 1，平级身份，上级对下级的日常会话。 2，查字典时用，所以又叫辞书形。 3，正式文章，如论文的写作。（书信，mail，产品说明书看情形用ます形） 4，语法上来讲。动词原形叫连体形，即连接体言（名词，代词）的形式。 所以做题时一定记住，名词呀，代词（の等）之前一定要接动词原形。 ます形通常意义上讲又称礼貌体，可以由动词原形变化成ます形。基本变化规律如下： 基本规律う段变成い段，加ます。 （其实ます前边的才叫动词的ます形。比如：たべます。　たべ叫做ます形。） う结尾的动词：う变成い。　例：　かう　＞　かいます く（ぐ）结尾的动词：く　（　ぐ　）变成き　（　ぎ　）　例：いく　＞　いきます　およぐ　＞　およぎます す结尾的动词：す变成し　例：　おす＞おします つ结尾的动词：つ变成ち　例：たつ　＞　たちます ぬ结尾的动词：ぬ变成に　例：しぬ　＞　しにます ぶ结尾的动词：ぶ变成び　例：ならぶ　＞　ならびます む结尾的动词：む变成み　例：よむ　＞　よみます　る结尾的动词：稍稍复杂。 分两类，看る前面的假名。 如果是え段假名，属于一段动词，简单，去掉る就行了。 例：たべる　＞　たべます 如果是え段意外的假名，属于五段动词，遵循以上规律。 る变成り　例：　きる　＞　きります 有例外：　おきる　＞　おきます　、　おりる　＞　おります　、　あびる　＞　あびます　等 其它：　くる　＞　きます 用途： 1，下级对上级，晚辈对长辈等，表示尊敬的语气。 2，语法上来讲。ます形叫连用形，即连接用言（动词，形容词，副词）的形式。所以要连接两 个动作，用ます形。如要表达：牵着手走。 ひく（牵）　あるく（走） 两个动作加在一起，变成 ひきあるく　手を引き歩く　","date":"0001-01-01","objectID":"/posts/%E7%94%9F%E6%B4%BB/%E5%8A%A8%E8%AF%8D%E7%AC%94%E8%AE%B0/:0:0","tags":null,"title":"","uri":"/posts/%E7%94%9F%E6%B4%BB/%E5%8A%A8%E8%AF%8D%E7%AC%94%E8%AE%B0/"}]